 => Using seed 2020
 => Using device: cuda
Files already downloaded and verified
Files already downloaded and verified
 => Loading model '/content/drive/MyDrive/pruningData/partially_trained/pretrained_models/vgg19_160_40_cifar100_basic_pretraining_model.pt'
 => Pruning (keeping 5.0% weights)
===> smart ratios before rearanging: 13.428, 3.021, 1.201, 0.601, 0.339, 0.206, 0.131, 0.086, 0.058, 0.039, 0.026, 0.018, 0.012, 0.008, 0.005, 0.003, 0.300
===> smart ratios: 1.000, 1.000, 1.000, 1.000, 0.515, 0.206, 0.131, 0.086, 0.058, 0.039, 0.026, 0.018, 0.012, 0.008, 0.005, 0.003, 0.300
===> total keep ratio: 0.04999625678686003
=> Using a preset learning rate schedule:
{0: 0.1, 80: 0.010000000000000002, 120: 0.001}
Fine tuning epoch 0 (scheduling like it's 40): loss 0.0243881, train_acc 63.85%, test_acc 56.43%
Fine tuning epoch 1 (scheduling like it's 41): loss 0.0192953, train_acc 66.27%, test_acc 57.21%
Fine tuning epoch 2 (scheduling like it's 42): loss 0.0173230, train_acc 71.27%, test_acc 60.34%
Fine tuning epoch 3 (scheduling like it's 43): loss 0.0163352, train_acc 65.42%, test_acc 56.40%
Fine tuning epoch 4 (scheduling like it's 44): loss 0.0153988, train_acc 68.70%, test_acc 58.10%
Fine tuning epoch 5 (scheduling like it's 45): loss 0.0149463, train_acc 72.87%, test_acc 60.84%
Fine tuning epoch 6 (scheduling like it's 46): loss 0.0144764, train_acc 72.59%, test_acc 60.36%
Fine tuning epoch 7 (scheduling like it's 47): loss 0.0142389, train_acc 73.61%, test_acc 60.73%
Fine tuning epoch 8 (scheduling like it's 48): loss 0.0138261, train_acc 77.42%, test_acc 63.59%
Fine tuning epoch 9 (scheduling like it's 49): loss 0.0137144, train_acc 74.47%, test_acc 61.43%
Fine tuning epoch 10 (scheduling like it's 50): loss 0.0135305, train_acc 75.65%, test_acc 61.58%
Fine tuning epoch 11 (scheduling like it's 51): loss 0.0134907, train_acc 71.76%, test_acc 58.75%
Fine tuning epoch 12 (scheduling like it's 52): loss 0.0132037, train_acc 77.38%, test_acc 62.78%
Fine tuning epoch 13 (scheduling like it's 53): loss 0.0130622, train_acc 71.19%, test_acc 59.06%
Fine tuning epoch 14 (scheduling like it's 54): loss 0.0130870, train_acc 77.43%, test_acc 62.84%
Fine tuning epoch 15 (scheduling like it's 55): loss 0.0130967, train_acc 76.34%, test_acc 62.64%
Fine tuning epoch 16 (scheduling like it's 56): loss 0.0130266, train_acc 72.38%, test_acc 59.29%
Fine tuning epoch 17 (scheduling like it's 57): loss 0.0128447, train_acc 75.09%, test_acc 61.42%
Fine tuning epoch 18 (scheduling like it's 58): loss 0.0127920, train_acc 77.08%, test_acc 62.43%
Fine tuning epoch 19 (scheduling like it's 59): loss 0.0126911, train_acc 74.36%, test_acc 60.20%
Fine tuning epoch 20 (scheduling like it's 60): loss 0.0127912, train_acc 77.50%, test_acc 62.91%
Fine tuning epoch 21 (scheduling like it's 61): loss 0.0126939, train_acc 74.73%, test_acc 61.47%
Fine tuning epoch 22 (scheduling like it's 62): loss 0.0126561, train_acc 77.12%, test_acc 62.18%
Fine tuning epoch 23 (scheduling like it's 63): loss 0.0125543, train_acc 75.00%, test_acc 61.30%
Fine tuning epoch 24 (scheduling like it's 64): loss 0.0126473, train_acc 73.47%, test_acc 59.93%
Fine tuning epoch 25 (scheduling like it's 65): loss 0.0125526, train_acc 74.93%, test_acc 60.51%
Fine tuning epoch 26 (scheduling like it's 66): loss 0.0125867, train_acc 75.70%, test_acc 61.29%
Fine tuning epoch 27 (scheduling like it's 67): loss 0.0125745, train_acc 77.92%, test_acc 63.68%
Fine tuning epoch 28 (scheduling like it's 68): loss 0.0123983, train_acc 77.12%, test_acc 62.60%
Fine tuning epoch 29 (scheduling like it's 69): loss 0.0124793, train_acc 76.11%, test_acc 61.51%
Fine tuning epoch 30 (scheduling like it's 70): loss 0.0126217, train_acc 74.35%, test_acc 60.25%
Fine tuning epoch 31 (scheduling like it's 71): loss 0.0124447, train_acc 72.00%, test_acc 59.83%
Fine tuning epoch 32 (scheduling like it's 72): loss 0.0126140, train_acc 75.40%, test_acc 60.50%
Fine tuning epoch 33 (scheduling like it's 73): loss 0.0124866, train_acc 77.07%, test_acc 62.73%
Fine tuning epoch 34 (scheduling like it's 74): loss 0.0124097, train_acc 78.72%, test_acc 63.34%
Fine tuning epoch 35 (scheduling like it's 75): loss 0.0123633, train_acc 75.35%, test_acc 61.62%
Fine tuning epoch 36 (scheduling like it's 76): loss 0.0123577, train_acc 74.92%, test_acc 60.85%
Fine tuning epoch 37 (scheduling like it's 77): loss 0.0122934, train_acc 75.44%, test_acc 61.21%
Fine tuning epoch 38 (scheduling like it's 78): loss 0.0125518, train_acc 75.47%, test_acc 61.63%
Fine tuning epoch 39 (scheduling like it's 79): loss 0.0124277, train_acc 76.61%, test_acc 61.96%
Fine tuning epoch 40 (scheduling like it's 80): loss 0.0071314, train_acc 90.38%, test_acc 70.03%
Fine tuning epoch 41 (scheduling like it's 81): loss 0.0055958, train_acc 91.78%, test_acc 70.30%
Fine tuning epoch 42 (scheduling like it's 82): loss 0.0049823, train_acc 92.88%, test_acc 70.43%
Fine tuning epoch 43 (scheduling like it's 83): loss 0.0045495, train_acc 93.36%, test_acc 70.76%
Fine tuning epoch 44 (scheduling like it's 84): loss 0.0042449, train_acc 94.00%, test_acc 70.99%
Fine tuning epoch 45 (scheduling like it's 85): loss 0.0039683, train_acc 94.50%, test_acc 70.71%
Fine tuning epoch 46 (scheduling like it's 86): loss 0.0037361, train_acc 94.80%, test_acc 70.84%
Fine tuning epoch 47 (scheduling like it's 87): loss 0.0035477, train_acc 95.37%, test_acc 70.69%
Fine tuning epoch 48 (scheduling like it's 88): loss 0.0033666, train_acc 95.60%, test_acc 70.74%
Fine tuning epoch 49 (scheduling like it's 89): loss 0.0031760, train_acc 95.82%, test_acc 70.54%
Fine tuning epoch 50 (scheduling like it's 90): loss 0.0030776, train_acc 96.06%, test_acc 70.62%
Fine tuning epoch 51 (scheduling like it's 91): loss 0.0028685, train_acc 96.27%, test_acc 70.55%
Fine tuning epoch 52 (scheduling like it's 92): loss 0.0028518, train_acc 96.55%, test_acc 70.44%
Fine tuning epoch 53 (scheduling like it's 93): loss 0.0026993, train_acc 96.52%, test_acc 70.43%
Fine tuning epoch 54 (scheduling like it's 94): loss 0.0025970, train_acc 96.89%, test_acc 70.51%
Fine tuning epoch 55 (scheduling like it's 95): loss 0.0025257, train_acc 96.97%, test_acc 70.67%
Fine tuning epoch 56 (scheduling like it's 96): loss 0.0024654, train_acc 97.06%, test_acc 70.41%
Fine tuning epoch 57 (scheduling like it's 97): loss 0.0023816, train_acc 97.16%, test_acc 70.56%
Fine tuning epoch 58 (scheduling like it's 98): loss 0.0023229, train_acc 97.51%, test_acc 70.62%
Fine tuning epoch 59 (scheduling like it's 99): loss 0.0022347, train_acc 97.51%, test_acc 70.49%
Fine tuning epoch 60 (scheduling like it's 100): loss 0.0021839, train_acc 97.55%, test_acc 70.18%
Fine tuning epoch 61 (scheduling like it's 101): loss 0.0020706, train_acc 97.70%, test_acc 70.35%
Fine tuning epoch 62 (scheduling like it's 102): loss 0.0019984, train_acc 97.90%, test_acc 70.66%
Fine tuning epoch 63 (scheduling like it's 103): loss 0.0019799, train_acc 97.77%, test_acc 70.07%
Fine tuning epoch 64 (scheduling like it's 104): loss 0.0019264, train_acc 97.99%, test_acc 70.39%
Fine tuning epoch 65 (scheduling like it's 105): loss 0.0019326, train_acc 97.98%, test_acc 70.31%
Fine tuning epoch 66 (scheduling like it's 106): loss 0.0018871, train_acc 98.14%, test_acc 70.12%
Fine tuning epoch 67 (scheduling like it's 107): loss 0.0017749, train_acc 98.14%, test_acc 70.25%
Fine tuning epoch 68 (scheduling like it's 108): loss 0.0017184, train_acc 98.27%, test_acc 70.39%
Fine tuning epoch 69 (scheduling like it's 109): loss 0.0017038, train_acc 98.13%, test_acc 70.37%
Fine tuning epoch 70 (scheduling like it's 110): loss 0.0017260, train_acc 98.16%, test_acc 69.73%
Fine tuning epoch 71 (scheduling like it's 111): loss 0.0017315, train_acc 98.29%, test_acc 70.09%
Fine tuning epoch 72 (scheduling like it's 112): loss 0.0016527, train_acc 98.28%, test_acc 69.81%
Fine tuning epoch 73 (scheduling like it's 113): loss 0.0016250, train_acc 98.28%, test_acc 70.07%
Fine tuning epoch 74 (scheduling like it's 114): loss 0.0016640, train_acc 98.46%, test_acc 70.09%
Fine tuning epoch 75 (scheduling like it's 115): loss 0.0016671, train_acc 98.47%, test_acc 69.95%
Fine tuning epoch 76 (scheduling like it's 116): loss 0.0015766, train_acc 98.43%, test_acc 69.96%
Fine tuning epoch 77 (scheduling like it's 117): loss 0.0015340, train_acc 98.41%, test_acc 70.21%
Fine tuning epoch 78 (scheduling like it's 118): loss 0.0015700, train_acc 98.52%, test_acc 69.94%
Fine tuning epoch 79 (scheduling like it's 119): loss 0.0015786, train_acc 98.49%, test_acc 70.09%
Fine tuning epoch 80 (scheduling like it's 120): loss 0.0012666, train_acc 99.05%, test_acc 70.58%
Fine tuning epoch 81 (scheduling like it's 121): loss 0.0011249, train_acc 99.12%, test_acc 70.86%
Fine tuning epoch 82 (scheduling like it's 122): loss 0.0010861, train_acc 99.08%, test_acc 70.80%
Fine tuning epoch 83 (scheduling like it's 123): loss 0.0010805, train_acc 99.24%, test_acc 70.70%
Fine tuning epoch 84 (scheduling like it's 124): loss 0.0010221, train_acc 99.25%, test_acc 70.60%
Fine tuning epoch 85 (scheduling like it's 125): loss 0.0010121, train_acc 99.26%, test_acc 70.75%
Fine tuning epoch 86 (scheduling like it's 126): loss 0.0009809, train_acc 99.32%, test_acc 70.72%
Fine tuning epoch 87 (scheduling like it's 127): loss 0.0009825, train_acc 99.33%, test_acc 70.88%
Fine tuning epoch 88 (scheduling like it's 128): loss 0.0009618, train_acc 99.32%, test_acc 70.74%
Fine tuning epoch 89 (scheduling like it's 129): loss 0.0009250, train_acc 99.35%, test_acc 70.67%
Fine tuning epoch 90 (scheduling like it's 130): loss 0.0009541, train_acc 99.43%, test_acc 70.65%
Fine tuning epoch 91 (scheduling like it's 131): loss 0.0009128, train_acc 99.35%, test_acc 70.77%
Fine tuning epoch 92 (scheduling like it's 132): loss 0.0009330, train_acc 99.39%, test_acc 70.72%
Fine tuning epoch 93 (scheduling like it's 133): loss 0.0008775, train_acc 99.40%, test_acc 70.82%
Fine tuning epoch 94 (scheduling like it's 134): loss 0.0009087, train_acc 99.43%, test_acc 70.85%
Fine tuning epoch 95 (scheduling like it's 135): loss 0.0008882, train_acc 99.42%, test_acc 70.73%
Fine tuning epoch 96 (scheduling like it's 136): loss 0.0008714, train_acc 99.47%, test_acc 70.68%
Fine tuning epoch 97 (scheduling like it's 137): loss 0.0008706, train_acc 99.46%, test_acc 70.89%
Fine tuning epoch 98 (scheduling like it's 138): loss 0.0008569, train_acc 99.42%, test_acc 70.95%
Fine tuning epoch 99 (scheduling like it's 139): loss 0.0008630, train_acc 99.43%, test_acc 70.84%
Fine tuning epoch 100 (scheduling like it's 140): loss 0.0008582, train_acc 99.55%, test_acc 70.82%
Fine tuning epoch 101 (scheduling like it's 141): loss 0.0008456, train_acc 99.51%, test_acc 70.60%
Fine tuning epoch 102 (scheduling like it's 142): loss 0.0008489, train_acc 99.52%, test_acc 70.72%
Fine tuning epoch 103 (scheduling like it's 143): loss 0.0008386, train_acc 99.55%, test_acc 70.87%
Fine tuning epoch 104 (scheduling like it's 144): loss 0.0008243, train_acc 99.55%, test_acc 70.98%
Fine tuning epoch 105 (scheduling like it's 145): loss 0.0008196, train_acc 99.53%, test_acc 70.86%
Fine tuning epoch 106 (scheduling like it's 146): loss 0.0008023, train_acc 99.50%, test_acc 70.94%
Fine tuning epoch 107 (scheduling like it's 147): loss 0.0008053, train_acc 99.55%, test_acc 70.81%
Fine tuning epoch 108 (scheduling like it's 148): loss 0.0008141, train_acc 99.52%, test_acc 70.84%
Fine tuning epoch 109 (scheduling like it's 149): loss 0.0007881, train_acc 99.55%, test_acc 70.70%
Fine tuning epoch 110 (scheduling like it's 150): loss 0.0007828, train_acc 99.58%, test_acc 71.10%
Fine tuning epoch 111 (scheduling like it's 151): loss 0.0008137, train_acc 99.56%, test_acc 71.01%
Fine tuning epoch 112 (scheduling like it's 152): loss 0.0007766, train_acc 99.54%, test_acc 71.00%
Fine tuning epoch 113 (scheduling like it's 153): loss 0.0007898, train_acc 99.62%, test_acc 70.75%
Fine tuning epoch 114 (scheduling like it's 154): loss 0.0007877, train_acc 99.57%, test_acc 70.87%
Fine tuning epoch 115 (scheduling like it's 155): loss 0.0007595, train_acc 99.58%, test_acc 71.05%
Fine tuning epoch 116 (scheduling like it's 156): loss 0.0007559, train_acc 99.55%, test_acc 70.74%
Fine tuning epoch 117 (scheduling like it's 157): loss 0.0007549, train_acc 99.58%, test_acc 70.99%
Fine tuning epoch 118 (scheduling like it's 158): loss 0.0007707, train_acc 99.62%, test_acc 70.86%
Fine tuning epoch 119 (scheduling like it's 159): loss 0.0007629, train_acc 99.63%, test_acc 70.92%
Fine tuning epoch 120 (scheduling like it's 160): loss 0.0007369, train_acc 99.62%, test_acc 70.70%
Fine tuning epoch 121 (scheduling like it's 161): loss 0.0007258, train_acc 99.60%, test_acc 70.80%
Fine tuning epoch 122 (scheduling like it's 162): loss 0.0007420, train_acc 99.65%, test_acc 70.75%
Fine tuning epoch 123 (scheduling like it's 163): loss 0.0007443, train_acc 99.60%, test_acc 70.92%
Fine tuning epoch 124 (scheduling like it's 164): loss 0.0007249, train_acc 99.65%, test_acc 70.93%
Fine tuning epoch 125 (scheduling like it's 165): loss 0.0007198, train_acc 99.61%, test_acc 70.74%
Fine tuning epoch 126 (scheduling like it's 166): loss 0.0007317, train_acc 99.64%, test_acc 70.86%
Fine tuning epoch 127 (scheduling like it's 167): loss 0.0007188, train_acc 99.61%, test_acc 70.93%
Fine tuning epoch 128 (scheduling like it's 168): loss 0.0007067, train_acc 99.64%, test_acc 70.78%
Fine tuning epoch 129 (scheduling like it's 169): loss 0.0007360, train_acc 99.68%, test_acc 70.94%
Fine tuning epoch 130 (scheduling like it's 170): loss 0.0007308, train_acc 99.64%, test_acc 70.99%
Fine tuning epoch 131 (scheduling like it's 171): loss 0.0007135, train_acc 99.69%, test_acc 70.96%
Fine tuning epoch 132 (scheduling like it's 172): loss 0.0006951, train_acc 99.68%, test_acc 70.89%
Fine tuning epoch 133 (scheduling like it's 173): loss 0.0006816, train_acc 99.68%, test_acc 70.93%
Fine tuning epoch 134 (scheduling like it's 174): loss 0.0006988, train_acc 99.64%, test_acc 70.93%
Fine tuning epoch 135 (scheduling like it's 175): loss 0.0007182, train_acc 99.70%, test_acc 70.92%
Fine tuning epoch 136 (scheduling like it's 176): loss 0.0006664, train_acc 99.65%, test_acc 70.96%
Fine tuning epoch 137 (scheduling like it's 177): loss 0.0006942, train_acc 99.64%, test_acc 70.97%
Fine tuning epoch 138 (scheduling like it's 178): loss 0.0006788, train_acc 99.71%, test_acc 71.02%
Fine tuning epoch 139 (scheduling like it's 179): loss 0.0006881, train_acc 99.65%, test_acc 71.01%
Fine tuning epoch 140 (scheduling like it's 180): loss 0.0006659, train_acc 99.69%, test_acc 70.75%
Fine tuning epoch 141 (scheduling like it's 181): loss 0.0006865, train_acc 99.67%, test_acc 70.80%
Fine tuning epoch 142 (scheduling like it's 182): loss 0.0006969, train_acc 99.69%, test_acc 70.86%
Fine tuning epoch 143 (scheduling like it's 183): loss 0.0006697, train_acc 99.70%, test_acc 70.76%
Fine tuning epoch 144 (scheduling like it's 184): loss 0.0006708, train_acc 99.68%, test_acc 70.93%
Fine tuning epoch 145 (scheduling like it's 185): loss 0.0006739, train_acc 99.67%, test_acc 70.90%
Fine tuning epoch 146 (scheduling like it's 186): loss 0.0006575, train_acc 99.70%, test_acc 70.82%
Fine tuning epoch 147 (scheduling like it's 187): loss 0.0006620, train_acc 99.72%, test_acc 71.06%
Fine tuning epoch 148 (scheduling like it's 188): loss 0.0006298, train_acc 99.71%, test_acc 71.10%
Fine tuning epoch 149 (scheduling like it's 189): loss 0.0006579, train_acc 99.74%, test_acc 70.95%
Fine tuning epoch 150 (scheduling like it's 190): loss 0.0006491, train_acc 99.70%, test_acc 71.03%
Fine tuning epoch 151 (scheduling like it's 191): loss 0.0006508, train_acc 99.70%, test_acc 70.94%
Fine tuning epoch 152 (scheduling like it's 192): loss 0.0006699, train_acc 99.71%, test_acc 70.95%
Fine tuning epoch 153 (scheduling like it's 193): loss 0.0006448, train_acc 99.72%, test_acc 71.02%
Fine tuning epoch 154 (scheduling like it's 194): loss 0.0006560, train_acc 99.71%, test_acc 71.08%
Fine tuning epoch 155 (scheduling like it's 195): loss 0.0006413, train_acc 99.71%, test_acc 71.02%
Fine tuning epoch 156 (scheduling like it's 196): loss 0.0006287, train_acc 99.73%, test_acc 71.02%
Fine tuning epoch 157 (scheduling like it's 197): loss 0.0006560, train_acc 99.76%, test_acc 71.10%
Fine tuning epoch 158 (scheduling like it's 198): loss 0.0006540, train_acc 99.72%, test_acc 71.00%
Fine tuning epoch 159 (scheduling like it's 199): loss 0.0006625, train_acc 99.75%, test_acc 70.96%
