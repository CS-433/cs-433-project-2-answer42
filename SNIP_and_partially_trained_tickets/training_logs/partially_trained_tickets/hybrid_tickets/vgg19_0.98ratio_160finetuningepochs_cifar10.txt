 => Using seed 2020
 => Using device: cuda
Files already downloaded and verified
Files already downloaded and verified
 => Loading model '/content/drive/MyDrive/pruningData/partially_trained/pretrained_models/vgg19_160_40_cifar10_basic_pretraining_model.pt'
 => Pruning (keeping 2.0% weights)
===> smart ratios before rearanging: 5.422, 1.220, 0.485, 0.243, 0.137, 0.083, 0.053, 0.035, 0.023, 0.016, 0.011, 0.007, 0.005, 0.003, 0.002, 0.001, 0.300
===> smart ratios: 1.000, 1.000, 0.699, 0.243, 0.137, 0.083, 0.053, 0.035, 0.023, 0.016, 0.011, 0.007, 0.005, 0.003, 0.002, 0.001, 0.300
===> total keep ratio: 0.019999848516880078
=> Using a preset learning rate schedule:
{0: 0.1, 80: 0.010000000000000002, 120: 0.001}
Fine tuning epoch 0 (scheduling like it's 40): loss 0.0068918, train_acc 81.95%, test_acc 78.57%
Fine tuning epoch 1 (scheduling like it's 41): loss 0.0049171, train_acc 92.31%, test_acc 88.14%
Fine tuning epoch 2 (scheduling like it's 42): loss 0.0041315, train_acc 92.38%, test_acc 87.69%
Fine tuning epoch 3 (scheduling like it's 43): loss 0.0038508, train_acc 92.42%, test_acc 87.61%
Fine tuning epoch 4 (scheduling like it's 44): loss 0.0035966, train_acc 93.40%, test_acc 88.52%
Fine tuning epoch 5 (scheduling like it's 45): loss 0.0034193, train_acc 93.27%, test_acc 88.61%
Fine tuning epoch 6 (scheduling like it's 46): loss 0.0032838, train_acc 91.16%, test_acc 86.22%
Fine tuning epoch 7 (scheduling like it's 47): loss 0.0033179, train_acc 92.53%, test_acc 87.98%
Fine tuning epoch 8 (scheduling like it's 48): loss 0.0032364, train_acc 93.59%, test_acc 88.77%
Fine tuning epoch 9 (scheduling like it's 49): loss 0.0031179, train_acc 94.52%, test_acc 89.30%
Fine tuning epoch 10 (scheduling like it's 50): loss 0.0030405, train_acc 93.90%, test_acc 88.82%
Fine tuning epoch 11 (scheduling like it's 51): loss 0.0030376, train_acc 93.22%, test_acc 88.40%
Fine tuning epoch 12 (scheduling like it's 52): loss 0.0030881, train_acc 91.96%, test_acc 87.41%
Fine tuning epoch 13 (scheduling like it's 53): loss 0.0029736, train_acc 93.63%, test_acc 88.78%
Fine tuning epoch 14 (scheduling like it's 54): loss 0.0029621, train_acc 94.04%, test_acc 89.13%
Fine tuning epoch 15 (scheduling like it's 55): loss 0.0030508, train_acc 92.89%, test_acc 87.70%
Fine tuning epoch 16 (scheduling like it's 56): loss 0.0028916, train_acc 94.79%, test_acc 88.72%
Fine tuning epoch 17 (scheduling like it's 57): loss 0.0029267, train_acc 94.07%, test_acc 88.80%
Fine tuning epoch 18 (scheduling like it's 58): loss 0.0028980, train_acc 94.83%, test_acc 89.71%
Fine tuning epoch 19 (scheduling like it's 59): loss 0.0029463, train_acc 93.73%, test_acc 88.49%
Fine tuning epoch 20 (scheduling like it's 60): loss 0.0029064, train_acc 93.70%, test_acc 88.36%
Fine tuning epoch 21 (scheduling like it's 61): loss 0.0029548, train_acc 93.46%, test_acc 88.59%
Fine tuning epoch 22 (scheduling like it's 62): loss 0.0029296, train_acc 94.43%, test_acc 89.34%
Fine tuning epoch 23 (scheduling like it's 63): loss 0.0028638, train_acc 93.26%, test_acc 88.55%
Fine tuning epoch 24 (scheduling like it's 64): loss 0.0028195, train_acc 93.11%, test_acc 87.74%
Fine tuning epoch 25 (scheduling like it's 65): loss 0.0028873, train_acc 94.76%, test_acc 89.38%
Fine tuning epoch 26 (scheduling like it's 66): loss 0.0028655, train_acc 93.69%, test_acc 88.13%
Fine tuning epoch 27 (scheduling like it's 67): loss 0.0029101, train_acc 94.86%, test_acc 89.88%
Fine tuning epoch 28 (scheduling like it's 68): loss 0.0028198, train_acc 93.91%, test_acc 88.57%
Fine tuning epoch 29 (scheduling like it's 69): loss 0.0027613, train_acc 94.56%, test_acc 89.23%
Fine tuning epoch 30 (scheduling like it's 70): loss 0.0029865, train_acc 93.42%, test_acc 87.97%
Fine tuning epoch 31 (scheduling like it's 71): loss 0.0028275, train_acc 94.04%, test_acc 88.82%
Fine tuning epoch 32 (scheduling like it's 72): loss 0.0028018, train_acc 93.43%, test_acc 88.21%
Fine tuning epoch 33 (scheduling like it's 73): loss 0.0028740, train_acc 94.18%, test_acc 88.97%
Fine tuning epoch 34 (scheduling like it's 74): loss 0.0027724, train_acc 94.79%, test_acc 89.48%
Fine tuning epoch 35 (scheduling like it's 75): loss 0.0028572, train_acc 92.80%, test_acc 87.76%
Fine tuning epoch 36 (scheduling like it's 76): loss 0.0028172, train_acc 94.60%, test_acc 89.56%
Fine tuning epoch 37 (scheduling like it's 77): loss 0.0029313, train_acc 93.98%, test_acc 88.50%
Fine tuning epoch 38 (scheduling like it's 78): loss 0.0028211, train_acc 95.06%, test_acc 89.47%
Fine tuning epoch 39 (scheduling like it's 79): loss 0.0028400, train_acc 94.66%, test_acc 89.20%
Fine tuning epoch 40 (scheduling like it's 80): loss 0.0014949, train_acc 98.07%, test_acc 91.89%
Fine tuning epoch 41 (scheduling like it's 81): loss 0.0010658, train_acc 98.52%, test_acc 92.18%
Fine tuning epoch 42 (scheduling like it's 82): loss 0.0008698, train_acc 98.82%, test_acc 92.22%
Fine tuning epoch 43 (scheduling like it's 83): loss 0.0007393, train_acc 98.87%, test_acc 92.68%
Fine tuning epoch 44 (scheduling like it's 84): loss 0.0007055, train_acc 99.00%, test_acc 92.37%
Fine tuning epoch 45 (scheduling like it's 85): loss 0.0006693, train_acc 99.13%, test_acc 92.41%
Fine tuning epoch 46 (scheduling like it's 86): loss 0.0006281, train_acc 99.23%, test_acc 92.53%
Fine tuning epoch 47 (scheduling like it's 87): loss 0.0005486, train_acc 99.23%, test_acc 92.39%
Fine tuning epoch 48 (scheduling like it's 88): loss 0.0005060, train_acc 99.30%, test_acc 92.47%
Fine tuning epoch 49 (scheduling like it's 89): loss 0.0005118, train_acc 99.40%, test_acc 92.65%
Fine tuning epoch 50 (scheduling like it's 90): loss 0.0004657, train_acc 99.48%, test_acc 92.61%
Fine tuning epoch 51 (scheduling like it's 91): loss 0.0004278, train_acc 99.48%, test_acc 92.77%
Fine tuning epoch 52 (scheduling like it's 92): loss 0.0004364, train_acc 99.48%, test_acc 92.53%
Fine tuning epoch 53 (scheduling like it's 93): loss 0.0004097, train_acc 99.48%, test_acc 92.74%
Fine tuning epoch 54 (scheduling like it's 94): loss 0.0003889, train_acc 99.54%, test_acc 92.66%
Fine tuning epoch 55 (scheduling like it's 95): loss 0.0003712, train_acc 99.51%, test_acc 92.56%
Fine tuning epoch 56 (scheduling like it's 96): loss 0.0003578, train_acc 99.49%, test_acc 92.43%
Fine tuning epoch 57 (scheduling like it's 97): loss 0.0003423, train_acc 99.58%, test_acc 92.52%
Fine tuning epoch 58 (scheduling like it's 98): loss 0.0003383, train_acc 99.59%, test_acc 92.58%
Fine tuning epoch 59 (scheduling like it's 99): loss 0.0002960, train_acc 99.60%, test_acc 92.84%
Fine tuning epoch 60 (scheduling like it's 100): loss 0.0003194, train_acc 99.61%, test_acc 92.73%
Fine tuning epoch 61 (scheduling like it's 101): loss 0.0003363, train_acc 99.63%, test_acc 92.85%
Fine tuning epoch 62 (scheduling like it's 102): loss 0.0003136, train_acc 99.58%, test_acc 92.59%
Fine tuning epoch 63 (scheduling like it's 103): loss 0.0003106, train_acc 99.58%, test_acc 92.59%
Fine tuning epoch 64 (scheduling like it's 104): loss 0.0003233, train_acc 99.69%, test_acc 92.87%
Fine tuning epoch 65 (scheduling like it's 105): loss 0.0002972, train_acc 99.62%, test_acc 92.50%
Fine tuning epoch 66 (scheduling like it's 106): loss 0.0002882, train_acc 99.59%, test_acc 92.53%
Fine tuning epoch 67 (scheduling like it's 107): loss 0.0002872, train_acc 99.68%, test_acc 92.81%
Fine tuning epoch 68 (scheduling like it's 108): loss 0.0002626, train_acc 99.64%, test_acc 92.34%
Fine tuning epoch 69 (scheduling like it's 109): loss 0.0002799, train_acc 99.66%, test_acc 92.50%
Fine tuning epoch 70 (scheduling like it's 110): loss 0.0002664, train_acc 99.66%, test_acc 92.46%
Fine tuning epoch 71 (scheduling like it's 111): loss 0.0002895, train_acc 99.63%, test_acc 92.31%
Fine tuning epoch 72 (scheduling like it's 112): loss 0.0002710, train_acc 99.66%, test_acc 92.39%
Fine tuning epoch 73 (scheduling like it's 113): loss 0.0002623, train_acc 99.72%, test_acc 92.57%
Fine tuning epoch 74 (scheduling like it's 114): loss 0.0002943, train_acc 99.67%, test_acc 92.50%
Fine tuning epoch 75 (scheduling like it's 115): loss 0.0002933, train_acc 99.67%, test_acc 92.38%
Fine tuning epoch 76 (scheduling like it's 116): loss 0.0002883, train_acc 99.58%, test_acc 92.43%
Fine tuning epoch 77 (scheduling like it's 117): loss 0.0002815, train_acc 99.62%, test_acc 92.66%
Fine tuning epoch 78 (scheduling like it's 118): loss 0.0002496, train_acc 99.59%, test_acc 92.38%
Fine tuning epoch 79 (scheduling like it's 119): loss 0.0002804, train_acc 99.59%, test_acc 92.40%
Fine tuning epoch 80 (scheduling like it's 120): loss 0.0002278, train_acc 99.83%, test_acc 92.75%
Fine tuning epoch 81 (scheduling like it's 121): loss 0.0001886, train_acc 99.86%, test_acc 92.74%
Fine tuning epoch 82 (scheduling like it's 122): loss 0.0001465, train_acc 99.86%, test_acc 92.78%
Fine tuning epoch 83 (scheduling like it's 123): loss 0.0001439, train_acc 99.87%, test_acc 92.66%
Fine tuning epoch 84 (scheduling like it's 124): loss 0.0001406, train_acc 99.86%, test_acc 92.85%
Fine tuning epoch 85 (scheduling like it's 125): loss 0.0001321, train_acc 99.87%, test_acc 92.71%
Fine tuning epoch 86 (scheduling like it's 126): loss 0.0001359, train_acc 99.88%, test_acc 92.64%
Fine tuning epoch 87 (scheduling like it's 127): loss 0.0001385, train_acc 99.88%, test_acc 92.86%
Fine tuning epoch 88 (scheduling like it's 128): loss 0.0001181, train_acc 99.90%, test_acc 92.82%
Fine tuning epoch 89 (scheduling like it's 129): loss 0.0001123, train_acc 99.90%, test_acc 92.69%
Fine tuning epoch 90 (scheduling like it's 130): loss 0.0001207, train_acc 99.91%, test_acc 92.76%
Fine tuning epoch 91 (scheduling like it's 131): loss 0.0001172, train_acc 99.93%, test_acc 92.75%
Fine tuning epoch 92 (scheduling like it's 132): loss 0.0001075, train_acc 99.93%, test_acc 92.76%
Fine tuning epoch 93 (scheduling like it's 133): loss 0.0001149, train_acc 99.92%, test_acc 92.68%
Fine tuning epoch 94 (scheduling like it's 134): loss 0.0001118, train_acc 99.93%, test_acc 92.85%
Fine tuning epoch 95 (scheduling like it's 135): loss 0.0001006, train_acc 99.91%, test_acc 92.91%
Fine tuning epoch 96 (scheduling like it's 136): loss 0.0001015, train_acc 99.91%, test_acc 92.80%
Fine tuning epoch 97 (scheduling like it's 137): loss 0.0001023, train_acc 99.93%, test_acc 92.90%
Fine tuning epoch 98 (scheduling like it's 138): loss 0.0000983, train_acc 99.92%, test_acc 92.94%
Fine tuning epoch 99 (scheduling like it's 139): loss 0.0001124, train_acc 99.94%, test_acc 92.92%
Fine tuning epoch 100 (scheduling like it's 140): loss 0.0001056, train_acc 99.92%, test_acc 92.90%
Fine tuning epoch 101 (scheduling like it's 141): loss 0.0001054, train_acc 99.90%, test_acc 92.90%
Fine tuning epoch 102 (scheduling like it's 142): loss 0.0001158, train_acc 99.95%, test_acc 92.86%
Fine tuning epoch 103 (scheduling like it's 143): loss 0.0001025, train_acc 99.91%, test_acc 92.99%
Fine tuning epoch 104 (scheduling like it's 144): loss 0.0000928, train_acc 99.91%, test_acc 93.03%
Fine tuning epoch 105 (scheduling like it's 145): loss 0.0000902, train_acc 99.94%, test_acc 93.02%
Fine tuning epoch 106 (scheduling like it's 146): loss 0.0000956, train_acc 99.94%, test_acc 92.91%
Fine tuning epoch 107 (scheduling like it's 147): loss 0.0000894, train_acc 99.95%, test_acc 92.97%
Fine tuning epoch 108 (scheduling like it's 148): loss 0.0000949, train_acc 99.93%, test_acc 92.84%
Fine tuning epoch 109 (scheduling like it's 149): loss 0.0000957, train_acc 99.92%, test_acc 92.80%
Fine tuning epoch 110 (scheduling like it's 150): loss 0.0000914, train_acc 99.91%, test_acc 93.12%
Fine tuning epoch 111 (scheduling like it's 151): loss 0.0000910, train_acc 99.93%, test_acc 93.03%
Fine tuning epoch 112 (scheduling like it's 152): loss 0.0000805, train_acc 99.90%, test_acc 92.99%
Fine tuning epoch 113 (scheduling like it's 153): loss 0.0000862, train_acc 99.94%, test_acc 92.95%
Fine tuning epoch 114 (scheduling like it's 154): loss 0.0000773, train_acc 99.94%, test_acc 92.89%
Fine tuning epoch 115 (scheduling like it's 155): loss 0.0000804, train_acc 99.93%, test_acc 92.96%
Fine tuning epoch 116 (scheduling like it's 156): loss 0.0000847, train_acc 99.94%, test_acc 92.84%
Fine tuning epoch 117 (scheduling like it's 157): loss 0.0000898, train_acc 99.93%, test_acc 92.88%
Fine tuning epoch 118 (scheduling like it's 158): loss 0.0000778, train_acc 99.97%, test_acc 93.00%
Fine tuning epoch 119 (scheduling like it's 159): loss 0.0000773, train_acc 99.94%, test_acc 92.96%
Fine tuning epoch 120 (scheduling like it's 160): loss 0.0000739, train_acc 99.96%, test_acc 93.13%
Fine tuning epoch 121 (scheduling like it's 161): loss 0.0000843, train_acc 99.95%, test_acc 92.99%
Fine tuning epoch 122 (scheduling like it's 162): loss 0.0000823, train_acc 99.96%, test_acc 92.96%
Fine tuning epoch 123 (scheduling like it's 163): loss 0.0000761, train_acc 99.97%, test_acc 92.93%
Fine tuning epoch 124 (scheduling like it's 164): loss 0.0000830, train_acc 99.95%, test_acc 93.00%
Fine tuning epoch 125 (scheduling like it's 165): loss 0.0000819, train_acc 99.94%, test_acc 93.01%
Fine tuning epoch 126 (scheduling like it's 166): loss 0.0000797, train_acc 99.96%, test_acc 93.06%
Fine tuning epoch 127 (scheduling like it's 167): loss 0.0000782, train_acc 99.94%, test_acc 92.94%
Fine tuning epoch 128 (scheduling like it's 168): loss 0.0000802, train_acc 99.97%, test_acc 92.94%
Fine tuning epoch 129 (scheduling like it's 169): loss 0.0000792, train_acc 99.96%, test_acc 92.93%
Fine tuning epoch 130 (scheduling like it's 170): loss 0.0000717, train_acc 99.96%, test_acc 92.87%
Fine tuning epoch 131 (scheduling like it's 171): loss 0.0000832, train_acc 99.98%, test_acc 92.90%
Fine tuning epoch 132 (scheduling like it's 172): loss 0.0000740, train_acc 99.97%, test_acc 93.08%
Fine tuning epoch 133 (scheduling like it's 173): loss 0.0000759, train_acc 99.97%, test_acc 93.06%
Fine tuning epoch 134 (scheduling like it's 174): loss 0.0000757, train_acc 99.95%, test_acc 92.98%
Fine tuning epoch 135 (scheduling like it's 175): loss 0.0000774, train_acc 99.96%, test_acc 93.05%
Fine tuning epoch 136 (scheduling like it's 176): loss 0.0000743, train_acc 99.94%, test_acc 92.90%
Fine tuning epoch 137 (scheduling like it's 177): loss 0.0000689, train_acc 99.97%, test_acc 93.11%
Fine tuning epoch 138 (scheduling like it's 178): loss 0.0000697, train_acc 99.97%, test_acc 92.92%
Fine tuning epoch 139 (scheduling like it's 179): loss 0.0000726, train_acc 99.97%, test_acc 92.96%
Fine tuning epoch 140 (scheduling like it's 180): loss 0.0000676, train_acc 99.96%, test_acc 93.01%
Fine tuning epoch 141 (scheduling like it's 181): loss 0.0000759, train_acc 99.98%, test_acc 92.95%
Fine tuning epoch 142 (scheduling like it's 182): loss 0.0000728, train_acc 99.97%, test_acc 93.02%
Fine tuning epoch 143 (scheduling like it's 183): loss 0.0000732, train_acc 99.96%, test_acc 93.00%
Fine tuning epoch 144 (scheduling like it's 184): loss 0.0000704, train_acc 99.96%, test_acc 93.10%
Fine tuning epoch 145 (scheduling like it's 185): loss 0.0000716, train_acc 99.95%, test_acc 93.11%
Fine tuning epoch 146 (scheduling like it's 186): loss 0.0000650, train_acc 99.96%, test_acc 93.06%
Fine tuning epoch 147 (scheduling like it's 187): loss 0.0000615, train_acc 99.95%, test_acc 93.09%
Fine tuning epoch 148 (scheduling like it's 188): loss 0.0000667, train_acc 99.96%, test_acc 93.06%
Fine tuning epoch 149 (scheduling like it's 189): loss 0.0000675, train_acc 99.97%, test_acc 93.00%
Fine tuning epoch 150 (scheduling like it's 190): loss 0.0000625, train_acc 99.95%, test_acc 92.95%
Fine tuning epoch 151 (scheduling like it's 191): loss 0.0000612, train_acc 99.97%, test_acc 93.00%
Fine tuning epoch 152 (scheduling like it's 192): loss 0.0000622, train_acc 99.97%, test_acc 93.06%
Fine tuning epoch 153 (scheduling like it's 193): loss 0.0000583, train_acc 99.96%, test_acc 93.10%
Fine tuning epoch 154 (scheduling like it's 194): loss 0.0000643, train_acc 99.98%, test_acc 93.05%
Fine tuning epoch 155 (scheduling like it's 195): loss 0.0000683, train_acc 99.97%, test_acc 93.10%
Fine tuning epoch 156 (scheduling like it's 196): loss 0.0000589, train_acc 99.96%, test_acc 93.02%
Fine tuning epoch 157 (scheduling like it's 197): loss 0.0000625, train_acc 99.98%, test_acc 93.07%
Fine tuning epoch 158 (scheduling like it's 198): loss 0.0000649, train_acc 99.97%, test_acc 93.02%
Fine tuning epoch 159 (scheduling like it's 199): loss 0.0000823, train_acc 99.96%, test_acc 92.93%
