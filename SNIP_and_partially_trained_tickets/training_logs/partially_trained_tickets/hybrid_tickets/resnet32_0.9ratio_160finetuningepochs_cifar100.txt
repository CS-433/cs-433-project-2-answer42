 => Using seed 2020
 => Using device: cuda
Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./cifar100/cifar-100-python.tar.gz
Extracting ./cifar100/cifar-100-python.tar.gz to ./cifar100
Files already downloaded and verified
 => Loading model '/content/drive/MyDrive/pruningData/partially_trained/pretrained_models/resnet32_160_40_cifar100_basic_pretraining_model.pt'
 => Pruning (keeping 10.0% weights)
===> smart ratios before rearanging: 0.854, 0.804, 0.755, 0.708, 0.662, 0.618, 0.575, 0.534, 0.495, 0.457, 0.420, 0.385, 0.352, 0.320, 0.289, 0.260, 0.233, 0.207, 0.183, 0.160, 0.139, 0.119, 0.100, 0.084, 0.069, 0.055, 0.043, 0.032, 0.023, 0.015, 0.009, 0.005, 0.002, 0.300
===> smart ratios: 0.854, 0.804, 0.755, 0.708, 0.662, 0.618, 0.575, 0.534, 0.495, 0.457, 0.420, 0.385, 0.352, 0.320, 0.289, 0.260, 0.233, 0.207, 0.183, 0.160, 0.139, 0.119, 0.100, 0.084, 0.069, 0.055, 0.043, 0.032, 0.023, 0.015, 0.009, 0.005, 0.002, 0.300
===> total keep ratio: 0.09999999999999996
=> Using a preset learning rate schedule:
{0: 0.1, 80: 0.010000000000000002, 120: 0.001}
Fine tuning epoch 0 (scheduling like it's 40): loss 0.0286100, train_acc 54.04%, test_acc 50.49%
Fine tuning epoch 1 (scheduling like it's 41): loss 0.0229978, train_acc 56.71%, test_acc 53.06%
Fine tuning epoch 2 (scheduling like it's 42): loss 0.0214035, train_acc 59.96%, test_acc 54.84%
Fine tuning epoch 3 (scheduling like it's 43): loss 0.0206221, train_acc 63.04%, test_acc 58.34%
Fine tuning epoch 4 (scheduling like it's 44): loss 0.0198280, train_acc 61.81%, test_acc 56.50%
Fine tuning epoch 5 (scheduling like it's 45): loss 0.0194946, train_acc 65.94%, test_acc 59.83%
Fine tuning epoch 6 (scheduling like it's 46): loss 0.0190270, train_acc 62.95%, test_acc 56.24%
Fine tuning epoch 7 (scheduling like it's 47): loss 0.0188825, train_acc 61.79%, test_acc 56.05%
Fine tuning epoch 8 (scheduling like it's 48): loss 0.0186144, train_acc 64.06%, test_acc 57.89%
Fine tuning epoch 9 (scheduling like it's 49): loss 0.0183553, train_acc 65.67%, test_acc 59.12%
Fine tuning epoch 10 (scheduling like it's 50): loss 0.0182787, train_acc 62.83%, test_acc 56.97%
Fine tuning epoch 11 (scheduling like it's 51): loss 0.0182174, train_acc 62.96%, test_acc 56.81%
Fine tuning epoch 12 (scheduling like it's 52): loss 0.0180360, train_acc 64.57%, test_acc 57.25%
Fine tuning epoch 13 (scheduling like it's 53): loss 0.0178171, train_acc 67.21%, test_acc 60.41%
Fine tuning epoch 14 (scheduling like it's 54): loss 0.0177902, train_acc 64.75%, test_acc 59.08%
Fine tuning epoch 15 (scheduling like it's 55): loss 0.0178908, train_acc 66.25%, test_acc 59.97%
Fine tuning epoch 16 (scheduling like it's 56): loss 0.0177324, train_acc 66.54%, test_acc 60.54%
Fine tuning epoch 17 (scheduling like it's 57): loss 0.0175632, train_acc 66.63%, test_acc 59.97%
Fine tuning epoch 18 (scheduling like it's 58): loss 0.0175634, train_acc 64.47%, test_acc 58.78%
Fine tuning epoch 19 (scheduling like it's 59): loss 0.0174710, train_acc 65.24%, test_acc 58.80%
Fine tuning epoch 20 (scheduling like it's 60): loss 0.0175381, train_acc 66.61%, test_acc 60.23%
Fine tuning epoch 21 (scheduling like it's 61): loss 0.0174637, train_acc 66.02%, test_acc 59.36%
Fine tuning epoch 22 (scheduling like it's 62): loss 0.0175057, train_acc 66.16%, test_acc 59.09%
Fine tuning epoch 23 (scheduling like it's 63): loss 0.0174664, train_acc 65.44%, test_acc 58.45%
Fine tuning epoch 24 (scheduling like it's 64): loss 0.0174077, train_acc 64.58%, test_acc 58.17%
Fine tuning epoch 25 (scheduling like it's 65): loss 0.0174055, train_acc 67.11%, test_acc 60.08%
Fine tuning epoch 26 (scheduling like it's 66): loss 0.0172729, train_acc 68.09%, test_acc 60.95%
Fine tuning epoch 27 (scheduling like it's 67): loss 0.0173985, train_acc 67.95%, test_acc 61.38%
Fine tuning epoch 28 (scheduling like it's 68): loss 0.0172949, train_acc 65.91%, test_acc 58.93%
Fine tuning epoch 29 (scheduling like it's 69): loss 0.0172634, train_acc 68.13%, test_acc 60.85%
Fine tuning epoch 30 (scheduling like it's 70): loss 0.0172743, train_acc 67.29%, test_acc 59.90%
Fine tuning epoch 31 (scheduling like it's 71): loss 0.0172321, train_acc 67.09%, test_acc 60.91%
Fine tuning epoch 32 (scheduling like it's 72): loss 0.0172596, train_acc 64.72%, test_acc 58.96%
Fine tuning epoch 33 (scheduling like it's 73): loss 0.0171860, train_acc 68.08%, test_acc 60.33%
Fine tuning epoch 34 (scheduling like it's 74): loss 0.0171864, train_acc 67.41%, test_acc 60.20%
Fine tuning epoch 35 (scheduling like it's 75): loss 0.0172172, train_acc 68.20%, test_acc 61.26%
Fine tuning epoch 36 (scheduling like it's 76): loss 0.0171036, train_acc 66.37%, test_acc 59.25%
Fine tuning epoch 37 (scheduling like it's 77): loss 0.0171442, train_acc 65.95%, test_acc 58.99%
Fine tuning epoch 38 (scheduling like it's 78): loss 0.0171970, train_acc 68.04%, test_acc 59.96%
Fine tuning epoch 39 (scheduling like it's 79): loss 0.0171639, train_acc 68.15%, test_acc 61.12%
Fine tuning epoch 40 (scheduling like it's 80): loss 0.0128335, train_acc 79.31%, test_acc 70.20%
Fine tuning epoch 41 (scheduling like it's 81): loss 0.0116159, train_acc 80.29%, test_acc 69.83%
Fine tuning epoch 42 (scheduling like it's 82): loss 0.0111888, train_acc 80.98%, test_acc 70.41%
Fine tuning epoch 43 (scheduling like it's 83): loss 0.0108238, train_acc 81.47%, test_acc 70.56%
Fine tuning epoch 44 (scheduling like it's 84): loss 0.0106525, train_acc 81.90%, test_acc 70.67%
Fine tuning epoch 45 (scheduling like it's 85): loss 0.0103976, train_acc 82.30%, test_acc 70.54%
Fine tuning epoch 46 (scheduling like it's 86): loss 0.0102145, train_acc 82.51%, test_acc 70.77%
Fine tuning epoch 47 (scheduling like it's 87): loss 0.0100716, train_acc 82.91%, test_acc 70.53%
Fine tuning epoch 48 (scheduling like it's 88): loss 0.0099764, train_acc 82.96%, test_acc 70.62%
Fine tuning epoch 49 (scheduling like it's 89): loss 0.0098766, train_acc 83.30%, test_acc 70.38%
Fine tuning epoch 50 (scheduling like it's 90): loss 0.0096905, train_acc 83.38%, test_acc 70.35%
Fine tuning epoch 51 (scheduling like it's 91): loss 0.0095948, train_acc 83.59%, test_acc 70.66%
Fine tuning epoch 52 (scheduling like it's 92): loss 0.0095010, train_acc 83.79%, test_acc 70.57%
Fine tuning epoch 53 (scheduling like it's 93): loss 0.0094449, train_acc 83.93%, test_acc 70.63%
Fine tuning epoch 54 (scheduling like it's 94): loss 0.0093297, train_acc 84.34%, test_acc 70.48%
Fine tuning epoch 55 (scheduling like it's 95): loss 0.0093456, train_acc 84.35%, test_acc 70.13%
Fine tuning epoch 56 (scheduling like it's 96): loss 0.0092372, train_acc 84.55%, test_acc 70.60%
Fine tuning epoch 57 (scheduling like it's 97): loss 0.0091502, train_acc 84.43%, test_acc 69.85%
Fine tuning epoch 58 (scheduling like it's 98): loss 0.0090656, train_acc 84.47%, test_acc 70.10%
Fine tuning epoch 59 (scheduling like it's 99): loss 0.0090137, train_acc 84.94%, test_acc 70.73%
Fine tuning epoch 60 (scheduling like it's 100): loss 0.0089820, train_acc 84.68%, test_acc 70.32%
Fine tuning epoch 61 (scheduling like it's 101): loss 0.0089567, train_acc 84.94%, test_acc 69.99%
Fine tuning epoch 62 (scheduling like it's 102): loss 0.0089134, train_acc 85.15%, test_acc 70.33%
Fine tuning epoch 63 (scheduling like it's 103): loss 0.0088147, train_acc 85.22%, test_acc 70.05%
Fine tuning epoch 64 (scheduling like it's 104): loss 0.0087938, train_acc 85.17%, test_acc 69.72%
Fine tuning epoch 65 (scheduling like it's 105): loss 0.0087840, train_acc 85.29%, test_acc 69.39%
Fine tuning epoch 66 (scheduling like it's 106): loss 0.0087566, train_acc 85.32%, test_acc 69.53%
Fine tuning epoch 67 (scheduling like it's 107): loss 0.0086667, train_acc 85.44%, test_acc 69.80%
Fine tuning epoch 68 (scheduling like it's 108): loss 0.0087044, train_acc 85.50%, test_acc 69.66%
Fine tuning epoch 69 (scheduling like it's 109): loss 0.0086356, train_acc 85.42%, test_acc 70.02%
Fine tuning epoch 70 (scheduling like it's 110): loss 0.0085758, train_acc 85.78%, test_acc 69.34%
Fine tuning epoch 71 (scheduling like it's 111): loss 0.0086412, train_acc 85.31%, test_acc 69.54%
Fine tuning epoch 72 (scheduling like it's 112): loss 0.0085691, train_acc 85.36%, test_acc 69.65%
Fine tuning epoch 73 (scheduling like it's 113): loss 0.0085355, train_acc 85.53%, test_acc 69.32%
Fine tuning epoch 74 (scheduling like it's 114): loss 0.0085437, train_acc 85.64%, test_acc 69.36%
Fine tuning epoch 75 (scheduling like it's 115): loss 0.0085214, train_acc 85.39%, test_acc 69.81%
Fine tuning epoch 76 (scheduling like it's 116): loss 0.0085233, train_acc 85.87%, test_acc 69.12%
Fine tuning epoch 77 (scheduling like it's 117): loss 0.0085101, train_acc 85.61%, test_acc 69.43%
Fine tuning epoch 78 (scheduling like it's 118): loss 0.0084563, train_acc 85.86%, test_acc 69.31%
Fine tuning epoch 79 (scheduling like it's 119): loss 0.0084736, train_acc 85.99%, test_acc 69.65%
Fine tuning epoch 80 (scheduling like it's 120): loss 0.0074732, train_acc 87.89%, test_acc 70.20%
Fine tuning epoch 81 (scheduling like it's 121): loss 0.0071775, train_acc 88.19%, test_acc 70.38%
Fine tuning epoch 82 (scheduling like it's 122): loss 0.0070459, train_acc 88.52%, test_acc 70.41%
Fine tuning epoch 83 (scheduling like it's 123): loss 0.0069786, train_acc 88.46%, test_acc 70.57%
Fine tuning epoch 84 (scheduling like it's 124): loss 0.0069802, train_acc 88.64%, test_acc 70.40%
Fine tuning epoch 85 (scheduling like it's 125): loss 0.0069532, train_acc 88.80%, test_acc 70.66%
Fine tuning epoch 86 (scheduling like it's 126): loss 0.0068295, train_acc 88.90%, test_acc 70.66%
Fine tuning epoch 87 (scheduling like it's 127): loss 0.0068706, train_acc 88.89%, test_acc 70.43%
Fine tuning epoch 88 (scheduling like it's 128): loss 0.0068077, train_acc 88.84%, test_acc 70.34%
Fine tuning epoch 89 (scheduling like it's 129): loss 0.0068075, train_acc 89.01%, test_acc 70.17%
Fine tuning epoch 90 (scheduling like it's 130): loss 0.0067787, train_acc 89.18%, test_acc 70.35%
Fine tuning epoch 91 (scheduling like it's 131): loss 0.0067213, train_acc 89.18%, test_acc 70.64%
Fine tuning epoch 92 (scheduling like it's 132): loss 0.0066669, train_acc 89.03%, test_acc 70.54%
Fine tuning epoch 93 (scheduling like it's 133): loss 0.0067077, train_acc 89.02%, test_acc 70.55%
Fine tuning epoch 94 (scheduling like it's 134): loss 0.0066319, train_acc 89.25%, test_acc 70.59%
Fine tuning epoch 95 (scheduling like it's 135): loss 0.0066161, train_acc 89.06%, test_acc 70.40%
Fine tuning epoch 96 (scheduling like it's 136): loss 0.0066269, train_acc 89.33%, test_acc 70.57%
Fine tuning epoch 97 (scheduling like it's 137): loss 0.0066219, train_acc 89.13%, test_acc 70.11%
Fine tuning epoch 98 (scheduling like it's 138): loss 0.0066239, train_acc 89.40%, test_acc 70.29%
Fine tuning epoch 99 (scheduling like it's 139): loss 0.0065348, train_acc 89.07%, test_acc 70.34%
Fine tuning epoch 100 (scheduling like it's 140): loss 0.0065494, train_acc 89.53%, test_acc 70.08%
Fine tuning epoch 101 (scheduling like it's 141): loss 0.0065524, train_acc 89.59%, test_acc 70.03%
Fine tuning epoch 102 (scheduling like it's 142): loss 0.0066242, train_acc 89.72%, test_acc 70.20%
Fine tuning epoch 103 (scheduling like it's 143): loss 0.0065845, train_acc 89.41%, test_acc 70.24%
Fine tuning epoch 104 (scheduling like it's 144): loss 0.0064981, train_acc 89.36%, test_acc 70.28%
Fine tuning epoch 105 (scheduling like it's 145): loss 0.0064400, train_acc 89.76%, test_acc 70.26%
Fine tuning epoch 106 (scheduling like it's 146): loss 0.0064298, train_acc 89.57%, test_acc 70.39%
Fine tuning epoch 107 (scheduling like it's 147): loss 0.0064806, train_acc 89.51%, test_acc 70.27%
Fine tuning epoch 108 (scheduling like it's 148): loss 0.0064009, train_acc 89.61%, test_acc 70.46%
Fine tuning epoch 109 (scheduling like it's 149): loss 0.0064342, train_acc 89.56%, test_acc 70.39%
Fine tuning epoch 110 (scheduling like it's 150): loss 0.0064339, train_acc 89.77%, test_acc 70.55%
Fine tuning epoch 111 (scheduling like it's 151): loss 0.0064415, train_acc 89.65%, test_acc 70.40%
Fine tuning epoch 112 (scheduling like it's 152): loss 0.0064046, train_acc 89.65%, test_acc 70.56%
Fine tuning epoch 113 (scheduling like it's 153): loss 0.0063665, train_acc 89.63%, test_acc 70.51%
Fine tuning epoch 114 (scheduling like it's 154): loss 0.0063885, train_acc 89.81%, test_acc 70.45%
Fine tuning epoch 115 (scheduling like it's 155): loss 0.0063744, train_acc 89.82%, test_acc 70.46%
Fine tuning epoch 116 (scheduling like it's 156): loss 0.0063675, train_acc 89.85%, test_acc 70.45%
Fine tuning epoch 117 (scheduling like it's 157): loss 0.0063223, train_acc 90.01%, test_acc 70.34%
Fine tuning epoch 118 (scheduling like it's 158): loss 0.0063481, train_acc 89.88%, test_acc 70.24%
Fine tuning epoch 119 (scheduling like it's 159): loss 0.0062439, train_acc 89.99%, test_acc 70.45%
Fine tuning epoch 120 (scheduling like it's 160): loss 0.0063014, train_acc 89.61%, test_acc 70.25%
Fine tuning epoch 121 (scheduling like it's 161): loss 0.0063013, train_acc 90.05%, test_acc 70.36%
Fine tuning epoch 122 (scheduling like it's 162): loss 0.0063058, train_acc 89.97%, test_acc 70.20%
Fine tuning epoch 123 (scheduling like it's 163): loss 0.0063002, train_acc 89.92%, test_acc 70.24%
Fine tuning epoch 124 (scheduling like it's 164): loss 0.0062030, train_acc 90.01%, test_acc 70.29%
Fine tuning epoch 125 (scheduling like it's 165): loss 0.0061944, train_acc 89.88%, test_acc 70.39%
Fine tuning epoch 126 (scheduling like it's 166): loss 0.0062653, train_acc 89.93%, test_acc 70.34%
Fine tuning epoch 127 (scheduling like it's 167): loss 0.0062009, train_acc 89.95%, test_acc 70.36%
Fine tuning epoch 128 (scheduling like it's 168): loss 0.0062396, train_acc 90.22%, test_acc 70.35%
Fine tuning epoch 129 (scheduling like it's 169): loss 0.0062145, train_acc 89.97%, test_acc 70.28%
Fine tuning epoch 130 (scheduling like it's 170): loss 0.0062441, train_acc 90.13%, test_acc 70.40%
Fine tuning epoch 131 (scheduling like it's 171): loss 0.0062445, train_acc 90.16%, test_acc 70.34%
Fine tuning epoch 132 (scheduling like it's 172): loss 0.0061680, train_acc 90.31%, test_acc 70.46%
Fine tuning epoch 133 (scheduling like it's 173): loss 0.0061656, train_acc 90.28%, test_acc 70.32%
Fine tuning epoch 134 (scheduling like it's 174): loss 0.0061432, train_acc 90.21%, test_acc 70.15%
Fine tuning epoch 135 (scheduling like it's 175): loss 0.0062178, train_acc 90.15%, test_acc 70.11%
Fine tuning epoch 136 (scheduling like it's 176): loss 0.0061703, train_acc 90.37%, test_acc 70.32%
Fine tuning epoch 137 (scheduling like it's 177): loss 0.0061189, train_acc 90.19%, test_acc 70.33%
Fine tuning epoch 138 (scheduling like it's 178): loss 0.0061208, train_acc 90.28%, test_acc 70.09%
Fine tuning epoch 139 (scheduling like it's 179): loss 0.0060781, train_acc 90.35%, test_acc 70.41%
Fine tuning epoch 140 (scheduling like it's 180): loss 0.0061128, train_acc 90.37%, test_acc 70.03%
Fine tuning epoch 141 (scheduling like it's 181): loss 0.0061131, train_acc 90.43%, test_acc 70.34%
Fine tuning epoch 142 (scheduling like it's 182): loss 0.0061229, train_acc 90.68%, test_acc 70.38%
Fine tuning epoch 143 (scheduling like it's 183): loss 0.0060877, train_acc 90.26%, test_acc 70.10%
Fine tuning epoch 144 (scheduling like it's 184): loss 0.0060179, train_acc 90.40%, test_acc 70.14%
Fine tuning epoch 145 (scheduling like it's 185): loss 0.0060888, train_acc 90.56%, test_acc 70.21%
Fine tuning epoch 146 (scheduling like it's 186): loss 0.0060440, train_acc 90.48%, test_acc 69.82%
Fine tuning epoch 147 (scheduling like it's 187): loss 0.0060466, train_acc 90.39%, test_acc 70.09%
Fine tuning epoch 148 (scheduling like it's 188): loss 0.0060815, train_acc 90.53%, test_acc 70.41%
Fine tuning epoch 149 (scheduling like it's 189): loss 0.0060672, train_acc 90.59%, test_acc 70.25%
Fine tuning epoch 150 (scheduling like it's 190): loss 0.0060237, train_acc 90.56%, test_acc 70.13%
Fine tuning epoch 151 (scheduling like it's 191): loss 0.0059839, train_acc 90.58%, test_acc 70.13%
Fine tuning epoch 152 (scheduling like it's 192): loss 0.0060887, train_acc 90.37%, test_acc 70.08%
Fine tuning epoch 153 (scheduling like it's 193): loss 0.0059889, train_acc 90.55%, test_acc 70.16%
Fine tuning epoch 154 (scheduling like it's 194): loss 0.0059965, train_acc 90.67%, test_acc 70.30%
Fine tuning epoch 155 (scheduling like it's 195): loss 0.0059723, train_acc 90.76%, test_acc 69.93%
Fine tuning epoch 156 (scheduling like it's 196): loss 0.0060216, train_acc 90.70%, test_acc 69.92%
Fine tuning epoch 157 (scheduling like it's 197): loss 0.0059754, train_acc 90.63%, test_acc 70.14%
Fine tuning epoch 158 (scheduling like it's 198): loss 0.0059187, train_acc 90.76%, test_acc 70.14%
Fine tuning epoch 159 (scheduling like it's 199): loss 0.0059372, train_acc 90.93%, test_acc 69.95%
