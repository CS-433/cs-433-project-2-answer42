 => Using seed 2020
 => Using device: cuda
Files already downloaded and verified
Files already downloaded and verified
 => Loading model '/content/drive/MyDrive/pruningData/partially_trained/pretrained_models/resnet32_160_40_cifar10_basic_pretraining_model.pt'
 => Pruning (keeping 2.0% weights)
===> smart ratios before rearanging: 0.172, 0.161, 0.152, 0.142, 0.133, 0.124, 0.116, 0.107, 0.099, 0.092, 0.084, 0.077, 0.071, 0.064, 0.058, 0.052, 0.047, 0.042, 0.037, 0.032, 0.028, 0.024, 0.020, 0.017, 0.014, 0.011, 0.009, 0.006, 0.005, 0.003, 0.002, 0.001, 0.000, 0.300
===> smart ratios: 0.172, 0.161, 0.152, 0.142, 0.133, 0.124, 0.116, 0.107, 0.099, 0.092, 0.084, 0.077, 0.071, 0.064, 0.058, 0.052, 0.047, 0.042, 0.037, 0.032, 0.028, 0.024, 0.020, 0.017, 0.014, 0.011, 0.009, 0.006, 0.005, 0.003, 0.002, 0.001, 0.000, 0.300
===> total keep ratio: 0.020000000000000014
=> Using a preset learning rate schedule:
{0: 0.1, 80: 0.010000000000000002, 120: 0.001}
Fine tuning epoch 0 (scheduling like it's 40): loss 0.0130797, train_acc 75.16%, test_acc 74.42%
Fine tuning epoch 1 (scheduling like it's 41): loss 0.0095181, train_acc 75.46%, test_acc 73.09%
Fine tuning epoch 2 (scheduling like it's 42): loss 0.0086405, train_acc 80.10%, test_acc 79.25%
Fine tuning epoch 3 (scheduling like it's 43): loss 0.0079405, train_acc 83.90%, test_acc 82.54%
Fine tuning epoch 4 (scheduling like it's 44): loss 0.0076823, train_acc 82.32%, test_acc 80.92%
Fine tuning epoch 5 (scheduling like it's 45): loss 0.0073859, train_acc 83.21%, test_acc 81.67%
Fine tuning epoch 6 (scheduling like it's 46): loss 0.0072332, train_acc 82.80%, test_acc 81.51%
Fine tuning epoch 7 (scheduling like it's 47): loss 0.0070757, train_acc 86.03%, test_acc 84.78%
Fine tuning epoch 8 (scheduling like it's 48): loss 0.0068852, train_acc 85.27%, test_acc 83.15%
Fine tuning epoch 9 (scheduling like it's 49): loss 0.0068702, train_acc 83.32%, test_acc 82.21%
Fine tuning epoch 10 (scheduling like it's 50): loss 0.0067483, train_acc 87.01%, test_acc 84.99%
Fine tuning epoch 11 (scheduling like it's 51): loss 0.0067665, train_acc 86.52%, test_acc 84.64%
Fine tuning epoch 12 (scheduling like it's 52): loss 0.0065598, train_acc 83.56%, test_acc 81.23%
Fine tuning epoch 13 (scheduling like it's 53): loss 0.0065687, train_acc 84.35%, test_acc 82.40%
Fine tuning epoch 14 (scheduling like it's 54): loss 0.0065761, train_acc 82.89%, test_acc 80.55%
Fine tuning epoch 15 (scheduling like it's 55): loss 0.0065421, train_acc 85.96%, test_acc 83.63%
Fine tuning epoch 16 (scheduling like it's 56): loss 0.0064619, train_acc 83.15%, test_acc 80.99%
Fine tuning epoch 17 (scheduling like it's 57): loss 0.0064779, train_acc 80.61%, test_acc 78.62%
Fine tuning epoch 18 (scheduling like it's 58): loss 0.0064294, train_acc 83.81%, test_acc 81.57%
Fine tuning epoch 19 (scheduling like it's 59): loss 0.0063881, train_acc 81.08%, test_acc 79.35%
Fine tuning epoch 20 (scheduling like it's 60): loss 0.0064060, train_acc 84.08%, test_acc 82.06%
Fine tuning epoch 21 (scheduling like it's 61): loss 0.0063242, train_acc 82.88%, test_acc 80.47%
Fine tuning epoch 22 (scheduling like it's 62): loss 0.0063710, train_acc 84.94%, test_acc 82.87%
Fine tuning epoch 23 (scheduling like it's 63): loss 0.0063297, train_acc 84.38%, test_acc 82.32%
Fine tuning epoch 24 (scheduling like it's 64): loss 0.0063481, train_acc 86.04%, test_acc 84.88%
Fine tuning epoch 25 (scheduling like it's 65): loss 0.0062617, train_acc 83.42%, test_acc 82.60%
Fine tuning epoch 26 (scheduling like it's 66): loss 0.0062841, train_acc 84.40%, test_acc 82.44%
Fine tuning epoch 27 (scheduling like it's 67): loss 0.0063130, train_acc 82.56%, test_acc 80.48%
Fine tuning epoch 28 (scheduling like it's 68): loss 0.0061959, train_acc 84.31%, test_acc 83.12%
Fine tuning epoch 29 (scheduling like it's 69): loss 0.0061870, train_acc 87.16%, test_acc 85.63%
Fine tuning epoch 30 (scheduling like it's 70): loss 0.0062740, train_acc 85.39%, test_acc 83.68%
Fine tuning epoch 31 (scheduling like it's 71): loss 0.0062161, train_acc 81.27%, test_acc 78.93%
Fine tuning epoch 32 (scheduling like it's 72): loss 0.0062084, train_acc 83.62%, test_acc 81.20%
Fine tuning epoch 33 (scheduling like it's 73): loss 0.0062341, train_acc 86.60%, test_acc 84.59%
Fine tuning epoch 34 (scheduling like it's 74): loss 0.0061553, train_acc 84.73%, test_acc 82.79%
Fine tuning epoch 35 (scheduling like it's 75): loss 0.0061651, train_acc 85.81%, test_acc 84.20%
Fine tuning epoch 36 (scheduling like it's 76): loss 0.0061882, train_acc 87.44%, test_acc 85.82%
Fine tuning epoch 37 (scheduling like it's 77): loss 0.0061424, train_acc 87.27%, test_acc 85.97%
Fine tuning epoch 38 (scheduling like it's 78): loss 0.0061605, train_acc 83.31%, test_acc 81.93%
Fine tuning epoch 39 (scheduling like it's 79): loss 0.0062154, train_acc 84.37%, test_acc 81.81%
Fine tuning epoch 40 (scheduling like it's 80): loss 0.0046886, train_acc 91.85%, test_acc 88.94%
Fine tuning epoch 41 (scheduling like it's 81): loss 0.0041571, train_acc 92.26%, test_acc 89.08%
Fine tuning epoch 42 (scheduling like it's 82): loss 0.0040254, train_acc 92.42%, test_acc 89.42%
Fine tuning epoch 43 (scheduling like it's 83): loss 0.0038189, train_acc 92.60%, test_acc 89.84%
Fine tuning epoch 44 (scheduling like it's 84): loss 0.0038004, train_acc 93.00%, test_acc 89.70%
Fine tuning epoch 45 (scheduling like it's 85): loss 0.0037272, train_acc 93.09%, test_acc 89.86%
Fine tuning epoch 46 (scheduling like it's 86): loss 0.0036100, train_acc 92.97%, test_acc 89.75%
Fine tuning epoch 47 (scheduling like it's 87): loss 0.0036208, train_acc 92.92%, test_acc 89.37%
Fine tuning epoch 48 (scheduling like it's 88): loss 0.0036159, train_acc 93.37%, test_acc 89.81%
Fine tuning epoch 49 (scheduling like it's 89): loss 0.0035571, train_acc 93.37%, test_acc 89.75%
Fine tuning epoch 50 (scheduling like it's 90): loss 0.0034976, train_acc 93.53%, test_acc 89.69%
Fine tuning epoch 51 (scheduling like it's 91): loss 0.0034814, train_acc 93.35%, test_acc 89.77%
Fine tuning epoch 52 (scheduling like it's 92): loss 0.0034305, train_acc 93.69%, test_acc 90.04%
Fine tuning epoch 53 (scheduling like it's 93): loss 0.0034365, train_acc 93.51%, test_acc 89.72%
Fine tuning epoch 54 (scheduling like it's 94): loss 0.0033687, train_acc 93.79%, test_acc 89.85%
Fine tuning epoch 55 (scheduling like it's 95): loss 0.0033272, train_acc 93.51%, test_acc 89.80%
Fine tuning epoch 56 (scheduling like it's 96): loss 0.0033460, train_acc 93.83%, test_acc 89.87%
Fine tuning epoch 57 (scheduling like it's 97): loss 0.0033240, train_acc 93.80%, test_acc 90.04%
Fine tuning epoch 58 (scheduling like it's 98): loss 0.0033280, train_acc 93.75%, test_acc 89.95%
Fine tuning epoch 59 (scheduling like it's 99): loss 0.0033109, train_acc 93.72%, test_acc 89.91%
Fine tuning epoch 60 (scheduling like it's 100): loss 0.0032744, train_acc 93.84%, test_acc 89.76%
Fine tuning epoch 61 (scheduling like it's 101): loss 0.0032678, train_acc 94.07%, test_acc 90.31%
Fine tuning epoch 62 (scheduling like it's 102): loss 0.0032373, train_acc 93.87%, test_acc 89.75%
Fine tuning epoch 63 (scheduling like it's 103): loss 0.0032623, train_acc 94.07%, test_acc 89.77%
Fine tuning epoch 64 (scheduling like it's 104): loss 0.0031773, train_acc 93.88%, test_acc 89.73%
Fine tuning epoch 65 (scheduling like it's 105): loss 0.0032523, train_acc 93.76%, test_acc 89.71%
Fine tuning epoch 66 (scheduling like it's 106): loss 0.0032149, train_acc 93.54%, test_acc 89.81%
Fine tuning epoch 67 (scheduling like it's 107): loss 0.0032222, train_acc 94.28%, test_acc 90.34%
Fine tuning epoch 68 (scheduling like it's 108): loss 0.0031841, train_acc 94.03%, test_acc 90.02%
Fine tuning epoch 69 (scheduling like it's 109): loss 0.0032081, train_acc 93.78%, test_acc 89.46%
Fine tuning epoch 70 (scheduling like it's 110): loss 0.0031531, train_acc 93.79%, test_acc 89.64%
Fine tuning epoch 71 (scheduling like it's 111): loss 0.0031871, train_acc 94.17%, test_acc 89.78%
Fine tuning epoch 72 (scheduling like it's 112): loss 0.0031442, train_acc 94.13%, test_acc 89.51%
Fine tuning epoch 73 (scheduling like it's 113): loss 0.0032045, train_acc 94.09%, test_acc 89.57%
Fine tuning epoch 74 (scheduling like it's 114): loss 0.0031549, train_acc 94.16%, test_acc 89.56%
Fine tuning epoch 75 (scheduling like it's 115): loss 0.0031594, train_acc 93.84%, test_acc 89.54%
Fine tuning epoch 76 (scheduling like it's 116): loss 0.0031608, train_acc 94.15%, test_acc 89.72%
Fine tuning epoch 77 (scheduling like it's 117): loss 0.0031168, train_acc 93.89%, test_acc 89.31%
Fine tuning epoch 78 (scheduling like it's 118): loss 0.0031396, train_acc 94.02%, test_acc 89.83%
Fine tuning epoch 79 (scheduling like it's 119): loss 0.0031211, train_acc 94.08%, test_acc 89.56%
Fine tuning epoch 80 (scheduling like it's 120): loss 0.0028311, train_acc 94.93%, test_acc 90.19%
Fine tuning epoch 81 (scheduling like it's 121): loss 0.0027318, train_acc 95.08%, test_acc 90.28%
Fine tuning epoch 82 (scheduling like it's 122): loss 0.0026935, train_acc 95.24%, test_acc 90.35%
Fine tuning epoch 83 (scheduling like it's 123): loss 0.0026242, train_acc 95.16%, test_acc 90.31%
Fine tuning epoch 84 (scheduling like it's 124): loss 0.0025973, train_acc 95.22%, test_acc 90.32%
Fine tuning epoch 85 (scheduling like it's 125): loss 0.0026001, train_acc 95.35%, test_acc 90.28%
Fine tuning epoch 86 (scheduling like it's 126): loss 0.0025687, train_acc 95.24%, test_acc 90.46%
Fine tuning epoch 87 (scheduling like it's 127): loss 0.0026115, train_acc 95.19%, test_acc 90.43%
Fine tuning epoch 88 (scheduling like it's 128): loss 0.0025796, train_acc 95.35%, test_acc 90.23%
Fine tuning epoch 89 (scheduling like it's 129): loss 0.0025402, train_acc 95.40%, test_acc 90.29%
Fine tuning epoch 90 (scheduling like it's 130): loss 0.0025656, train_acc 95.49%, test_acc 90.43%
Fine tuning epoch 91 (scheduling like it's 131): loss 0.0025696, train_acc 95.43%, test_acc 90.48%
Fine tuning epoch 92 (scheduling like it's 132): loss 0.0025387, train_acc 95.24%, test_acc 90.32%
Fine tuning epoch 93 (scheduling like it's 133): loss 0.0025153, train_acc 95.39%, test_acc 90.44%
Fine tuning epoch 94 (scheduling like it's 134): loss 0.0025424, train_acc 95.39%, test_acc 90.42%
Fine tuning epoch 95 (scheduling like it's 135): loss 0.0025080, train_acc 95.50%, test_acc 90.31%
Fine tuning epoch 96 (scheduling like it's 136): loss 0.0024939, train_acc 95.55%, test_acc 90.38%
Fine tuning epoch 97 (scheduling like it's 137): loss 0.0025073, train_acc 95.50%, test_acc 90.39%
Fine tuning epoch 98 (scheduling like it's 138): loss 0.0024957, train_acc 95.56%, test_acc 90.39%
Fine tuning epoch 99 (scheduling like it's 139): loss 0.0024611, train_acc 95.47%, test_acc 90.41%
Fine tuning epoch 100 (scheduling like it's 140): loss 0.0024378, train_acc 95.49%, test_acc 90.39%
Fine tuning epoch 101 (scheduling like it's 141): loss 0.0024882, train_acc 95.53%, test_acc 90.25%
Fine tuning epoch 102 (scheduling like it's 142): loss 0.0024828, train_acc 95.56%, test_acc 90.37%
Fine tuning epoch 103 (scheduling like it's 143): loss 0.0024594, train_acc 95.52%, test_acc 90.33%
Fine tuning epoch 104 (scheduling like it's 144): loss 0.0024855, train_acc 95.55%, test_acc 90.15%
Fine tuning epoch 105 (scheduling like it's 145): loss 0.0024403, train_acc 95.62%, test_acc 90.08%
Fine tuning epoch 106 (scheduling like it's 146): loss 0.0024801, train_acc 95.56%, test_acc 90.38%
Fine tuning epoch 107 (scheduling like it's 147): loss 0.0024577, train_acc 95.66%, test_acc 90.31%
Fine tuning epoch 108 (scheduling like it's 148): loss 0.0024609, train_acc 95.66%, test_acc 90.41%
Fine tuning epoch 109 (scheduling like it's 149): loss 0.0024068, train_acc 95.53%, test_acc 90.46%
Fine tuning epoch 110 (scheduling like it's 150): loss 0.0024316, train_acc 95.62%, test_acc 90.41%
Fine tuning epoch 111 (scheduling like it's 151): loss 0.0024178, train_acc 95.66%, test_acc 90.30%
Fine tuning epoch 112 (scheduling like it's 152): loss 0.0024600, train_acc 95.73%, test_acc 90.50%
Fine tuning epoch 113 (scheduling like it's 153): loss 0.0024158, train_acc 95.76%, test_acc 90.46%
Fine tuning epoch 114 (scheduling like it's 154): loss 0.0023695, train_acc 95.51%, test_acc 90.43%
Fine tuning epoch 115 (scheduling like it's 155): loss 0.0024031, train_acc 95.65%, test_acc 90.21%
Fine tuning epoch 116 (scheduling like it's 156): loss 0.0023790, train_acc 95.69%, test_acc 90.31%
Fine tuning epoch 117 (scheduling like it's 157): loss 0.0023726, train_acc 95.80%, test_acc 90.41%
Fine tuning epoch 118 (scheduling like it's 158): loss 0.0023932, train_acc 95.62%, test_acc 90.30%
Fine tuning epoch 119 (scheduling like it's 159): loss 0.0024437, train_acc 95.69%, test_acc 90.28%
Fine tuning epoch 120 (scheduling like it's 160): loss 0.0024187, train_acc 95.84%, test_acc 90.33%
Fine tuning epoch 121 (scheduling like it's 161): loss 0.0024095, train_acc 95.70%, test_acc 90.28%
Fine tuning epoch 122 (scheduling like it's 162): loss 0.0023897, train_acc 95.70%, test_acc 90.34%
Fine tuning epoch 123 (scheduling like it's 163): loss 0.0024254, train_acc 95.94%, test_acc 90.52%
Fine tuning epoch 124 (scheduling like it's 164): loss 0.0024154, train_acc 95.73%, test_acc 90.37%
Fine tuning epoch 125 (scheduling like it's 165): loss 0.0023811, train_acc 95.62%, test_acc 90.38%
Fine tuning epoch 126 (scheduling like it's 166): loss 0.0023915, train_acc 95.74%, test_acc 90.46%
Fine tuning epoch 127 (scheduling like it's 167): loss 0.0024065, train_acc 95.81%, test_acc 90.38%
Fine tuning epoch 128 (scheduling like it's 168): loss 0.0023521, train_acc 95.93%, test_acc 90.27%
Fine tuning epoch 129 (scheduling like it's 169): loss 0.0023075, train_acc 95.86%, test_acc 90.45%
Fine tuning epoch 130 (scheduling like it's 170): loss 0.0023662, train_acc 95.79%, test_acc 90.28%
Fine tuning epoch 131 (scheduling like it's 171): loss 0.0024009, train_acc 95.83%, test_acc 90.47%
Fine tuning epoch 132 (scheduling like it's 172): loss 0.0023666, train_acc 95.76%, test_acc 90.30%
Fine tuning epoch 133 (scheduling like it's 173): loss 0.0023746, train_acc 95.86%, test_acc 90.30%
Fine tuning epoch 134 (scheduling like it's 174): loss 0.0023161, train_acc 95.87%, test_acc 90.34%
Fine tuning epoch 135 (scheduling like it's 175): loss 0.0023876, train_acc 95.86%, test_acc 90.30%
Fine tuning epoch 136 (scheduling like it's 176): loss 0.0023474, train_acc 95.80%, test_acc 90.18%
Fine tuning epoch 137 (scheduling like it's 177): loss 0.0023371, train_acc 95.88%, test_acc 90.54%
Fine tuning epoch 138 (scheduling like it's 178): loss 0.0023537, train_acc 95.86%, test_acc 90.52%
Fine tuning epoch 139 (scheduling like it's 179): loss 0.0023139, train_acc 95.78%, test_acc 90.35%
Fine tuning epoch 140 (scheduling like it's 180): loss 0.0023082, train_acc 95.91%, test_acc 90.28%
Fine tuning epoch 141 (scheduling like it's 181): loss 0.0023174, train_acc 95.78%, test_acc 90.26%
Fine tuning epoch 142 (scheduling like it's 182): loss 0.0023109, train_acc 96.01%, test_acc 90.50%
Fine tuning epoch 143 (scheduling like it's 183): loss 0.0023152, train_acc 95.93%, test_acc 90.48%
Fine tuning epoch 144 (scheduling like it's 184): loss 0.0023525, train_acc 95.86%, test_acc 90.23%
Fine tuning epoch 145 (scheduling like it's 185): loss 0.0023322, train_acc 95.88%, test_acc 90.25%
Fine tuning epoch 146 (scheduling like it's 186): loss 0.0023767, train_acc 95.87%, test_acc 90.15%
Fine tuning epoch 147 (scheduling like it's 187): loss 0.0023152, train_acc 95.98%, test_acc 90.41%
Fine tuning epoch 148 (scheduling like it's 188): loss 0.0023119, train_acc 95.77%, test_acc 90.27%
Fine tuning epoch 149 (scheduling like it's 189): loss 0.0023246, train_acc 96.05%, test_acc 90.30%
Fine tuning epoch 150 (scheduling like it's 190): loss 0.0022872, train_acc 95.89%, test_acc 90.44%
Fine tuning epoch 151 (scheduling like it's 191): loss 0.0022469, train_acc 96.02%, test_acc 90.34%
Fine tuning epoch 152 (scheduling like it's 192): loss 0.0022804, train_acc 95.95%, test_acc 90.34%
Fine tuning epoch 153 (scheduling like it's 193): loss 0.0023219, train_acc 96.04%, test_acc 90.36%
Fine tuning epoch 154 (scheduling like it's 194): loss 0.0023147, train_acc 96.02%, test_acc 90.47%
Fine tuning epoch 155 (scheduling like it's 195): loss 0.0022950, train_acc 95.91%, test_acc 90.21%
Fine tuning epoch 156 (scheduling like it's 196): loss 0.0022650, train_acc 96.03%, test_acc 90.20%
Fine tuning epoch 157 (scheduling like it's 197): loss 0.0023037, train_acc 95.89%, test_acc 90.21%
Fine tuning epoch 158 (scheduling like it's 198): loss 0.0023013, train_acc 96.15%, test_acc 90.32%
Fine tuning epoch 159 (scheduling like it's 199): loss 0.0022353, train_acc 95.92%, test_acc 90.47%
