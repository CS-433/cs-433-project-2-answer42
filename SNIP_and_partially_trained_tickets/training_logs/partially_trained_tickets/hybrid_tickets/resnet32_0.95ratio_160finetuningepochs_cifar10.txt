 => Using seed 2020
 => Using device: cuda
Files already downloaded and verified
Files already downloaded and verified
 => Loading model '/content/drive/MyDrive/pruningData/partially_trained/pretrained_models/resnet32_160_40_cifar10_basic_pretraining_model.pt'
 => Pruning (keeping 5.0% weights)
===> smart ratios before rearanging: 0.432, 0.406, 0.382, 0.358, 0.335, 0.312, 0.291, 0.270, 0.250, 0.231, 0.212, 0.195, 0.178, 0.162, 0.146, 0.132, 0.118, 0.105, 0.092, 0.081, 0.070, 0.060, 0.051, 0.042, 0.035, 0.028, 0.022, 0.016, 0.012, 0.008, 0.005, 0.002, 0.001, 0.300
===> smart ratios: 0.432, 0.406, 0.382, 0.358, 0.335, 0.312, 0.291, 0.270, 0.250, 0.231, 0.212, 0.195, 0.178, 0.162, 0.146, 0.132, 0.118, 0.105, 0.092, 0.081, 0.070, 0.060, 0.051, 0.042, 0.035, 0.028, 0.022, 0.016, 0.012, 0.008, 0.005, 0.002, 0.001, 0.300
===> total keep ratio: 0.05000000000000004
=> Using a preset learning rate schedule:
{0: 0.1, 80: 0.010000000000000002, 120: 0.001}
Fine tuning epoch 0 (scheduling like it's 40): loss 0.0093112, train_acc 82.09%, test_acc 80.83%
Fine tuning epoch 1 (scheduling like it's 41): loss 0.0067773, train_acc 78.08%, test_acc 75.91%
Fine tuning epoch 2 (scheduling like it's 42): loss 0.0061744, train_acc 86.18%, test_acc 84.43%
Fine tuning epoch 3 (scheduling like it's 43): loss 0.0056913, train_acc 89.33%, test_acc 86.65%
Fine tuning epoch 4 (scheduling like it's 44): loss 0.0053651, train_acc 89.35%, test_acc 86.90%
Fine tuning epoch 5 (scheduling like it's 45): loss 0.0052056, train_acc 88.60%, test_acc 85.66%
Fine tuning epoch 6 (scheduling like it's 46): loss 0.0050431, train_acc 86.85%, test_acc 83.96%
Fine tuning epoch 7 (scheduling like it's 47): loss 0.0049872, train_acc 89.44%, test_acc 87.08%
Fine tuning epoch 8 (scheduling like it's 48): loss 0.0049346, train_acc 87.49%, test_acc 84.08%
Fine tuning epoch 9 (scheduling like it's 49): loss 0.0048627, train_acc 88.94%, test_acc 86.39%
Fine tuning epoch 10 (scheduling like it's 50): loss 0.0047550, train_acc 90.88%, test_acc 88.04%
Fine tuning epoch 11 (scheduling like it's 51): loss 0.0047362, train_acc 89.64%, test_acc 86.05%
Fine tuning epoch 12 (scheduling like it's 52): loss 0.0046178, train_acc 89.38%, test_acc 86.07%
Fine tuning epoch 13 (scheduling like it's 53): loss 0.0046633, train_acc 90.22%, test_acc 87.05%
Fine tuning epoch 14 (scheduling like it's 54): loss 0.0046270, train_acc 85.41%, test_acc 82.38%
Fine tuning epoch 15 (scheduling like it's 55): loss 0.0046328, train_acc 89.86%, test_acc 87.18%
Fine tuning epoch 16 (scheduling like it's 56): loss 0.0044624, train_acc 88.13%, test_acc 85.59%
Fine tuning epoch 17 (scheduling like it's 57): loss 0.0046057, train_acc 88.21%, test_acc 85.08%
Fine tuning epoch 18 (scheduling like it's 58): loss 0.0045851, train_acc 88.57%, test_acc 85.98%
Fine tuning epoch 19 (scheduling like it's 59): loss 0.0044866, train_acc 86.50%, test_acc 83.55%
Fine tuning epoch 20 (scheduling like it's 60): loss 0.0046046, train_acc 89.57%, test_acc 87.03%
Fine tuning epoch 21 (scheduling like it's 61): loss 0.0044687, train_acc 90.16%, test_acc 86.76%
Fine tuning epoch 22 (scheduling like it's 62): loss 0.0045281, train_acc 86.34%, test_acc 82.92%
Fine tuning epoch 23 (scheduling like it's 63): loss 0.0045257, train_acc 89.82%, test_acc 87.27%
Fine tuning epoch 24 (scheduling like it's 64): loss 0.0045667, train_acc 88.97%, test_acc 86.60%
Fine tuning epoch 25 (scheduling like it's 65): loss 0.0044132, train_acc 87.95%, test_acc 85.87%
Fine tuning epoch 26 (scheduling like it's 66): loss 0.0043754, train_acc 86.70%, test_acc 83.43%
Fine tuning epoch 27 (scheduling like it's 67): loss 0.0045254, train_acc 89.67%, test_acc 87.26%
Fine tuning epoch 28 (scheduling like it's 68): loss 0.0044041, train_acc 90.23%, test_acc 87.12%
Fine tuning epoch 29 (scheduling like it's 69): loss 0.0043857, train_acc 90.13%, test_acc 87.27%
Fine tuning epoch 30 (scheduling like it's 70): loss 0.0044067, train_acc 90.06%, test_acc 87.62%
Fine tuning epoch 31 (scheduling like it's 71): loss 0.0044054, train_acc 86.32%, test_acc 83.54%
Fine tuning epoch 32 (scheduling like it's 72): loss 0.0044391, train_acc 88.69%, test_acc 85.65%
Fine tuning epoch 33 (scheduling like it's 73): loss 0.0044478, train_acc 89.82%, test_acc 87.33%
Fine tuning epoch 34 (scheduling like it's 74): loss 0.0044793, train_acc 88.11%, test_acc 84.98%
Fine tuning epoch 35 (scheduling like it's 75): loss 0.0044650, train_acc 88.53%, test_acc 85.87%
Fine tuning epoch 36 (scheduling like it's 76): loss 0.0043671, train_acc 87.93%, test_acc 85.89%
Fine tuning epoch 37 (scheduling like it's 77): loss 0.0043724, train_acc 88.69%, test_acc 85.27%
Fine tuning epoch 38 (scheduling like it's 78): loss 0.0043482, train_acc 88.99%, test_acc 86.05%
Fine tuning epoch 39 (scheduling like it's 79): loss 0.0044046, train_acc 90.36%, test_acc 87.29%
Fine tuning epoch 40 (scheduling like it's 80): loss 0.0029746, train_acc 95.49%, test_acc 91.78%
Fine tuning epoch 41 (scheduling like it's 81): loss 0.0024267, train_acc 95.96%, test_acc 92.03%
Fine tuning epoch 42 (scheduling like it's 82): loss 0.0022280, train_acc 96.19%, test_acc 92.32%
Fine tuning epoch 43 (scheduling like it's 83): loss 0.0021189, train_acc 96.44%, test_acc 92.58%
Fine tuning epoch 44 (scheduling like it's 84): loss 0.0020414, train_acc 96.63%, test_acc 92.46%
Fine tuning epoch 45 (scheduling like it's 85): loss 0.0020194, train_acc 96.76%, test_acc 92.49%
Fine tuning epoch 46 (scheduling like it's 86): loss 0.0018960, train_acc 96.89%, test_acc 92.46%
Fine tuning epoch 47 (scheduling like it's 87): loss 0.0018457, train_acc 96.93%, test_acc 92.41%
Fine tuning epoch 48 (scheduling like it's 88): loss 0.0017895, train_acc 97.17%, test_acc 92.49%
Fine tuning epoch 49 (scheduling like it's 89): loss 0.0017366, train_acc 97.10%, test_acc 92.56%
Fine tuning epoch 50 (scheduling like it's 90): loss 0.0017031, train_acc 97.31%, test_acc 92.36%
Fine tuning epoch 51 (scheduling like it's 91): loss 0.0016765, train_acc 97.44%, test_acc 92.36%
Fine tuning epoch 52 (scheduling like it's 92): loss 0.0016051, train_acc 97.31%, test_acc 92.23%
Fine tuning epoch 53 (scheduling like it's 93): loss 0.0015590, train_acc 97.43%, test_acc 92.53%
Fine tuning epoch 54 (scheduling like it's 94): loss 0.0015752, train_acc 97.56%, test_acc 92.39%
Fine tuning epoch 55 (scheduling like it's 95): loss 0.0014964, train_acc 97.50%, test_acc 92.47%
Fine tuning epoch 56 (scheduling like it's 96): loss 0.0015306, train_acc 97.66%, test_acc 92.43%
Fine tuning epoch 57 (scheduling like it's 97): loss 0.0014975, train_acc 97.61%, test_acc 92.16%
Fine tuning epoch 58 (scheduling like it's 98): loss 0.0014649, train_acc 97.71%, test_acc 92.50%
Fine tuning epoch 59 (scheduling like it's 99): loss 0.0014668, train_acc 97.81%, test_acc 92.58%
Fine tuning epoch 60 (scheduling like it's 100): loss 0.0014236, train_acc 97.84%, test_acc 92.02%
Fine tuning epoch 61 (scheduling like it's 101): loss 0.0014324, train_acc 97.98%, test_acc 92.34%
Fine tuning epoch 62 (scheduling like it's 102): loss 0.0014194, train_acc 98.02%, test_acc 92.39%
Fine tuning epoch 63 (scheduling like it's 103): loss 0.0013747, train_acc 97.91%, test_acc 92.48%
Fine tuning epoch 64 (scheduling like it's 104): loss 0.0013597, train_acc 98.05%, test_acc 92.24%
Fine tuning epoch 65 (scheduling like it's 105): loss 0.0013780, train_acc 97.89%, test_acc 92.23%
Fine tuning epoch 66 (scheduling like it's 106): loss 0.0013489, train_acc 97.99%, test_acc 92.03%
Fine tuning epoch 67 (scheduling like it's 107): loss 0.0013540, train_acc 98.00%, test_acc 92.40%
Fine tuning epoch 68 (scheduling like it's 108): loss 0.0013068, train_acc 98.07%, test_acc 92.14%
Fine tuning epoch 69 (scheduling like it's 109): loss 0.0013092, train_acc 97.78%, test_acc 92.18%
Fine tuning epoch 70 (scheduling like it's 110): loss 0.0013024, train_acc 97.96%, test_acc 91.90%
Fine tuning epoch 71 (scheduling like it's 111): loss 0.0013023, train_acc 97.97%, test_acc 92.14%
Fine tuning epoch 72 (scheduling like it's 112): loss 0.0012664, train_acc 98.15%, test_acc 92.12%
Fine tuning epoch 73 (scheduling like it's 113): loss 0.0012900, train_acc 97.97%, test_acc 92.28%
Fine tuning epoch 74 (scheduling like it's 114): loss 0.0012551, train_acc 98.08%, test_acc 92.17%
Fine tuning epoch 75 (scheduling like it's 115): loss 0.0012478, train_acc 98.11%, test_acc 92.22%
Fine tuning epoch 76 (scheduling like it's 116): loss 0.0012569, train_acc 98.16%, test_acc 92.23%
Fine tuning epoch 77 (scheduling like it's 117): loss 0.0012750, train_acc 98.14%, test_acc 92.00%
Fine tuning epoch 78 (scheduling like it's 118): loss 0.0012608, train_acc 97.92%, test_acc 91.71%
Fine tuning epoch 79 (scheduling like it's 119): loss 0.0012585, train_acc 98.16%, test_acc 92.00%
Fine tuning epoch 80 (scheduling like it's 120): loss 0.0010483, train_acc 98.61%, test_acc 92.38%
Fine tuning epoch 81 (scheduling like it's 121): loss 0.0009589, train_acc 98.83%, test_acc 92.31%
Fine tuning epoch 82 (scheduling like it's 122): loss 0.0009161, train_acc 98.82%, test_acc 92.34%
Fine tuning epoch 83 (scheduling like it's 123): loss 0.0009018, train_acc 98.93%, test_acc 92.68%
Fine tuning epoch 84 (scheduling like it's 124): loss 0.0008967, train_acc 98.90%, test_acc 92.59%
Fine tuning epoch 85 (scheduling like it's 125): loss 0.0008517, train_acc 99.00%, test_acc 92.74%
Fine tuning epoch 86 (scheduling like it's 126): loss 0.0008461, train_acc 98.94%, test_acc 92.72%
Fine tuning epoch 87 (scheduling like it's 127): loss 0.0008274, train_acc 98.91%, test_acc 92.53%
Fine tuning epoch 88 (scheduling like it's 128): loss 0.0008336, train_acc 98.95%, test_acc 92.75%
Fine tuning epoch 89 (scheduling like it's 129): loss 0.0008274, train_acc 99.06%, test_acc 92.68%
Fine tuning epoch 90 (scheduling like it's 130): loss 0.0008101, train_acc 99.07%, test_acc 92.80%
Fine tuning epoch 91 (scheduling like it's 131): loss 0.0008167, train_acc 99.06%, test_acc 92.71%
Fine tuning epoch 92 (scheduling like it's 132): loss 0.0007889, train_acc 99.00%, test_acc 92.73%
Fine tuning epoch 93 (scheduling like it's 133): loss 0.0008096, train_acc 99.10%, test_acc 92.93%
Fine tuning epoch 94 (scheduling like it's 134): loss 0.0007634, train_acc 99.03%, test_acc 92.62%
Fine tuning epoch 95 (scheduling like it's 135): loss 0.0007923, train_acc 99.07%, test_acc 92.86%
Fine tuning epoch 96 (scheduling like it's 136): loss 0.0007936, train_acc 99.16%, test_acc 92.69%
Fine tuning epoch 97 (scheduling like it's 137): loss 0.0007879, train_acc 99.07%, test_acc 92.84%
Fine tuning epoch 98 (scheduling like it's 138): loss 0.0007635, train_acc 99.10%, test_acc 92.90%
Fine tuning epoch 99 (scheduling like it's 139): loss 0.0007835, train_acc 99.18%, test_acc 92.85%
Fine tuning epoch 100 (scheduling like it's 140): loss 0.0007378, train_acc 99.12%, test_acc 92.80%
Fine tuning epoch 101 (scheduling like it's 141): loss 0.0007603, train_acc 99.14%, test_acc 92.76%
Fine tuning epoch 102 (scheduling like it's 142): loss 0.0007396, train_acc 99.20%, test_acc 92.88%
Fine tuning epoch 103 (scheduling like it's 143): loss 0.0007518, train_acc 99.19%, test_acc 92.74%
Fine tuning epoch 104 (scheduling like it's 144): loss 0.0007615, train_acc 99.14%, test_acc 92.65%
Fine tuning epoch 105 (scheduling like it's 145): loss 0.0007176, train_acc 99.21%, test_acc 92.87%
Fine tuning epoch 106 (scheduling like it's 146): loss 0.0007392, train_acc 99.19%, test_acc 92.76%
Fine tuning epoch 107 (scheduling like it's 147): loss 0.0007560, train_acc 99.22%, test_acc 92.73%
Fine tuning epoch 108 (scheduling like it's 148): loss 0.0007380, train_acc 99.22%, test_acc 92.86%
Fine tuning epoch 109 (scheduling like it's 149): loss 0.0007316, train_acc 99.13%, test_acc 92.55%
Fine tuning epoch 110 (scheduling like it's 150): loss 0.0007009, train_acc 99.07%, test_acc 92.76%
Fine tuning epoch 111 (scheduling like it's 151): loss 0.0007343, train_acc 99.17%, test_acc 92.78%
Fine tuning epoch 112 (scheduling like it's 152): loss 0.0007170, train_acc 99.23%, test_acc 92.72%
Fine tuning epoch 113 (scheduling like it's 153): loss 0.0007293, train_acc 99.20%, test_acc 92.72%
Fine tuning epoch 114 (scheduling like it's 154): loss 0.0006810, train_acc 99.21%, test_acc 92.81%
Fine tuning epoch 115 (scheduling like it's 155): loss 0.0007002, train_acc 99.29%, test_acc 92.82%
Fine tuning epoch 116 (scheduling like it's 156): loss 0.0006984, train_acc 99.18%, test_acc 92.56%
Fine tuning epoch 117 (scheduling like it's 157): loss 0.0006828, train_acc 99.25%, test_acc 92.62%
Fine tuning epoch 118 (scheduling like it's 158): loss 0.0006921, train_acc 99.17%, test_acc 92.55%
Fine tuning epoch 119 (scheduling like it's 159): loss 0.0007036, train_acc 99.27%, test_acc 92.72%
Fine tuning epoch 120 (scheduling like it's 160): loss 0.0007006, train_acc 99.23%, test_acc 92.75%
Fine tuning epoch 121 (scheduling like it's 161): loss 0.0006963, train_acc 99.23%, test_acc 92.80%
Fine tuning epoch 122 (scheduling like it's 162): loss 0.0006858, train_acc 99.29%, test_acc 92.75%
Fine tuning epoch 123 (scheduling like it's 163): loss 0.0006744, train_acc 99.33%, test_acc 92.88%
Fine tuning epoch 124 (scheduling like it's 164): loss 0.0006537, train_acc 99.31%, test_acc 92.48%
Fine tuning epoch 125 (scheduling like it's 165): loss 0.0006676, train_acc 99.23%, test_acc 92.71%
Fine tuning epoch 126 (scheduling like it's 166): loss 0.0006663, train_acc 99.28%, test_acc 92.60%
Fine tuning epoch 127 (scheduling like it's 167): loss 0.0007076, train_acc 99.29%, test_acc 92.64%
Fine tuning epoch 128 (scheduling like it's 168): loss 0.0006613, train_acc 99.33%, test_acc 92.74%
Fine tuning epoch 129 (scheduling like it's 169): loss 0.0006716, train_acc 99.33%, test_acc 92.65%
Fine tuning epoch 130 (scheduling like it's 170): loss 0.0006323, train_acc 99.33%, test_acc 92.76%
Fine tuning epoch 131 (scheduling like it's 171): loss 0.0006386, train_acc 99.32%, test_acc 92.61%
Fine tuning epoch 132 (scheduling like it's 172): loss 0.0006766, train_acc 99.39%, test_acc 92.66%
Fine tuning epoch 133 (scheduling like it's 173): loss 0.0006710, train_acc 99.30%, test_acc 92.81%
Fine tuning epoch 134 (scheduling like it's 174): loss 0.0006504, train_acc 99.36%, test_acc 92.83%
Fine tuning epoch 135 (scheduling like it's 175): loss 0.0006519, train_acc 99.42%, test_acc 92.64%
Fine tuning epoch 136 (scheduling like it's 176): loss 0.0006790, train_acc 99.22%, test_acc 92.57%
Fine tuning epoch 137 (scheduling like it's 177): loss 0.0006565, train_acc 99.34%, test_acc 92.59%
Fine tuning epoch 138 (scheduling like it's 178): loss 0.0006550, train_acc 99.34%, test_acc 92.67%
Fine tuning epoch 139 (scheduling like it's 179): loss 0.0006353, train_acc 99.28%, test_acc 92.69%
Fine tuning epoch 140 (scheduling like it's 180): loss 0.0006135, train_acc 99.36%, test_acc 92.69%
Fine tuning epoch 141 (scheduling like it's 181): loss 0.0006401, train_acc 99.35%, test_acc 92.91%
Fine tuning epoch 142 (scheduling like it's 182): loss 0.0006298, train_acc 99.36%, test_acc 92.67%
Fine tuning epoch 143 (scheduling like it's 183): loss 0.0006468, train_acc 99.34%, test_acc 92.79%
Fine tuning epoch 144 (scheduling like it's 184): loss 0.0006273, train_acc 99.38%, test_acc 92.68%
Fine tuning epoch 145 (scheduling like it's 185): loss 0.0006251, train_acc 99.37%, test_acc 92.60%
Fine tuning epoch 146 (scheduling like it's 186): loss 0.0006356, train_acc 99.37%, test_acc 92.63%
Fine tuning epoch 147 (scheduling like it's 187): loss 0.0006129, train_acc 99.46%, test_acc 92.50%
Fine tuning epoch 148 (scheduling like it's 188): loss 0.0006242, train_acc 99.36%, test_acc 92.54%
Fine tuning epoch 149 (scheduling like it's 189): loss 0.0006161, train_acc 99.42%, test_acc 92.61%
Fine tuning epoch 150 (scheduling like it's 190): loss 0.0006303, train_acc 99.37%, test_acc 92.60%
Fine tuning epoch 151 (scheduling like it's 191): loss 0.0006210, train_acc 99.39%, test_acc 92.66%
Fine tuning epoch 152 (scheduling like it's 192): loss 0.0006216, train_acc 99.42%, test_acc 92.69%
Fine tuning epoch 153 (scheduling like it's 193): loss 0.0006209, train_acc 99.39%, test_acc 92.54%
Fine tuning epoch 154 (scheduling like it's 194): loss 0.0006133, train_acc 99.41%, test_acc 92.58%
Fine tuning epoch 155 (scheduling like it's 195): loss 0.0006135, train_acc 99.36%, test_acc 92.66%
Fine tuning epoch 156 (scheduling like it's 196): loss 0.0005949, train_acc 99.43%, test_acc 92.59%
Fine tuning epoch 157 (scheduling like it's 197): loss 0.0006195, train_acc 99.37%, test_acc 92.69%
Fine tuning epoch 158 (scheduling like it's 198): loss 0.0006093, train_acc 99.43%, test_acc 92.61%
Fine tuning epoch 159 (scheduling like it's 199): loss 0.0006210, train_acc 99.44%, test_acc 92.83%
