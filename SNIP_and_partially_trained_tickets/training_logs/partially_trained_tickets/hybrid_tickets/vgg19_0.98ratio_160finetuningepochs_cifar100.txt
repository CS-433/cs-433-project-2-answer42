 => Using seed 2020
 => Using device: cuda
Files already downloaded and verified
Files already downloaded and verified
 => Loading model '/content/drive/MyDrive/pruningData/partially_trained/pretrained_models/vgg19_160_40_cifar100_basic_pretraining_model.pt'
 => Pruning (keeping 2.0% weights)
===> smart ratios before rearanging: 5.246, 1.180, 0.469, 0.235, 0.133, 0.081, 0.051, 0.034, 0.022, 0.015, 0.010, 0.007, 0.005, 0.003, 0.002, 0.001, 0.300
===> smart ratios: 1.000, 1.000, 0.659, 0.235, 0.133, 0.081, 0.051, 0.034, 0.022, 0.015, 0.010, 0.007, 0.005, 0.003, 0.002, 0.001, 0.300
===> total keep ratio: 0.019998537626105418
=> Using a preset learning rate schedule:
{0: 0.1, 80: 0.010000000000000002, 120: 0.001}
Fine tuning epoch 0 (scheduling like it's 40): loss 0.0317897, train_acc 52.91%, test_acc 49.60%
Fine tuning epoch 1 (scheduling like it's 41): loss 0.0244291, train_acc 58.08%, test_acc 53.33%
Fine tuning epoch 2 (scheduling like it's 42): loss 0.0220559, train_acc 58.64%, test_acc 52.75%
Fine tuning epoch 3 (scheduling like it's 43): loss 0.0209341, train_acc 63.17%, test_acc 57.07%
Fine tuning epoch 4 (scheduling like it's 44): loss 0.0199368, train_acc 64.78%, test_acc 57.41%
Fine tuning epoch 5 (scheduling like it's 45): loss 0.0192848, train_acc 66.95%, test_acc 59.39%
Fine tuning epoch 6 (scheduling like it's 46): loss 0.0188448, train_acc 63.16%, test_acc 55.96%
Fine tuning epoch 7 (scheduling like it's 47): loss 0.0186873, train_acc 66.50%, test_acc 57.32%
Fine tuning epoch 8 (scheduling like it's 48): loss 0.0180155, train_acc 69.09%, test_acc 59.87%
Fine tuning epoch 9 (scheduling like it's 49): loss 0.0179044, train_acc 68.41%, test_acc 59.93%
Fine tuning epoch 10 (scheduling like it's 50): loss 0.0176624, train_acc 68.73%, test_acc 59.27%
Fine tuning epoch 11 (scheduling like it's 51): loss 0.0174552, train_acc 69.10%, test_acc 59.58%
Fine tuning epoch 12 (scheduling like it's 52): loss 0.0172869, train_acc 69.27%, test_acc 59.83%
Fine tuning epoch 13 (scheduling like it's 53): loss 0.0171525, train_acc 68.87%, test_acc 59.77%
Fine tuning epoch 14 (scheduling like it's 54): loss 0.0169508, train_acc 70.68%, test_acc 60.97%
Fine tuning epoch 15 (scheduling like it's 55): loss 0.0170117, train_acc 69.53%, test_acc 60.57%
Fine tuning epoch 16 (scheduling like it's 56): loss 0.0169195, train_acc 68.69%, test_acc 59.36%
Fine tuning epoch 17 (scheduling like it's 57): loss 0.0168233, train_acc 69.67%, test_acc 60.11%
Fine tuning epoch 18 (scheduling like it's 58): loss 0.0166471, train_acc 70.88%, test_acc 61.01%
Fine tuning epoch 19 (scheduling like it's 59): loss 0.0166280, train_acc 70.46%, test_acc 61.22%
Fine tuning epoch 20 (scheduling like it's 60): loss 0.0165591, train_acc 71.60%, test_acc 61.20%
Fine tuning epoch 21 (scheduling like it's 61): loss 0.0165972, train_acc 67.95%, test_acc 59.09%
Fine tuning epoch 22 (scheduling like it's 62): loss 0.0165970, train_acc 71.76%, test_acc 61.77%
Fine tuning epoch 23 (scheduling like it's 63): loss 0.0164148, train_acc 70.09%, test_acc 60.27%
Fine tuning epoch 24 (scheduling like it's 64): loss 0.0165195, train_acc 69.39%, test_acc 60.32%
Fine tuning epoch 25 (scheduling like it's 65): loss 0.0164938, train_acc 69.34%, test_acc 60.22%
Fine tuning epoch 26 (scheduling like it's 66): loss 0.0163340, train_acc 69.52%, test_acc 59.15%
Fine tuning epoch 27 (scheduling like it's 67): loss 0.0164134, train_acc 72.46%, test_acc 62.19%
Fine tuning epoch 28 (scheduling like it's 68): loss 0.0161664, train_acc 71.70%, test_acc 62.11%
Fine tuning epoch 29 (scheduling like it's 69): loss 0.0162912, train_acc 71.68%, test_acc 61.56%
Fine tuning epoch 30 (scheduling like it's 70): loss 0.0162786, train_acc 70.75%, test_acc 60.73%
Fine tuning epoch 31 (scheduling like it's 71): loss 0.0163647, train_acc 71.67%, test_acc 61.58%
Fine tuning epoch 32 (scheduling like it's 72): loss 0.0163014, train_acc 71.08%, test_acc 60.90%
Fine tuning epoch 33 (scheduling like it's 73): loss 0.0161666, train_acc 70.69%, test_acc 60.75%
Fine tuning epoch 34 (scheduling like it's 74): loss 0.0162052, train_acc 70.55%, test_acc 60.77%
Fine tuning epoch 35 (scheduling like it's 75): loss 0.0162139, train_acc 71.55%, test_acc 62.11%
Fine tuning epoch 36 (scheduling like it's 76): loss 0.0160761, train_acc 68.56%, test_acc 59.13%
Fine tuning epoch 37 (scheduling like it's 77): loss 0.0161311, train_acc 70.46%, test_acc 60.91%
Fine tuning epoch 38 (scheduling like it's 78): loss 0.0160668, train_acc 71.22%, test_acc 60.75%
Fine tuning epoch 39 (scheduling like it's 79): loss 0.0161778, train_acc 73.02%, test_acc 62.10%
Fine tuning epoch 40 (scheduling like it's 80): loss 0.0114327, train_acc 82.48%, test_acc 68.41%
Fine tuning epoch 41 (scheduling like it's 81): loss 0.0100003, train_acc 84.02%, test_acc 68.97%
Fine tuning epoch 42 (scheduling like it's 82): loss 0.0093554, train_acc 84.96%, test_acc 69.35%
Fine tuning epoch 43 (scheduling like it's 83): loss 0.0089613, train_acc 85.31%, test_acc 69.40%
Fine tuning epoch 44 (scheduling like it's 84): loss 0.0086017, train_acc 86.06%, test_acc 69.48%
Fine tuning epoch 45 (scheduling like it's 85): loss 0.0083612, train_acc 86.51%, test_acc 69.10%
Fine tuning epoch 46 (scheduling like it's 86): loss 0.0081913, train_acc 86.89%, test_acc 69.28%
Fine tuning epoch 47 (scheduling like it's 87): loss 0.0079546, train_acc 87.61%, test_acc 69.60%
Fine tuning epoch 48 (scheduling like it's 88): loss 0.0076895, train_acc 87.75%, test_acc 69.53%
Fine tuning epoch 49 (scheduling like it's 89): loss 0.0075445, train_acc 88.04%, test_acc 69.34%
Fine tuning epoch 50 (scheduling like it's 90): loss 0.0074245, train_acc 88.40%, test_acc 69.60%
Fine tuning epoch 51 (scheduling like it's 91): loss 0.0071746, train_acc 88.67%, test_acc 69.56%
Fine tuning epoch 52 (scheduling like it's 92): loss 0.0070841, train_acc 89.05%, test_acc 69.95%
Fine tuning epoch 53 (scheduling like it's 93): loss 0.0070279, train_acc 88.89%, test_acc 69.81%
Fine tuning epoch 54 (scheduling like it's 94): loss 0.0069387, train_acc 89.46%, test_acc 69.85%
Fine tuning epoch 55 (scheduling like it's 95): loss 0.0067782, train_acc 89.63%, test_acc 69.87%
Fine tuning epoch 56 (scheduling like it's 96): loss 0.0066557, train_acc 89.68%, test_acc 69.67%
Fine tuning epoch 57 (scheduling like it's 97): loss 0.0065213, train_acc 89.92%, test_acc 69.69%
Fine tuning epoch 58 (scheduling like it's 98): loss 0.0064833, train_acc 89.95%, test_acc 69.77%
Fine tuning epoch 59 (scheduling like it's 99): loss 0.0063915, train_acc 90.41%, test_acc 69.53%
Fine tuning epoch 60 (scheduling like it's 100): loss 0.0063364, train_acc 90.21%, test_acc 69.20%
Fine tuning epoch 61 (scheduling like it's 101): loss 0.0062091, train_acc 90.39%, test_acc 69.73%
Fine tuning epoch 62 (scheduling like it's 102): loss 0.0061879, train_acc 91.00%, test_acc 69.75%
Fine tuning epoch 63 (scheduling like it's 103): loss 0.0060150, train_acc 91.01%, test_acc 69.40%
Fine tuning epoch 64 (scheduling like it's 104): loss 0.0060828, train_acc 91.04%, test_acc 69.93%
Fine tuning epoch 65 (scheduling like it's 105): loss 0.0059873, train_acc 91.19%, test_acc 69.66%
Fine tuning epoch 66 (scheduling like it's 106): loss 0.0059898, train_acc 91.14%, test_acc 69.53%
Fine tuning epoch 67 (scheduling like it's 107): loss 0.0058028, train_acc 91.39%, test_acc 69.33%
Fine tuning epoch 68 (scheduling like it's 108): loss 0.0058258, train_acc 91.53%, test_acc 69.64%
Fine tuning epoch 69 (scheduling like it's 109): loss 0.0056813, train_acc 91.57%, test_acc 69.43%
Fine tuning epoch 70 (scheduling like it's 110): loss 0.0057723, train_acc 91.66%, test_acc 69.39%
Fine tuning epoch 71 (scheduling like it's 111): loss 0.0056681, train_acc 91.40%, test_acc 69.42%
Fine tuning epoch 72 (scheduling like it's 112): loss 0.0055964, train_acc 91.63%, test_acc 69.24%
Fine tuning epoch 73 (scheduling like it's 113): loss 0.0056095, train_acc 91.53%, test_acc 69.24%
Fine tuning epoch 74 (scheduling like it's 114): loss 0.0055816, train_acc 91.61%, test_acc 69.41%
Fine tuning epoch 75 (scheduling like it's 115): loss 0.0055871, train_acc 91.95%, test_acc 69.33%
Fine tuning epoch 76 (scheduling like it's 116): loss 0.0055555, train_acc 91.75%, test_acc 68.99%
Fine tuning epoch 77 (scheduling like it's 117): loss 0.0054138, train_acc 91.76%, test_acc 68.89%
Fine tuning epoch 78 (scheduling like it's 118): loss 0.0054861, train_acc 92.18%, test_acc 69.00%
Fine tuning epoch 79 (scheduling like it's 119): loss 0.0054608, train_acc 92.09%, test_acc 69.37%
Fine tuning epoch 80 (scheduling like it's 120): loss 0.0047626, train_acc 93.33%, test_acc 69.91%
Fine tuning epoch 81 (scheduling like it's 121): loss 0.0045208, train_acc 93.76%, test_acc 70.07%
Fine tuning epoch 82 (scheduling like it's 122): loss 0.0043651, train_acc 93.63%, test_acc 70.07%
Fine tuning epoch 83 (scheduling like it's 123): loss 0.0044216, train_acc 93.98%, test_acc 70.13%
Fine tuning epoch 84 (scheduling like it's 124): loss 0.0043060, train_acc 94.03%, test_acc 70.21%
Fine tuning epoch 85 (scheduling like it's 125): loss 0.0042928, train_acc 93.88%, test_acc 69.93%
Fine tuning epoch 86 (scheduling like it's 126): loss 0.0041753, train_acc 94.12%, test_acc 70.22%
Fine tuning epoch 87 (scheduling like it's 127): loss 0.0041839, train_acc 94.35%, test_acc 69.96%
Fine tuning epoch 88 (scheduling like it's 128): loss 0.0041550, train_acc 94.29%, test_acc 69.95%
Fine tuning epoch 89 (scheduling like it's 129): loss 0.0041492, train_acc 94.37%, test_acc 69.86%
Fine tuning epoch 90 (scheduling like it's 130): loss 0.0041215, train_acc 94.57%, test_acc 69.93%
Fine tuning epoch 91 (scheduling like it's 131): loss 0.0040921, train_acc 94.43%, test_acc 70.23%
Fine tuning epoch 92 (scheduling like it's 132): loss 0.0041341, train_acc 94.51%, test_acc 70.08%
Fine tuning epoch 93 (scheduling like it's 133): loss 0.0040133, train_acc 94.67%, test_acc 70.14%
Fine tuning epoch 94 (scheduling like it's 134): loss 0.0039942, train_acc 94.40%, test_acc 69.82%
Fine tuning epoch 95 (scheduling like it's 135): loss 0.0039849, train_acc 94.76%, test_acc 70.05%
Fine tuning epoch 96 (scheduling like it's 136): loss 0.0039887, train_acc 94.67%, test_acc 70.14%
Fine tuning epoch 97 (scheduling like it's 137): loss 0.0039137, train_acc 94.54%, test_acc 69.95%
Fine tuning epoch 98 (scheduling like it's 138): loss 0.0039866, train_acc 94.65%, test_acc 70.20%
Fine tuning epoch 99 (scheduling like it's 139): loss 0.0039008, train_acc 94.75%, test_acc 70.00%
Fine tuning epoch 100 (scheduling like it's 140): loss 0.0038716, train_acc 94.90%, test_acc 69.86%
Fine tuning epoch 101 (scheduling like it's 141): loss 0.0038156, train_acc 94.76%, test_acc 70.02%
Fine tuning epoch 102 (scheduling like it's 142): loss 0.0038960, train_acc 95.02%, test_acc 70.00%
Fine tuning epoch 103 (scheduling like it's 143): loss 0.0039095, train_acc 94.94%, test_acc 70.12%
Fine tuning epoch 104 (scheduling like it's 144): loss 0.0038310, train_acc 94.99%, test_acc 70.01%
Fine tuning epoch 105 (scheduling like it's 145): loss 0.0038555, train_acc 94.92%, test_acc 70.06%
Fine tuning epoch 106 (scheduling like it's 146): loss 0.0037088, train_acc 95.05%, test_acc 70.13%
Fine tuning epoch 107 (scheduling like it's 147): loss 0.0037809, train_acc 95.21%, test_acc 70.09%
Fine tuning epoch 108 (scheduling like it's 148): loss 0.0038821, train_acc 95.14%, test_acc 69.92%
Fine tuning epoch 109 (scheduling like it's 149): loss 0.0037769, train_acc 95.13%, test_acc 70.09%
Fine tuning epoch 110 (scheduling like it's 150): loss 0.0037099, train_acc 95.10%, test_acc 70.12%
Fine tuning epoch 111 (scheduling like it's 151): loss 0.0037990, train_acc 95.12%, test_acc 70.05%
Fine tuning epoch 112 (scheduling like it's 152): loss 0.0037269, train_acc 95.12%, test_acc 69.93%
Fine tuning epoch 113 (scheduling like it's 153): loss 0.0037083, train_acc 95.10%, test_acc 69.97%
Fine tuning epoch 114 (scheduling like it's 154): loss 0.0037582, train_acc 95.33%, test_acc 69.85%
Fine tuning epoch 115 (scheduling like it's 155): loss 0.0036924, train_acc 95.14%, test_acc 70.07%
Fine tuning epoch 116 (scheduling like it's 156): loss 0.0036829, train_acc 95.21%, test_acc 69.70%
Fine tuning epoch 117 (scheduling like it's 157): loss 0.0037122, train_acc 95.33%, test_acc 70.02%
Fine tuning epoch 118 (scheduling like it's 158): loss 0.0036601, train_acc 95.17%, test_acc 69.78%
Fine tuning epoch 119 (scheduling like it's 159): loss 0.0036577, train_acc 95.31%, test_acc 69.70%
Fine tuning epoch 120 (scheduling like it's 160): loss 0.0036373, train_acc 95.23%, test_acc 69.71%
Fine tuning epoch 121 (scheduling like it's 161): loss 0.0035996, train_acc 95.39%, test_acc 70.07%
Fine tuning epoch 122 (scheduling like it's 162): loss 0.0035415, train_acc 95.36%, test_acc 69.69%
Fine tuning epoch 123 (scheduling like it's 163): loss 0.0036072, train_acc 95.38%, test_acc 69.74%
Fine tuning epoch 124 (scheduling like it's 164): loss 0.0035568, train_acc 95.37%, test_acc 70.00%
Fine tuning epoch 125 (scheduling like it's 165): loss 0.0035959, train_acc 95.36%, test_acc 69.83%
Fine tuning epoch 126 (scheduling like it's 166): loss 0.0035396, train_acc 95.54%, test_acc 69.94%
Fine tuning epoch 127 (scheduling like it's 167): loss 0.0035594, train_acc 95.33%, test_acc 69.85%
Fine tuning epoch 128 (scheduling like it's 168): loss 0.0035865, train_acc 95.54%, test_acc 69.72%
Fine tuning epoch 129 (scheduling like it's 169): loss 0.0035760, train_acc 95.54%, test_acc 70.09%
Fine tuning epoch 130 (scheduling like it's 170): loss 0.0035660, train_acc 95.42%, test_acc 69.75%
Fine tuning epoch 131 (scheduling like it's 171): loss 0.0034819, train_acc 95.47%, test_acc 69.70%
Fine tuning epoch 132 (scheduling like it's 172): loss 0.0035419, train_acc 95.72%, test_acc 69.87%
Fine tuning epoch 133 (scheduling like it's 173): loss 0.0034860, train_acc 95.67%, test_acc 69.81%
Fine tuning epoch 134 (scheduling like it's 174): loss 0.0035250, train_acc 95.72%, test_acc 69.88%
Fine tuning epoch 135 (scheduling like it's 175): loss 0.0035404, train_acc 95.47%, test_acc 69.99%
Fine tuning epoch 136 (scheduling like it's 176): loss 0.0034761, train_acc 95.66%, test_acc 70.04%
Fine tuning epoch 137 (scheduling like it's 177): loss 0.0035110, train_acc 95.64%, test_acc 70.16%
Fine tuning epoch 138 (scheduling like it's 178): loss 0.0034764, train_acc 95.67%, test_acc 69.80%
Fine tuning epoch 139 (scheduling like it's 179): loss 0.0034790, train_acc 95.76%, test_acc 69.92%
Fine tuning epoch 140 (scheduling like it's 180): loss 0.0034602, train_acc 95.63%, test_acc 69.94%
Fine tuning epoch 141 (scheduling like it's 181): loss 0.0034861, train_acc 95.86%, test_acc 70.31%
Fine tuning epoch 142 (scheduling like it's 182): loss 0.0034566, train_acc 95.91%, test_acc 70.16%
Fine tuning epoch 143 (scheduling like it's 183): loss 0.0034447, train_acc 95.81%, test_acc 69.96%
Fine tuning epoch 144 (scheduling like it's 184): loss 0.0034286, train_acc 95.76%, test_acc 69.98%
Fine tuning epoch 145 (scheduling like it's 185): loss 0.0034299, train_acc 95.94%, test_acc 70.18%
Fine tuning epoch 146 (scheduling like it's 186): loss 0.0033737, train_acc 95.97%, test_acc 70.17%
Fine tuning epoch 147 (scheduling like it's 187): loss 0.0033367, train_acc 95.83%, test_acc 70.37%
Fine tuning epoch 148 (scheduling like it's 188): loss 0.0034000, train_acc 95.99%, test_acc 69.85%
Fine tuning epoch 149 (scheduling like it's 189): loss 0.0034154, train_acc 95.98%, test_acc 70.01%
Fine tuning epoch 150 (scheduling like it's 190): loss 0.0033906, train_acc 95.85%, test_acc 69.91%
Fine tuning epoch 151 (scheduling like it's 191): loss 0.0033455, train_acc 95.95%, test_acc 69.89%
Fine tuning epoch 152 (scheduling like it's 192): loss 0.0033980, train_acc 95.94%, test_acc 70.14%
Fine tuning epoch 153 (scheduling like it's 193): loss 0.0033425, train_acc 95.94%, test_acc 70.11%
Fine tuning epoch 154 (scheduling like it's 194): loss 0.0033178, train_acc 95.92%, test_acc 69.84%
Fine tuning epoch 155 (scheduling like it's 195): loss 0.0033412, train_acc 96.04%, test_acc 69.94%
Fine tuning epoch 156 (scheduling like it's 196): loss 0.0033744, train_acc 96.06%, test_acc 69.98%
Fine tuning epoch 157 (scheduling like it's 197): loss 0.0033359, train_acc 96.13%, test_acc 69.98%
Fine tuning epoch 158 (scheduling like it's 198): loss 0.0032569, train_acc 95.93%, test_acc 70.09%
Fine tuning epoch 159 (scheduling like it's 199): loss 0.0032715, train_acc 96.07%, test_acc 70.01%
