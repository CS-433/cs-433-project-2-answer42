 => Using seed 2020
 => Using device: cuda
Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./cifar100/cifar-100-python.tar.gz
Extracting ./cifar100/cifar-100-python.tar.gz to ./cifar100
Files already downloaded and verified
 => Loading model '/content/drive/MyDrive/pruningData/partially_trained/pretrained_models/vgg19_160_40_cifar100_basic_pretraining_model.pt'
 => Pruning (keeping 10.0% weights)
=> Using a preset learning rate schedule:
{0: 0.1, 80: 0.010000000000000002, 120: 0.001}
Fine tuning epoch 0 (scheduling like it's 40): loss 0.0224591, train_acc 66.19%, test_acc 56.69%
Fine tuning epoch 1 (scheduling like it's 41): loss 0.0167062, train_acc 71.29%, test_acc 59.32%
Fine tuning epoch 2 (scheduling like it's 42): loss 0.0150268, train_acc 73.22%, test_acc 60.53%
Fine tuning epoch 3 (scheduling like it's 43): loss 0.0143585, train_acc 73.05%, test_acc 60.26%
Fine tuning epoch 4 (scheduling like it's 44): loss 0.0134289, train_acc 75.26%, test_acc 60.88%
Fine tuning epoch 5 (scheduling like it's 45): loss 0.0128505, train_acc 77.87%, test_acc 63.43%
Fine tuning epoch 6 (scheduling like it's 46): loss 0.0124596, train_acc 75.28%, test_acc 60.68%
Fine tuning epoch 7 (scheduling like it's 47): loss 0.0123015, train_acc 78.98%, test_acc 62.92%
Fine tuning epoch 8 (scheduling like it's 48): loss 0.0119097, train_acc 76.84%, test_acc 61.53%
Fine tuning epoch 9 (scheduling like it's 49): loss 0.0118383, train_acc 78.76%, test_acc 62.83%
Fine tuning epoch 10 (scheduling like it's 50): loss 0.0117363, train_acc 76.22%, test_acc 61.34%
Fine tuning epoch 11 (scheduling like it's 51): loss 0.0117438, train_acc 75.42%, test_acc 60.60%
Fine tuning epoch 12 (scheduling like it's 52): loss 0.0113822, train_acc 78.09%, test_acc 62.37%
Fine tuning epoch 13 (scheduling like it's 53): loss 0.0113221, train_acc 77.80%, test_acc 61.83%
Fine tuning epoch 14 (scheduling like it's 54): loss 0.0113229, train_acc 79.23%, test_acc 61.79%
Fine tuning epoch 15 (scheduling like it's 55): loss 0.0112136, train_acc 76.16%, test_acc 60.96%
Fine tuning epoch 16 (scheduling like it's 56): loss 0.0112560, train_acc 74.95%, test_acc 59.76%
Fine tuning epoch 17 (scheduling like it's 57): loss 0.0114418, train_acc 76.62%, test_acc 61.25%
Fine tuning epoch 18 (scheduling like it's 58): loss 0.0111340, train_acc 76.88%, test_acc 61.37%
Fine tuning epoch 19 (scheduling like it's 59): loss 0.0108703, train_acc 79.17%, test_acc 62.57%
Fine tuning epoch 20 (scheduling like it's 60): loss 0.0109908, train_acc 79.19%, test_acc 62.04%
Fine tuning epoch 21 (scheduling like it's 61): loss 0.0110844, train_acc 80.01%, test_acc 62.96%
Fine tuning epoch 22 (scheduling like it's 62): loss 0.0110974, train_acc 79.74%, test_acc 63.21%
Fine tuning epoch 23 (scheduling like it's 63): loss 0.0106965, train_acc 78.02%, test_acc 62.10%
Fine tuning epoch 24 (scheduling like it's 64): loss 0.0110106, train_acc 74.63%, test_acc 59.64%
Fine tuning epoch 25 (scheduling like it's 65): loss 0.0109783, train_acc 78.64%, test_acc 61.89%
Fine tuning epoch 26 (scheduling like it's 66): loss 0.0107920, train_acc 78.28%, test_acc 61.89%
Fine tuning epoch 27 (scheduling like it's 67): loss 0.0107376, train_acc 80.59%, test_acc 62.73%
Fine tuning epoch 28 (scheduling like it's 68): loss 0.0106850, train_acc 80.47%, test_acc 63.69%
Fine tuning epoch 29 (scheduling like it's 69): loss 0.0108364, train_acc 77.23%, test_acc 61.12%
Fine tuning epoch 30 (scheduling like it's 70): loss 0.0109161, train_acc 77.50%, test_acc 60.40%
Fine tuning epoch 31 (scheduling like it's 71): loss 0.0107243, train_acc 76.63%, test_acc 61.09%
Fine tuning epoch 32 (scheduling like it's 72): loss 0.0109931, train_acc 74.02%, test_acc 59.30%
Fine tuning epoch 33 (scheduling like it's 73): loss 0.0112896, train_acc 79.21%, test_acc 63.32%
Fine tuning epoch 34 (scheduling like it's 74): loss 0.0110897, train_acc 77.41%, test_acc 61.10%
Fine tuning epoch 35 (scheduling like it's 75): loss 0.0108647, train_acc 78.60%, test_acc 62.48%
Fine tuning epoch 36 (scheduling like it's 76): loss 0.0106343, train_acc 74.47%, test_acc 59.31%
Fine tuning epoch 37 (scheduling like it's 77): loss 0.0110116, train_acc 77.62%, test_acc 60.90%
Fine tuning epoch 38 (scheduling like it's 78): loss 0.0109257, train_acc 81.08%, test_acc 63.04%
Fine tuning epoch 39 (scheduling like it's 79): loss 0.0107379, train_acc 81.96%, test_acc 63.95%
Fine tuning epoch 40 (scheduling like it's 80): loss 0.0052475, train_acc 93.81%, test_acc 70.42%
Fine tuning epoch 41 (scheduling like it's 81): loss 0.0036427, train_acc 94.83%, test_acc 70.89%
Fine tuning epoch 42 (scheduling like it's 82): loss 0.0030983, train_acc 95.79%, test_acc 71.26%
Fine tuning epoch 43 (scheduling like it's 83): loss 0.0027461, train_acc 96.16%, test_acc 71.14%
Fine tuning epoch 44 (scheduling like it's 84): loss 0.0024263, train_acc 96.64%, test_acc 71.20%
Fine tuning epoch 45 (scheduling like it's 85): loss 0.0022512, train_acc 97.02%, test_acc 71.00%
Fine tuning epoch 46 (scheduling like it's 86): loss 0.0020362, train_acc 97.33%, test_acc 71.17%
Fine tuning epoch 47 (scheduling like it's 87): loss 0.0018946, train_acc 97.61%, test_acc 71.24%
Fine tuning epoch 48 (scheduling like it's 88): loss 0.0017691, train_acc 97.81%, test_acc 70.99%
Fine tuning epoch 49 (scheduling like it's 89): loss 0.0016552, train_acc 98.04%, test_acc 71.03%
Fine tuning epoch 50 (scheduling like it's 90): loss 0.0015865, train_acc 98.25%, test_acc 70.86%
Fine tuning epoch 51 (scheduling like it's 91): loss 0.0014818, train_acc 98.31%, test_acc 70.47%
Fine tuning epoch 52 (scheduling like it's 92): loss 0.0014209, train_acc 98.46%, test_acc 70.83%
Fine tuning epoch 53 (scheduling like it's 93): loss 0.0013611, train_acc 98.45%, test_acc 71.01%
Fine tuning epoch 54 (scheduling like it's 94): loss 0.0012416, train_acc 98.77%, test_acc 70.87%
Fine tuning epoch 55 (scheduling like it's 95): loss 0.0012032, train_acc 98.79%, test_acc 70.64%
Fine tuning epoch 56 (scheduling like it's 96): loss 0.0011798, train_acc 98.91%, test_acc 70.92%
Fine tuning epoch 57 (scheduling like it's 97): loss 0.0010998, train_acc 99.02%, test_acc 70.84%
Fine tuning epoch 58 (scheduling like it's 98): loss 0.0010867, train_acc 99.02%, test_acc 70.82%
Fine tuning epoch 59 (scheduling like it's 99): loss 0.0010423, train_acc 98.97%, test_acc 70.95%
Fine tuning epoch 60 (scheduling like it's 100): loss 0.0009881, train_acc 99.14%, test_acc 70.79%
Fine tuning epoch 61 (scheduling like it's 101): loss 0.0009444, train_acc 99.15%, test_acc 70.58%
Fine tuning epoch 62 (scheduling like it's 102): loss 0.0009122, train_acc 99.17%, test_acc 70.78%
Fine tuning epoch 63 (scheduling like it's 103): loss 0.0009010, train_acc 99.23%, test_acc 70.58%
Fine tuning epoch 64 (scheduling like it's 104): loss 0.0008535, train_acc 99.25%, test_acc 70.70%
Fine tuning epoch 65 (scheduling like it's 105): loss 0.0008355, train_acc 99.36%, test_acc 71.14%
Fine tuning epoch 66 (scheduling like it's 106): loss 0.0008083, train_acc 99.36%, test_acc 70.89%
Fine tuning epoch 67 (scheduling like it's 107): loss 0.0007556, train_acc 99.42%, test_acc 70.76%
Fine tuning epoch 68 (scheduling like it's 108): loss 0.0007724, train_acc 99.39%, test_acc 70.68%
Fine tuning epoch 69 (scheduling like it's 109): loss 0.0007567, train_acc 99.36%, test_acc 70.85%
Fine tuning epoch 70 (scheduling like it's 110): loss 0.0006982, train_acc 99.48%, test_acc 70.71%
Fine tuning epoch 71 (scheduling like it's 111): loss 0.0007131, train_acc 99.46%, test_acc 71.05%
Fine tuning epoch 72 (scheduling like it's 112): loss 0.0006652, train_acc 99.39%, test_acc 71.08%
Fine tuning epoch 73 (scheduling like it's 113): loss 0.0006912, train_acc 99.44%, test_acc 70.96%
Fine tuning epoch 74 (scheduling like it's 114): loss 0.0006784, train_acc 99.45%, test_acc 71.38%
Fine tuning epoch 75 (scheduling like it's 115): loss 0.0006823, train_acc 99.44%, test_acc 70.78%
Fine tuning epoch 76 (scheduling like it's 116): loss 0.0006906, train_acc 99.53%, test_acc 70.88%
Fine tuning epoch 77 (scheduling like it's 117): loss 0.0006609, train_acc 99.45%, test_acc 70.57%
Fine tuning epoch 78 (scheduling like it's 118): loss 0.0006947, train_acc 99.51%, test_acc 70.59%
Fine tuning epoch 79 (scheduling like it's 119): loss 0.0006456, train_acc 99.57%, test_acc 70.87%
Fine tuning epoch 80 (scheduling like it's 120): loss 0.0005143, train_acc 99.69%, test_acc 71.13%
Fine tuning epoch 81 (scheduling like it's 121): loss 0.0004282, train_acc 99.76%, test_acc 71.36%
Fine tuning epoch 82 (scheduling like it's 122): loss 0.0004206, train_acc 99.78%, test_acc 71.22%
Fine tuning epoch 83 (scheduling like it's 123): loss 0.0004138, train_acc 99.78%, test_acc 71.39%
Fine tuning epoch 84 (scheduling like it's 124): loss 0.0004077, train_acc 99.83%, test_acc 71.30%
Fine tuning epoch 85 (scheduling like it's 125): loss 0.0003899, train_acc 99.81%, test_acc 71.23%
Fine tuning epoch 86 (scheduling like it's 126): loss 0.0003846, train_acc 99.82%, test_acc 71.13%
Fine tuning epoch 87 (scheduling like it's 127): loss 0.0003571, train_acc 99.81%, test_acc 71.27%
Fine tuning epoch 88 (scheduling like it's 128): loss 0.0003632, train_acc 99.85%, test_acc 71.11%
Fine tuning epoch 89 (scheduling like it's 129): loss 0.0003484, train_acc 99.84%, test_acc 71.09%
Fine tuning epoch 90 (scheduling like it's 130): loss 0.0003676, train_acc 99.81%, test_acc 71.25%
Fine tuning epoch 91 (scheduling like it's 131): loss 0.0003548, train_acc 99.82%, test_acc 71.23%
Fine tuning epoch 92 (scheduling like it's 132): loss 0.0003453, train_acc 99.83%, test_acc 71.14%
Fine tuning epoch 93 (scheduling like it's 133): loss 0.0003352, train_acc 99.83%, test_acc 71.30%
Fine tuning epoch 94 (scheduling like it's 134): loss 0.0003226, train_acc 99.86%, test_acc 71.16%
Fine tuning epoch 95 (scheduling like it's 135): loss 0.0003511, train_acc 99.84%, test_acc 71.28%
Fine tuning epoch 96 (scheduling like it's 136): loss 0.0003251, train_acc 99.85%, test_acc 71.16%
Fine tuning epoch 97 (scheduling like it's 137): loss 0.0003283, train_acc 99.83%, test_acc 71.16%
Fine tuning epoch 98 (scheduling like it's 138): loss 0.0003290, train_acc 99.85%, test_acc 71.33%
Fine tuning epoch 99 (scheduling like it's 139): loss 0.0003128, train_acc 99.88%, test_acc 71.58%
Fine tuning epoch 100 (scheduling like it's 140): loss 0.0003127, train_acc 99.85%, test_acc 71.41%
Fine tuning epoch 101 (scheduling like it's 141): loss 0.0003141, train_acc 99.85%, test_acc 71.34%
Fine tuning epoch 102 (scheduling like it's 142): loss 0.0003235, train_acc 99.88%, test_acc 71.46%
Fine tuning epoch 103 (scheduling like it's 143): loss 0.0003177, train_acc 99.86%, test_acc 71.38%
Fine tuning epoch 104 (scheduling like it's 144): loss 0.0003068, train_acc 99.89%, test_acc 71.54%
Fine tuning epoch 105 (scheduling like it's 145): loss 0.0002965, train_acc 99.87%, test_acc 71.50%
Fine tuning epoch 106 (scheduling like it's 146): loss 0.0002994, train_acc 99.85%, test_acc 71.43%
Fine tuning epoch 107 (scheduling like it's 147): loss 0.0003128, train_acc 99.87%, test_acc 71.42%
Fine tuning epoch 108 (scheduling like it's 148): loss 0.0002934, train_acc 99.90%, test_acc 71.47%
Fine tuning epoch 109 (scheduling like it's 149): loss 0.0002980, train_acc 99.88%, test_acc 71.51%
Fine tuning epoch 110 (scheduling like it's 150): loss 0.0002927, train_acc 99.89%, test_acc 71.56%
Fine tuning epoch 111 (scheduling like it's 151): loss 0.0002882, train_acc 99.89%, test_acc 71.45%
Fine tuning epoch 112 (scheduling like it's 152): loss 0.0002704, train_acc 99.87%, test_acc 71.46%
Fine tuning epoch 113 (scheduling like it's 153): loss 0.0003013, train_acc 99.89%, test_acc 71.31%
Fine tuning epoch 114 (scheduling like it's 154): loss 0.0002835, train_acc 99.88%, test_acc 71.37%
Fine tuning epoch 115 (scheduling like it's 155): loss 0.0002781, train_acc 99.91%, test_acc 71.28%
Fine tuning epoch 116 (scheduling like it's 156): loss 0.0002775, train_acc 99.88%, test_acc 71.39%
Fine tuning epoch 117 (scheduling like it's 157): loss 0.0002875, train_acc 99.87%, test_acc 71.38%
Fine tuning epoch 118 (scheduling like it's 158): loss 0.0002782, train_acc 99.89%, test_acc 71.56%
Fine tuning epoch 119 (scheduling like it's 159): loss 0.0002709, train_acc 99.88%, test_acc 71.31%
Fine tuning epoch 120 (scheduling like it's 160): loss 0.0002569, train_acc 99.90%, test_acc 71.37%
Fine tuning epoch 121 (scheduling like it's 161): loss 0.0002762, train_acc 99.91%, test_acc 71.32%
Fine tuning epoch 122 (scheduling like it's 162): loss 0.0002616, train_acc 99.90%, test_acc 71.39%
Fine tuning epoch 123 (scheduling like it's 163): loss 0.0002774, train_acc 99.90%, test_acc 71.57%
Fine tuning epoch 124 (scheduling like it's 164): loss 0.0002638, train_acc 99.91%, test_acc 71.42%
Fine tuning epoch 125 (scheduling like it's 165): loss 0.0002652, train_acc 99.89%, test_acc 71.35%
Fine tuning epoch 126 (scheduling like it's 166): loss 0.0002733, train_acc 99.92%, test_acc 71.47%
Fine tuning epoch 127 (scheduling like it's 167): loss 0.0002649, train_acc 99.89%, test_acc 71.52%
Fine tuning epoch 128 (scheduling like it's 168): loss 0.0002669, train_acc 99.90%, test_acc 71.38%
Fine tuning epoch 129 (scheduling like it's 169): loss 0.0002553, train_acc 99.92%, test_acc 71.32%
Fine tuning epoch 130 (scheduling like it's 170): loss 0.0002755, train_acc 99.92%, test_acc 71.44%
Fine tuning epoch 131 (scheduling like it's 171): loss 0.0002591, train_acc 99.90%, test_acc 71.50%
Fine tuning epoch 132 (scheduling like it's 172): loss 0.0002737, train_acc 99.91%, test_acc 71.09%
Fine tuning epoch 133 (scheduling like it's 173): loss 0.0002535, train_acc 99.92%, test_acc 71.40%
Fine tuning epoch 134 (scheduling like it's 174): loss 0.0002623, train_acc 99.90%, test_acc 71.27%
Fine tuning epoch 135 (scheduling like it's 175): loss 0.0002608, train_acc 99.93%, test_acc 71.18%
Fine tuning epoch 136 (scheduling like it's 176): loss 0.0002552, train_acc 99.92%, test_acc 71.61%
Fine tuning epoch 137 (scheduling like it's 177): loss 0.0002534, train_acc 99.89%, test_acc 71.42%
Fine tuning epoch 138 (scheduling like it's 178): loss 0.0002282, train_acc 99.92%, test_acc 71.40%
Fine tuning epoch 139 (scheduling like it's 179): loss 0.0002688, train_acc 99.90%, test_acc 71.34%
Fine tuning epoch 140 (scheduling like it's 180): loss 0.0002532, train_acc 99.93%, test_acc 71.45%
Fine tuning epoch 141 (scheduling like it's 181): loss 0.0002514, train_acc 99.92%, test_acc 71.50%
Fine tuning epoch 142 (scheduling like it's 182): loss 0.0002625, train_acc 99.94%, test_acc 71.29%
Fine tuning epoch 143 (scheduling like it's 183): loss 0.0002532, train_acc 99.93%, test_acc 71.49%
Fine tuning epoch 144 (scheduling like it's 184): loss 0.0002379, train_acc 99.91%, test_acc 71.57%
Fine tuning epoch 145 (scheduling like it's 185): loss 0.0002537, train_acc 99.93%, test_acc 71.53%
Fine tuning epoch 146 (scheduling like it's 186): loss 0.0002311, train_acc 99.93%, test_acc 71.50%
Fine tuning epoch 147 (scheduling like it's 187): loss 0.0002438, train_acc 99.93%, test_acc 71.67%
Fine tuning epoch 148 (scheduling like it's 188): loss 0.0002363, train_acc 99.90%, test_acc 71.42%
Fine tuning epoch 149 (scheduling like it's 189): loss 0.0002336, train_acc 99.92%, test_acc 71.53%
Fine tuning epoch 150 (scheduling like it's 190): loss 0.0002409, train_acc 99.93%, test_acc 71.52%
Fine tuning epoch 151 (scheduling like it's 191): loss 0.0002291, train_acc 99.91%, test_acc 71.41%
Fine tuning epoch 152 (scheduling like it's 192): loss 0.0002293, train_acc 99.92%, test_acc 71.52%
Fine tuning epoch 153 (scheduling like it's 193): loss 0.0002304, train_acc 99.93%, test_acc 71.49%
Fine tuning epoch 154 (scheduling like it's 194): loss 0.0002352, train_acc 99.92%, test_acc 71.26%
Fine tuning epoch 155 (scheduling like it's 195): loss 0.0002221, train_acc 99.92%, test_acc 71.58%
Fine tuning epoch 156 (scheduling like it's 196): loss 0.0002240, train_acc 99.93%, test_acc 71.54%
Fine tuning epoch 157 (scheduling like it's 197): loss 0.0002389, train_acc 99.91%, test_acc 71.42%
Fine tuning epoch 158 (scheduling like it's 198): loss 0.0002381, train_acc 99.92%, test_acc 71.40%
Fine tuning epoch 159 (scheduling like it's 199): loss 0.0002366, train_acc 99.93%, test_acc 71.60%
