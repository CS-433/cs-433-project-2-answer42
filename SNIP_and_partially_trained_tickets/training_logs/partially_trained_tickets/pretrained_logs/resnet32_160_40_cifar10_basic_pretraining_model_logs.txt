 => Using seed 2020
 => Using device: cuda
Files already downloaded and verified
Files already downloaded and verified
=> Using a preset learning rate schedule:
{0: 0.1, 80: 0.010000000000000002, 120: 0.001}
Pretraining epoch 0: loss 0.0292275, train_acc 41.71%, test_acc 43.61%
Pretraining epoch 1: loss 0.0208624, train_acc 59.52%, test_acc 59.96%
Pretraining epoch 2: loss 0.0151698, train_acc 67.22%, test_acc 66.74%
Pretraining epoch 3: loss 0.0119833, train_acc 70.22%, test_acc 69.79%
Pretraining epoch 4: loss 0.0100949, train_acc 78.61%, test_acc 77.83%
Pretraining epoch 5: loss 0.0089848, train_acc 81.01%, test_acc 79.64%
Pretraining epoch 6: loss 0.0081446, train_acc 83.16%, test_acc 81.68%
Pretraining epoch 7: loss 0.0075876, train_acc 84.63%, test_acc 82.56%
Pretraining epoch 8: loss 0.0070088, train_acc 82.82%, test_acc 80.43%
Pretraining epoch 9: loss 0.0066888, train_acc 83.15%, test_acc 79.93%
Pretraining epoch 10: loss 0.0063041, train_acc 85.79%, test_acc 83.06%
Pretraining epoch 11: loss 0.0060894, train_acc 85.97%, test_acc 83.39%
Pretraining epoch 12: loss 0.0056967, train_acc 82.11%, test_acc 78.76%
Pretraining epoch 13: loss 0.0055640, train_acc 85.93%, test_acc 83.23%
Pretraining epoch 14: loss 0.0053900, train_acc 85.19%, test_acc 82.95%
Pretraining epoch 15: loss 0.0052541, train_acc 88.06%, test_acc 85.14%
Pretraining epoch 16: loss 0.0050965, train_acc 89.26%, test_acc 86.55%
Pretraining epoch 17: loss 0.0049635, train_acc 90.29%, test_acc 87.20%
Pretraining epoch 18: loss 0.0048591, train_acc 89.09%, test_acc 85.79%
Pretraining epoch 19: loss 0.0046725, train_acc 88.79%, test_acc 86.08%
Pretraining epoch 20: loss 0.0045757, train_acc 90.96%, test_acc 87.87%
Pretraining epoch 21: loss 0.0044733, train_acc 89.61%, test_acc 85.95%
Pretraining epoch 22: loss 0.0045148, train_acc 86.68%, test_acc 82.90%
Pretraining epoch 23: loss 0.0043693, train_acc 84.92%, test_acc 82.55%
Pretraining epoch 24: loss 0.0042295, train_acc 89.49%, test_acc 86.37%
Pretraining epoch 25: loss 0.0041029, train_acc 90.19%, test_acc 86.99%
Pretraining epoch 26: loss 0.0041681, train_acc 89.73%, test_acc 86.61%
Pretraining epoch 27: loss 0.0040766, train_acc 91.20%, test_acc 87.67%
Pretraining epoch 28: loss 0.0040180, train_acc 91.83%, test_acc 88.30%
Pretraining epoch 29: loss 0.0039828, train_acc 89.94%, test_acc 86.47%
Pretraining epoch 30: loss 0.0038954, train_acc 88.06%, test_acc 84.91%
Pretraining epoch 31: loss 0.0038504, train_acc 91.76%, test_acc 88.02%
Pretraining epoch 32: loss 0.0037975, train_acc 90.66%, test_acc 86.88%
Pretraining epoch 33: loss 0.0037578, train_acc 93.21%, test_acc 89.02%
Pretraining epoch 34: loss 0.0037012, train_acc 90.01%, test_acc 85.99%
Pretraining epoch 35: loss 0.0036739, train_acc 89.10%, test_acc 84.94%
Pretraining epoch 36: loss 0.0036692, train_acc 91.76%, test_acc 87.81%
Pretraining epoch 37: loss 0.0036539, train_acc 92.36%, test_acc 88.33%
Pretraining epoch 38: loss 0.0035836, train_acc 90.93%, test_acc 86.97%
Pretraining epoch 39: loss 0.0035884, train_acc 92.11%, test_acc 87.99%
Pretraining epoch 40: loss 0.0035299, train_acc 91.99%, test_acc 87.72%
Pretraining epoch 41: loss 0.0034946, train_acc 90.01%, test_acc 85.95%
Pretraining epoch 42: loss 0.0035536, train_acc 91.24%, test_acc 87.18%
Pretraining epoch 43: loss 0.0034273, train_acc 92.65%, test_acc 88.54%
Pretraining epoch 44: loss 0.0034926, train_acc 91.38%, test_acc 87.65%
Pretraining epoch 45: loss 0.0033778, train_acc 92.46%, test_acc 87.95%
Pretraining epoch 46: loss 0.0034441, train_acc 91.77%, test_acc 87.65%
Pretraining epoch 47: loss 0.0033373, train_acc 90.36%, test_acc 86.77%
Pretraining epoch 48: loss 0.0033252, train_acc 91.95%, test_acc 87.70%
Pretraining epoch 49: loss 0.0033129, train_acc 90.83%, test_acc 86.24%
Pretraining epoch 50: loss 0.0033195, train_acc 92.81%, test_acc 88.84%
Pretraining epoch 51: loss 0.0032967, train_acc 90.72%, test_acc 86.22%
Pretraining epoch 52: loss 0.0033115, train_acc 90.43%, test_acc 86.43%
Pretraining epoch 53: loss 0.0032743, train_acc 88.66%, test_acc 84.05%
Pretraining epoch 54: loss 0.0033096, train_acc 91.15%, test_acc 86.98%
Pretraining epoch 55: loss 0.0032476, train_acc 92.90%, test_acc 88.13%
Pretraining epoch 56: loss 0.0032302, train_acc 92.91%, test_acc 88.65%
Pretraining epoch 57: loss 0.0032081, train_acc 90.07%, test_acc 86.89%
Pretraining epoch 58: loss 0.0031678, train_acc 91.96%, test_acc 88.23%
Pretraining epoch 59: loss 0.0032168, train_acc 90.57%, test_acc 86.67%
Pretraining epoch 60: loss 0.0032172, train_acc 92.41%, test_acc 88.06%
Pretraining epoch 61: loss 0.0031918, train_acc 92.91%, test_acc 88.64%
Pretraining epoch 62: loss 0.0031876, train_acc 93.10%, test_acc 88.41%
Pretraining epoch 63: loss 0.0030637, train_acc 92.71%, test_acc 88.37%
Pretraining epoch 64: loss 0.0031963, train_acc 93.56%, test_acc 89.58%
Pretraining epoch 65: loss 0.0031318, train_acc 93.10%, test_acc 88.85%
Pretraining epoch 66: loss 0.0031286, train_acc 93.62%, test_acc 89.42%
Pretraining epoch 67: loss 0.0030931, train_acc 90.82%, test_acc 86.53%
Pretraining epoch 68: loss 0.0030970, train_acc 89.98%, test_acc 86.43%
Pretraining epoch 69: loss 0.0031104, train_acc 92.37%, test_acc 87.97%
Pretraining epoch 70: loss 0.0031154, train_acc 92.05%, test_acc 87.93%
Pretraining epoch 71: loss 0.0030351, train_acc 92.71%, test_acc 88.29%
Pretraining epoch 72: loss 0.0030187, train_acc 94.08%, test_acc 89.92%
Pretraining epoch 73: loss 0.0030517, train_acc 92.94%, test_acc 89.18%
Pretraining epoch 74: loss 0.0030345, train_acc 89.59%, test_acc 85.62%
Pretraining epoch 75: loss 0.0030021, train_acc 93.42%, test_acc 89.38%
Pretraining epoch 76: loss 0.0030156, train_acc 93.79%, test_acc 89.19%
Pretraining epoch 77: loss 0.0029788, train_acc 89.71%, test_acc 85.10%
Pretraining epoch 78: loss 0.0030598, train_acc 92.91%, test_acc 88.85%
Pretraining epoch 79: loss 0.0029803, train_acc 93.78%, test_acc 89.73%
Pretraining epoch 80: loss 0.0013726, train_acc 98.38%, test_acc 93.47%
Pretraining epoch 81: loss 0.0009045, train_acc 98.82%, test_acc 93.61%
Pretraining epoch 82: loss 0.0007436, train_acc 99.02%, test_acc 93.78%
Pretraining epoch 83: loss 0.0006218, train_acc 99.22%, test_acc 93.83%
Pretraining epoch 84: loss 0.0005190, train_acc 99.34%, test_acc 94.03%
Pretraining epoch 85: loss 0.0004699, train_acc 99.44%, test_acc 94.14%
Pretraining epoch 86: loss 0.0004185, train_acc 99.50%, test_acc 94.13%
Pretraining epoch 87: loss 0.0003865, train_acc 99.55%, test_acc 94.03%
Pretraining epoch 88: loss 0.0003243, train_acc 99.67%, test_acc 94.12%
Pretraining epoch 89: loss 0.0003220, train_acc 99.69%, test_acc 94.07%
Pretraining epoch 90: loss 0.0002774, train_acc 99.78%, test_acc 94.13%
Pretraining epoch 91: loss 0.0002641, train_acc 99.73%, test_acc 94.05%
Pretraining epoch 92: loss 0.0002408, train_acc 99.79%, test_acc 94.10%
Pretraining epoch 93: loss 0.0002230, train_acc 99.77%, test_acc 94.20%
Pretraining epoch 94: loss 0.0002320, train_acc 99.79%, test_acc 93.99%
Pretraining epoch 95: loss 0.0001934, train_acc 99.84%, test_acc 94.24%
Pretraining epoch 96: loss 0.0001885, train_acc 99.81%, test_acc 94.19%
Pretraining epoch 97: loss 0.0001829, train_acc 99.85%, test_acc 94.31%
Pretraining epoch 98: loss 0.0001750, train_acc 99.85%, test_acc 93.91%
Pretraining epoch 99: loss 0.0001713, train_acc 99.86%, test_acc 94.16%
Pretraining epoch 100: loss 0.0001487, train_acc 99.89%, test_acc 94.19%
Pretraining epoch 101: loss 0.0001544, train_acc 99.88%, test_acc 94.08%
Pretraining epoch 102: loss 0.0001334, train_acc 99.91%, test_acc 94.03%
Pretraining epoch 103: loss 0.0001490, train_acc 99.91%, test_acc 94.12%
Pretraining epoch 104: loss 0.0001277, train_acc 99.90%, test_acc 94.23%
Pretraining epoch 105: loss 0.0001365, train_acc 99.89%, test_acc 94.06%
Pretraining epoch 106: loss 0.0001285, train_acc 99.93%, test_acc 94.21%
Pretraining epoch 107: loss 0.0001247, train_acc 99.90%, test_acc 94.26%
Pretraining epoch 108: loss 0.0001285, train_acc 99.91%, test_acc 94.03%
Pretraining epoch 109: loss 0.0001268, train_acc 99.91%, test_acc 94.20%
Pretraining epoch 110: loss 0.0001144, train_acc 99.92%, test_acc 94.32%
Pretraining epoch 111: loss 0.0001264, train_acc 99.89%, test_acc 94.14%
Pretraining epoch 112: loss 0.0001250, train_acc 99.89%, test_acc 94.07%
Pretraining epoch 113: loss 0.0001169, train_acc 99.89%, test_acc 94.25%
Pretraining epoch 114: loss 0.0001190, train_acc 99.94%, test_acc 94.49%
Pretraining epoch 115: loss 0.0001067, train_acc 99.94%, test_acc 94.24%
Pretraining epoch 116: loss 0.0001201, train_acc 99.92%, test_acc 94.49%
Pretraining epoch 117: loss 0.0000814, train_acc 99.94%, test_acc 94.43%
Pretraining epoch 118: loss 0.0000861, train_acc 99.93%, test_acc 94.51%
Pretraining epoch 119: loss 0.0000830, train_acc 99.95%, test_acc 94.48%
Pretraining epoch 120: loss 0.0000800, train_acc 99.97%, test_acc 94.47%
Pretraining epoch 121: loss 0.0000677, train_acc 99.97%, test_acc 94.39%
Pretraining epoch 122: loss 0.0000529, train_acc 99.99%, test_acc 94.45%
Pretraining epoch 123: loss 0.0000562, train_acc 99.97%, test_acc 94.36%
Pretraining epoch 124: loss 0.0000516, train_acc 99.98%, test_acc 94.49%
Pretraining epoch 125: loss 0.0000480, train_acc 99.97%, test_acc 94.51%
Pretraining epoch 126: loss 0.0000499, train_acc 99.99%, test_acc 94.58%
Pretraining epoch 127: loss 0.0000445, train_acc 99.99%, test_acc 94.55%
Pretraining epoch 128: loss 0.0000509, train_acc 99.98%, test_acc 94.55%
Pretraining epoch 129: loss 0.0000485, train_acc 99.99%, test_acc 94.56%
Pretraining epoch 130: loss 0.0000444, train_acc 99.98%, test_acc 94.62%
Pretraining epoch 131: loss 0.0000442, train_acc 99.99%, test_acc 94.65%
Pretraining epoch 132: loss 0.0000464, train_acc 99.98%, test_acc 94.68%
Pretraining epoch 133: loss 0.0000414, train_acc 99.99%, test_acc 94.54%
Pretraining epoch 134: loss 0.0000429, train_acc 100.00%, test_acc 94.67%
Pretraining epoch 135: loss 0.0000437, train_acc 99.99%, test_acc 94.56%
Pretraining epoch 136: loss 0.0000347, train_acc 99.99%, test_acc 94.71%
Pretraining epoch 137: loss 0.0000403, train_acc 99.99%, test_acc 94.64%
Pretraining epoch 138: loss 0.0000414, train_acc 99.99%, test_acc 94.72%
Pretraining epoch 139: loss 0.0000400, train_acc 99.99%, test_acc 94.72%
Pretraining epoch 140: loss 0.0000368, train_acc 99.99%, test_acc 94.68%
Pretraining epoch 141: loss 0.0000395, train_acc 99.99%, test_acc 94.58%
Pretraining epoch 142: loss 0.0000448, train_acc 99.99%, test_acc 94.70%
Pretraining epoch 143: loss 0.0000358, train_acc 99.99%, test_acc 94.71%
Pretraining epoch 144: loss 0.0000401, train_acc 99.99%, test_acc 94.76%
Pretraining epoch 145: loss 0.0000362, train_acc 99.99%, test_acc 94.82%
Pretraining epoch 146: loss 0.0000362, train_acc 99.99%, test_acc 94.67%
Pretraining epoch 147: loss 0.0000348, train_acc 99.99%, test_acc 94.65%
Pretraining epoch 148: loss 0.0000346, train_acc 99.99%, test_acc 94.66%
Pretraining epoch 149: loss 0.0000383, train_acc 100.00%, test_acc 94.77%
Pretraining epoch 150: loss 0.0000384, train_acc 99.99%, test_acc 94.59%
Pretraining epoch 151: loss 0.0000394, train_acc 99.99%, test_acc 94.70%
Pretraining epoch 152: loss 0.0000363, train_acc 99.99%, test_acc 94.73%
Pretraining epoch 153: loss 0.0000333, train_acc 99.99%, test_acc 94.69%
Pretraining epoch 154: loss 0.0000355, train_acc 99.99%, test_acc 94.72%
Pretraining epoch 155: loss 0.0000335, train_acc 99.99%, test_acc 94.72%
Pretraining epoch 156: loss 0.0000338, train_acc 100.00%, test_acc 94.63%
Pretraining epoch 157: loss 0.0000357, train_acc 100.00%, test_acc 94.71%
Pretraining epoch 158: loss 0.0000309, train_acc 100.00%, test_acc 94.61%
Pretraining epoch 159: loss 0.0000357, train_acc 99.99%, test_acc 94.69%
 => Saving model at '/content/drive/MyDrive/pruningData/partially_trained/pretrained_models/resnet32_160_40_cifar10_basic_pretraining_model.pt'
