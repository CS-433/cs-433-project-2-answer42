 => Using seed 2020
 => Using device: cuda
Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./cifar100/cifar-100-python.tar.gz
Extracting ./cifar100/cifar-100-python.tar.gz to ./cifar100
Files already downloaded and verified
=> Using a preset learning rate schedule:
{0: 0.1, 80: 0.010000000000000002, 120: 0.001}
Pretraining epoch 0: loss 0.0661028, train_acc 5.94%, test_acc 5.97%
Pretraining epoch 1: loss 0.0606453, train_acc 9.68%, test_acc 10.38%
Pretraining epoch 2: loss 0.0568273, train_acc 13.29%, test_acc 14.26%
Pretraining epoch 3: loss 0.0539923, train_acc 16.47%, test_acc 16.98%
Pretraining epoch 4: loss 0.0519502, train_acc 13.19%, test_acc 12.95%
Pretraining epoch 5: loss 0.0493558, train_acc 20.49%, test_acc 21.18%
Pretraining epoch 6: loss 0.0450390, train_acc 27.52%, test_acc 27.22%
Pretraining epoch 7: loss 0.0423032, train_acc 29.77%, test_acc 29.26%
Pretraining epoch 8: loss 0.0400439, train_acc 33.10%, test_acc 32.99%
Pretraining epoch 9: loss 0.0379641, train_acc 36.53%, test_acc 35.32%
Pretraining epoch 10: loss 0.0365705, train_acc 29.24%, test_acc 31.13%
Pretraining epoch 11: loss 0.0358968, train_acc 39.78%, test_acc 38.78%
Pretraining epoch 12: loss 0.0336292, train_acc 38.56%, test_acc 37.35%
Pretraining epoch 13: loss 0.0334059, train_acc 42.70%, test_acc 40.56%
Pretraining epoch 14: loss 0.0318463, train_acc 39.81%, test_acc 38.89%
Pretraining epoch 15: loss 0.0324186, train_acc 47.40%, test_acc 45.82%
Pretraining epoch 16: loss 0.0302096, train_acc 48.21%, test_acc 45.84%
Pretraining epoch 17: loss 0.0291268, train_acc 49.10%, test_acc 46.44%
Pretraining epoch 18: loss 0.0283232, train_acc 50.15%, test_acc 46.00%
Pretraining epoch 19: loss 0.0276122, train_acc 51.62%, test_acc 48.20%
Pretraining epoch 20: loss 0.0271229, train_acc 53.90%, test_acc 50.18%
Pretraining epoch 21: loss 0.0265988, train_acc 53.19%, test_acc 48.75%
Pretraining epoch 22: loss 0.0259364, train_acc 52.30%, test_acc 48.41%
Pretraining epoch 23: loss 0.0255219, train_acc 55.40%, test_acc 51.48%
Pretraining epoch 24: loss 0.0252500, train_acc 56.27%, test_acc 51.33%
Pretraining epoch 25: loss 0.0249486, train_acc 55.97%, test_acc 51.81%
Pretraining epoch 26: loss 0.0253205, train_acc 47.48%, test_acc 44.57%
Pretraining epoch 27: loss 0.0253752, train_acc 57.49%, test_acc 52.81%
Pretraining epoch 28: loss 0.0238194, train_acc 57.23%, test_acc 51.72%
Pretraining epoch 29: loss 0.0233395, train_acc 58.19%, test_acc 52.58%
Pretraining epoch 30: loss 0.0228525, train_acc 56.43%, test_acc 51.12%
Pretraining epoch 31: loss 0.0227270, train_acc 60.04%, test_acc 54.66%
Pretraining epoch 32: loss 0.0228576, train_acc 58.42%, test_acc 52.69%
Pretraining epoch 33: loss 0.0220979, train_acc 61.11%, test_acc 54.39%
Pretraining epoch 34: loss 0.0220208, train_acc 58.43%, test_acc 52.08%
Pretraining epoch 35: loss 0.0215273, train_acc 62.41%, test_acc 55.13%
Pretraining epoch 36: loss 0.0211594, train_acc 61.83%, test_acc 55.18%
Pretraining epoch 37: loss 0.0210892, train_acc 62.04%, test_acc 55.29%
Pretraining epoch 38: loss 0.0213389, train_acc 58.97%, test_acc 52.15%
Pretraining epoch 39: loss 0.0206825, train_acc 63.21%, test_acc 55.72%
Pretraining epoch 40: loss 0.0203807, train_acc 62.88%, test_acc 55.67%
Pretraining epoch 41: loss 0.0200216, train_acc 63.12%, test_acc 55.87%
Pretraining epoch 42: loss 0.0202025, train_acc 62.99%, test_acc 56.01%
Pretraining epoch 43: loss 0.0197387, train_acc 62.42%, test_acc 55.01%
Pretraining epoch 44: loss 0.0194566, train_acc 64.62%, test_acc 56.94%
Pretraining epoch 45: loss 0.0206561, train_acc 64.14%, test_acc 56.46%
Pretraining epoch 46: loss 0.0192640, train_acc 66.20%, test_acc 57.92%
Pretraining epoch 47: loss 0.0190804, train_acc 64.19%, test_acc 55.78%
Pretraining epoch 48: loss 0.0190206, train_acc 66.23%, test_acc 58.02%
Pretraining epoch 49: loss 0.0186582, train_acc 63.51%, test_acc 55.72%
Pretraining epoch 50: loss 0.0187312, train_acc 67.11%, test_acc 59.18%
Pretraining epoch 51: loss 0.0184846, train_acc 65.15%, test_acc 56.47%
Pretraining epoch 52: loss 0.0181215, train_acc 51.24%, test_acc 45.55%
Pretraining epoch 53: loss 0.0183779, train_acc 66.46%, test_acc 58.05%
Pretraining epoch 54: loss 0.0179341, train_acc 62.82%, test_acc 54.35%
Pretraining epoch 55: loss 0.0183521, train_acc 68.66%, test_acc 58.83%
Pretraining epoch 56: loss 0.0176964, train_acc 67.77%, test_acc 58.46%
Pretraining epoch 57: loss 0.0174417, train_acc 64.43%, test_acc 56.13%
Pretraining epoch 58: loss 0.0183167, train_acc 68.60%, test_acc 58.76%
Pretraining epoch 59: loss 0.0172711, train_acc 65.32%, test_acc 56.40%
Pretraining epoch 60: loss 0.0173715, train_acc 67.61%, test_acc 58.88%
Pretraining epoch 61: loss 0.0170970, train_acc 66.65%, test_acc 57.73%
Pretraining epoch 62: loss 0.0171383, train_acc 70.65%, test_acc 60.09%
Pretraining epoch 63: loss 0.0167865, train_acc 69.09%, test_acc 58.58%
Pretraining epoch 64: loss 0.0169156, train_acc 69.24%, test_acc 58.61%
Pretraining epoch 65: loss 0.0166444, train_acc 67.05%, test_acc 58.25%
Pretraining epoch 66: loss 0.0166344, train_acc 67.91%, test_acc 57.58%
Pretraining epoch 67: loss 0.0163356, train_acc 69.32%, test_acc 59.84%
Pretraining epoch 68: loss 0.0165894, train_acc 65.76%, test_acc 55.44%
Pretraining epoch 69: loss 0.0163989, train_acc 71.79%, test_acc 60.06%
Pretraining epoch 70: loss 0.0162326, train_acc 68.99%, test_acc 58.58%
Pretraining epoch 71: loss 0.0162625, train_acc 70.40%, test_acc 59.49%
Pretraining epoch 72: loss 0.0162992, train_acc 70.16%, test_acc 59.60%
Pretraining epoch 73: loss 0.0160073, train_acc 69.89%, test_acc 58.76%
Pretraining epoch 74: loss 0.0159490, train_acc 71.10%, test_acc 59.78%
Pretraining epoch 75: loss 0.0159790, train_acc 64.92%, test_acc 55.54%
Pretraining epoch 76: loss 0.0157836, train_acc 72.86%, test_acc 61.09%
Pretraining epoch 77: loss 0.0155350, train_acc 65.47%, test_acc 55.65%
Pretraining epoch 78: loss 0.0159211, train_acc 72.74%, test_acc 61.20%
Pretraining epoch 79: loss 0.0156096, train_acc 71.56%, test_acc 60.03%
Pretraining epoch 80: loss 0.0088143, train_acc 87.29%, test_acc 69.79%
Pretraining epoch 81: loss 0.0069575, train_acc 88.77%, test_acc 70.35%
Pretraining epoch 82: loss 0.0063607, train_acc 89.84%, test_acc 70.51%
Pretraining epoch 83: loss 0.0057922, train_acc 90.62%, test_acc 71.13%
Pretraining epoch 84: loss 0.0053573, train_acc 91.23%, test_acc 70.66%
Pretraining epoch 85: loss 0.0050068, train_acc 91.91%, test_acc 70.50%
Pretraining epoch 86: loss 0.0047652, train_acc 92.73%, test_acc 70.45%
Pretraining epoch 87: loss 0.0044879, train_acc 93.17%, test_acc 70.31%
Pretraining epoch 88: loss 0.0043037, train_acc 93.23%, test_acc 70.69%
Pretraining epoch 89: loss 0.0040270, train_acc 93.76%, test_acc 70.38%
Pretraining epoch 90: loss 0.0038948, train_acc 94.18%, test_acc 70.28%
Pretraining epoch 91: loss 0.0037097, train_acc 94.45%, test_acc 70.03%
Pretraining epoch 92: loss 0.0035127, train_acc 94.67%, test_acc 70.58%
Pretraining epoch 93: loss 0.0033571, train_acc 95.08%, test_acc 70.42%
Pretraining epoch 94: loss 0.0032786, train_acc 95.35%, test_acc 70.01%
Pretraining epoch 95: loss 0.0031073, train_acc 95.48%, test_acc 70.51%
Pretraining epoch 96: loss 0.0030045, train_acc 95.72%, test_acc 70.20%
Pretraining epoch 97: loss 0.0029181, train_acc 95.76%, test_acc 69.66%
Pretraining epoch 98: loss 0.0028274, train_acc 96.26%, test_acc 70.06%
Pretraining epoch 99: loss 0.0027135, train_acc 96.28%, test_acc 70.20%
Pretraining epoch 100: loss 0.0025453, train_acc 96.28%, test_acc 70.05%
Pretraining epoch 101: loss 0.0025807, train_acc 96.30%, test_acc 69.45%
Pretraining epoch 102: loss 0.0024509, train_acc 96.54%, test_acc 70.06%
Pretraining epoch 103: loss 0.0023755, train_acc 96.93%, test_acc 69.83%
Pretraining epoch 104: loss 0.0024161, train_acc 96.92%, test_acc 69.57%
Pretraining epoch 105: loss 0.0022292, train_acc 96.68%, test_acc 69.13%
Pretraining epoch 106: loss 0.0022774, train_acc 96.90%, test_acc 69.25%
Pretraining epoch 107: loss 0.0021120, train_acc 97.15%, test_acc 69.50%
Pretraining epoch 108: loss 0.0021653, train_acc 96.95%, test_acc 68.89%
Pretraining epoch 109: loss 0.0020765, train_acc 97.12%, test_acc 68.96%
Pretraining epoch 110: loss 0.0020189, train_acc 97.59%, test_acc 69.51%
Pretraining epoch 111: loss 0.0020716, train_acc 97.42%, test_acc 69.46%
Pretraining epoch 112: loss 0.0019020, train_acc 97.43%, test_acc 69.13%
Pretraining epoch 113: loss 0.0018933, train_acc 97.56%, test_acc 69.31%
Pretraining epoch 114: loss 0.0019099, train_acc 97.41%, test_acc 68.94%
Pretraining epoch 115: loss 0.0019047, train_acc 97.69%, test_acc 69.88%
Pretraining epoch 116: loss 0.0018419, train_acc 97.45%, test_acc 69.46%
Pretraining epoch 117: loss 0.0018548, train_acc 97.73%, test_acc 69.12%
Pretraining epoch 118: loss 0.0018168, train_acc 97.71%, test_acc 69.59%
Pretraining epoch 119: loss 0.0017749, train_acc 97.45%, test_acc 68.86%
Pretraining epoch 120: loss 0.0011344, train_acc 99.12%, test_acc 70.82%
Pretraining epoch 121: loss 0.0008396, train_acc 99.25%, test_acc 70.71%
Pretraining epoch 122: loss 0.0007519, train_acc 99.38%, test_acc 70.79%
Pretraining epoch 123: loss 0.0006909, train_acc 99.43%, test_acc 71.18%
Pretraining epoch 124: loss 0.0006478, train_acc 99.51%, test_acc 70.89%
Pretraining epoch 125: loss 0.0006205, train_acc 99.48%, test_acc 71.29%
Pretraining epoch 126: loss 0.0006140, train_acc 99.58%, test_acc 71.08%
Pretraining epoch 127: loss 0.0005876, train_acc 99.52%, test_acc 71.08%
Pretraining epoch 128: loss 0.0005563, train_acc 99.59%, test_acc 71.26%
Pretraining epoch 129: loss 0.0005335, train_acc 99.61%, test_acc 71.14%
Pretraining epoch 130: loss 0.0005112, train_acc 99.59%, test_acc 71.25%
Pretraining epoch 131: loss 0.0005030, train_acc 99.62%, test_acc 71.19%
Pretraining epoch 132: loss 0.0005112, train_acc 99.67%, test_acc 71.11%
Pretraining epoch 133: loss 0.0004823, train_acc 99.64%, test_acc 71.09%
Pretraining epoch 134: loss 0.0004763, train_acc 99.70%, test_acc 71.09%
Pretraining epoch 135: loss 0.0004743, train_acc 99.70%, test_acc 71.03%
Pretraining epoch 136: loss 0.0004628, train_acc 99.72%, test_acc 71.00%
Pretraining epoch 137: loss 0.0004751, train_acc 99.69%, test_acc 71.05%
Pretraining epoch 138: loss 0.0004414, train_acc 99.69%, test_acc 71.29%
Pretraining epoch 139: loss 0.0004519, train_acc 99.73%, test_acc 71.15%
Pretraining epoch 140: loss 0.0004208, train_acc 99.73%, test_acc 71.28%
Pretraining epoch 141: loss 0.0004068, train_acc 99.78%, test_acc 71.16%
Pretraining epoch 142: loss 0.0003857, train_acc 99.73%, test_acc 71.19%
Pretraining epoch 143: loss 0.0004047, train_acc 99.75%, test_acc 71.00%
Pretraining epoch 144: loss 0.0003702, train_acc 99.79%, test_acc 71.33%
Pretraining epoch 145: loss 0.0003912, train_acc 99.76%, test_acc 71.10%
Pretraining epoch 146: loss 0.0004177, train_acc 99.76%, test_acc 71.24%
Pretraining epoch 147: loss 0.0003794, train_acc 99.75%, test_acc 71.35%
Pretraining epoch 148: loss 0.0003740, train_acc 99.79%, test_acc 71.24%
Pretraining epoch 149: loss 0.0003741, train_acc 99.80%, test_acc 71.45%
Pretraining epoch 150: loss 0.0003651, train_acc 99.79%, test_acc 71.38%
Pretraining epoch 151: loss 0.0003511, train_acc 99.80%, test_acc 71.21%
Pretraining epoch 152: loss 0.0003612, train_acc 99.78%, test_acc 71.26%
Pretraining epoch 153: loss 0.0003542, train_acc 99.80%, test_acc 71.20%
Pretraining epoch 154: loss 0.0003475, train_acc 99.81%, test_acc 71.37%
Pretraining epoch 155: loss 0.0003399, train_acc 99.77%, test_acc 71.19%
Pretraining epoch 156: loss 0.0003439, train_acc 99.83%, test_acc 71.22%
Pretraining epoch 157: loss 0.0003348, train_acc 99.81%, test_acc 71.24%
Pretraining epoch 158: loss 0.0003299, train_acc 99.82%, test_acc 71.26%
Pretraining epoch 159: loss 0.0003254, train_acc 99.78%, test_acc 71.04%
 => Saving model at '/content/drive/MyDrive/pruningData/partially_trained/pretrained_models/vgg19_160_40_cifar100_basic_pretraining_model.pt'
