 => Using seed 2020
 => Using device: cuda
Files already downloaded and verified
Files already downloaded and verified
=> Using a preset learning rate schedule:
{0: 0.1, 80: 0.010000000000000002, 120: 0.001}
Pretraining epoch 0: loss 0.0273856, train_acc 36.95%, test_acc 38.58%
Pretraining epoch 1: loss 0.0210341, train_acc 54.84%, test_acc 55.68%
Pretraining epoch 2: loss 0.0168218, train_acc 67.35%, test_acc 68.08%
Pretraining epoch 3: loss 0.0143927, train_acc 64.01%, test_acc 61.76%
Pretraining epoch 4: loss 0.0125368, train_acc 71.58%, test_acc 71.43%
Pretraining epoch 5: loss 0.0118741, train_acc 73.02%, test_acc 70.93%
Pretraining epoch 6: loss 0.0106341, train_acc 79.29%, test_acc 78.64%
Pretraining epoch 7: loss 0.0100219, train_acc 79.63%, test_acc 79.62%
Pretraining epoch 8: loss 0.0093645, train_acc 82.88%, test_acc 81.36%
Pretraining epoch 9: loss 0.0087696, train_acc 77.28%, test_acc 76.18%
Pretraining epoch 10: loss 0.0094728, train_acc 82.86%, test_acc 81.77%
Pretraining epoch 11: loss 0.0081283, train_acc 82.50%, test_acc 80.31%
Pretraining epoch 12: loss 0.0077117, train_acc 84.06%, test_acc 82.16%
Pretraining epoch 13: loss 0.0075109, train_acc 84.63%, test_acc 82.96%
Pretraining epoch 14: loss 0.0071632, train_acc 85.87%, test_acc 83.86%
Pretraining epoch 15: loss 0.0070044, train_acc 87.08%, test_acc 85.60%
Pretraining epoch 16: loss 0.0068461, train_acc 87.49%, test_acc 84.25%
Pretraining epoch 17: loss 0.0064574, train_acc 85.85%, test_acc 83.67%
Pretraining epoch 18: loss 0.0065133, train_acc 87.30%, test_acc 84.54%
Pretraining epoch 19: loss 0.0062180, train_acc 86.04%, test_acc 84.19%
Pretraining epoch 20: loss 0.0060753, train_acc 87.10%, test_acc 83.47%
Pretraining epoch 21: loss 0.0060359, train_acc 87.22%, test_acc 84.49%
Pretraining epoch 22: loss 0.0056988, train_acc 88.02%, test_acc 85.34%
Pretraining epoch 23: loss 0.0060526, train_acc 86.06%, test_acc 83.36%
Pretraining epoch 24: loss 0.0056839, train_acc 88.30%, test_acc 84.99%
Pretraining epoch 25: loss 0.0056388, train_acc 89.58%, test_acc 86.57%
Pretraining epoch 26: loss 0.0054861, train_acc 89.39%, test_acc 85.82%
Pretraining epoch 27: loss 0.0053889, train_acc 88.32%, test_acc 85.34%
Pretraining epoch 28: loss 0.0053990, train_acc 89.82%, test_acc 86.88%
Pretraining epoch 29: loss 0.0053195, train_acc 89.06%, test_acc 85.88%
Pretraining epoch 30: loss 0.0052738, train_acc 89.61%, test_acc 85.71%
Pretraining epoch 31: loss 0.0050605, train_acc 89.05%, test_acc 85.51%
Pretraining epoch 32: loss 0.0050648, train_acc 89.87%, test_acc 86.20%
Pretraining epoch 33: loss 0.0049891, train_acc 88.36%, test_acc 84.88%
Pretraining epoch 34: loss 0.0050459, train_acc 89.40%, test_acc 86.40%
Pretraining epoch 35: loss 0.0048429, train_acc 88.03%, test_acc 85.26%
Pretraining epoch 36: loss 0.0052129, train_acc 87.60%, test_acc 84.63%
Pretraining epoch 37: loss 0.0046761, train_acc 87.74%, test_acc 84.26%
Pretraining epoch 38: loss 0.0047298, train_acc 89.47%, test_acc 86.04%
Pretraining epoch 39: loss 0.0047189, train_acc 91.12%, test_acc 87.26%
Pretraining epoch 40: loss 0.0046628, train_acc 91.52%, test_acc 88.10%
Pretraining epoch 41: loss 0.0046447, train_acc 90.37%, test_acc 86.87%
Pretraining epoch 42: loss 0.0047856, train_acc 89.58%, test_acc 86.32%
Pretraining epoch 43: loss 0.0046675, train_acc 90.36%, test_acc 87.14%
Pretraining epoch 44: loss 0.0044400, train_acc 86.79%, test_acc 82.49%
Pretraining epoch 45: loss 0.0050329, train_acc 90.98%, test_acc 87.32%
Pretraining epoch 46: loss 0.0044305, train_acc 91.13%, test_acc 87.55%
Pretraining epoch 47: loss 0.0043194, train_acc 92.63%, test_acc 88.40%
Pretraining epoch 48: loss 0.0042683, train_acc 90.45%, test_acc 86.61%
Pretraining epoch 49: loss 0.0045124, train_acc 91.03%, test_acc 87.39%
Pretraining epoch 50: loss 0.0043189, train_acc 92.31%, test_acc 88.46%
Pretraining epoch 51: loss 0.0043557, train_acc 91.58%, test_acc 88.10%
Pretraining epoch 52: loss 0.0043167, train_acc 85.58%, test_acc 80.73%
Pretraining epoch 53: loss 0.0043715, train_acc 88.13%, test_acc 84.69%
Pretraining epoch 54: loss 0.0042412, train_acc 91.13%, test_acc 87.24%
Pretraining epoch 55: loss 0.0041632, train_acc 89.56%, test_acc 86.68%
Pretraining epoch 56: loss 0.0041876, train_acc 90.82%, test_acc 86.63%
Pretraining epoch 57: loss 0.0041562, train_acc 91.81%, test_acc 87.25%
Pretraining epoch 58: loss 0.0046327, train_acc 92.42%, test_acc 87.60%
Pretraining epoch 59: loss 0.0040465, train_acc 92.14%, test_acc 87.51%
Pretraining epoch 60: loss 0.0041440, train_acc 91.48%, test_acc 87.57%
Pretraining epoch 61: loss 0.0041426, train_acc 90.76%, test_acc 86.53%
Pretraining epoch 62: loss 0.0041296, train_acc 91.75%, test_acc 87.87%
Pretraining epoch 63: loss 0.0041161, train_acc 90.82%, test_acc 86.75%
Pretraining epoch 64: loss 0.0042511, train_acc 90.11%, test_acc 86.29%
Pretraining epoch 65: loss 0.0040395, train_acc 90.77%, test_acc 87.06%
Pretraining epoch 66: loss 0.0040786, train_acc 90.92%, test_acc 87.02%
Pretraining epoch 67: loss 0.0039717, train_acc 90.91%, test_acc 87.51%
Pretraining epoch 68: loss 0.0039705, train_acc 91.44%, test_acc 87.29%
Pretraining epoch 69: loss 0.0039963, train_acc 92.62%, test_acc 88.75%
Pretraining epoch 70: loss 0.0040163, train_acc 90.96%, test_acc 86.45%
Pretraining epoch 71: loss 0.0039279, train_acc 92.35%, test_acc 87.91%
Pretraining epoch 72: loss 0.0038191, train_acc 93.46%, test_acc 89.29%
Pretraining epoch 73: loss 0.0039209, train_acc 93.15%, test_acc 88.97%
Pretraining epoch 74: loss 0.0039779, train_acc 90.53%, test_acc 86.44%
Pretraining epoch 75: loss 0.0038469, train_acc 90.77%, test_acc 86.98%
Pretraining epoch 76: loss 0.0039616, train_acc 91.54%, test_acc 87.52%
Pretraining epoch 77: loss 0.0039375, train_acc 94.05%, test_acc 89.15%
Pretraining epoch 78: loss 0.0039204, train_acc 92.36%, test_acc 88.11%
Pretraining epoch 79: loss 0.0038782, train_acc 92.86%, test_acc 88.58%
Pretraining epoch 80: loss 0.0017619, train_acc 97.60%, test_acc 92.49%
Pretraining epoch 81: loss 0.0012046, train_acc 98.20%, test_acc 92.74%
Pretraining epoch 82: loss 0.0010521, train_acc 98.49%, test_acc 92.87%
Pretraining epoch 83: loss 0.0009004, train_acc 98.59%, test_acc 92.86%
Pretraining epoch 84: loss 0.0008090, train_acc 98.83%, test_acc 92.83%
Pretraining epoch 85: loss 0.0007075, train_acc 98.94%, test_acc 92.61%
Pretraining epoch 86: loss 0.0006301, train_acc 98.99%, test_acc 92.44%
Pretraining epoch 87: loss 0.0006118, train_acc 99.06%, test_acc 92.62%
Pretraining epoch 88: loss 0.0005506, train_acc 99.24%, test_acc 92.84%
Pretraining epoch 89: loss 0.0005033, train_acc 99.30%, test_acc 92.80%
Pretraining epoch 90: loss 0.0004940, train_acc 99.24%, test_acc 92.88%
Pretraining epoch 91: loss 0.0004604, train_acc 99.40%, test_acc 93.02%
Pretraining epoch 92: loss 0.0004070, train_acc 99.30%, test_acc 92.68%
Pretraining epoch 93: loss 0.0004076, train_acc 99.44%, test_acc 92.86%
Pretraining epoch 94: loss 0.0003929, train_acc 99.46%, test_acc 92.72%
Pretraining epoch 95: loss 0.0003476, train_acc 99.46%, test_acc 92.90%
Pretraining epoch 96: loss 0.0003459, train_acc 99.59%, test_acc 92.91%
Pretraining epoch 97: loss 0.0003289, train_acc 99.60%, test_acc 92.68%
Pretraining epoch 98: loss 0.0003314, train_acc 99.55%, test_acc 92.89%
Pretraining epoch 99: loss 0.0003256, train_acc 99.64%, test_acc 92.81%
Pretraining epoch 100: loss 0.0002954, train_acc 99.47%, test_acc 92.68%
Pretraining epoch 101: loss 0.0003033, train_acc 99.59%, test_acc 92.75%
Pretraining epoch 102: loss 0.0003116, train_acc 99.57%, test_acc 92.68%
Pretraining epoch 103: loss 0.0002825, train_acc 99.69%, test_acc 92.83%
Pretraining epoch 104: loss 0.0002658, train_acc 99.65%, test_acc 92.83%
Pretraining epoch 105: loss 0.0002472, train_acc 99.60%, test_acc 92.96%
Pretraining epoch 106: loss 0.0002683, train_acc 99.62%, test_acc 92.89%
Pretraining epoch 107: loss 0.0002773, train_acc 99.64%, test_acc 92.94%
Pretraining epoch 108: loss 0.0002726, train_acc 99.56%, test_acc 92.68%
Pretraining epoch 109: loss 0.0002488, train_acc 99.65%, test_acc 92.84%
Pretraining epoch 110: loss 0.0002596, train_acc 99.67%, test_acc 92.78%
Pretraining epoch 111: loss 0.0002728, train_acc 99.60%, test_acc 92.62%
Pretraining epoch 112: loss 0.0002594, train_acc 99.58%, test_acc 92.46%
Pretraining epoch 113: loss 0.0002657, train_acc 99.71%, test_acc 92.67%
Pretraining epoch 114: loss 0.0002810, train_acc 99.55%, test_acc 92.66%
Pretraining epoch 115: loss 0.0002617, train_acc 99.73%, test_acc 92.72%
Pretraining epoch 116: loss 0.0002584, train_acc 99.66%, test_acc 92.45%
Pretraining epoch 117: loss 0.0002200, train_acc 99.74%, test_acc 92.35%
Pretraining epoch 118: loss 0.0002374, train_acc 99.60%, test_acc 92.52%
Pretraining epoch 119: loss 0.0002429, train_acc 99.66%, test_acc 92.96%
Pretraining epoch 120: loss 0.0001644, train_acc 99.84%, test_acc 92.91%
Pretraining epoch 121: loss 0.0001231, train_acc 99.89%, test_acc 93.18%
Pretraining epoch 122: loss 0.0001009, train_acc 99.90%, test_acc 93.27%
Pretraining epoch 123: loss 0.0000899, train_acc 99.92%, test_acc 93.10%
Pretraining epoch 124: loss 0.0000832, train_acc 99.92%, test_acc 93.23%
Pretraining epoch 125: loss 0.0000706, train_acc 99.93%, test_acc 93.28%
Pretraining epoch 126: loss 0.0000667, train_acc 99.95%, test_acc 93.35%
Pretraining epoch 127: loss 0.0000622, train_acc 99.97%, test_acc 93.32%
Pretraining epoch 128: loss 0.0000618, train_acc 99.94%, test_acc 93.33%
Pretraining epoch 129: loss 0.0000609, train_acc 99.95%, test_acc 93.27%
Pretraining epoch 130: loss 0.0000558, train_acc 99.95%, test_acc 93.37%
Pretraining epoch 131: loss 0.0000469, train_acc 99.95%, test_acc 93.33%
Pretraining epoch 132: loss 0.0000539, train_acc 99.97%, test_acc 93.35%
Pretraining epoch 133: loss 0.0000498, train_acc 99.97%, test_acc 93.38%
Pretraining epoch 134: loss 0.0000445, train_acc 99.96%, test_acc 93.37%
Pretraining epoch 135: loss 0.0000447, train_acc 99.97%, test_acc 93.35%
Pretraining epoch 136: loss 0.0000475, train_acc 99.96%, test_acc 93.43%
Pretraining epoch 137: loss 0.0000422, train_acc 99.96%, test_acc 93.46%
Pretraining epoch 138: loss 0.0000449, train_acc 99.96%, test_acc 93.37%
Pretraining epoch 139: loss 0.0000344, train_acc 99.97%, test_acc 93.38%
Pretraining epoch 140: loss 0.0000365, train_acc 99.98%, test_acc 93.42%
Pretraining epoch 141: loss 0.0000484, train_acc 99.97%, test_acc 93.40%
Pretraining epoch 142: loss 0.0000462, train_acc 99.98%, test_acc 93.29%
Pretraining epoch 143: loss 0.0000439, train_acc 99.98%, test_acc 93.43%
Pretraining epoch 144: loss 0.0000407, train_acc 99.97%, test_acc 93.52%
Pretraining epoch 145: loss 0.0000369, train_acc 99.98%, test_acc 93.49%
Pretraining epoch 146: loss 0.0000370, train_acc 99.98%, test_acc 93.45%
Pretraining epoch 147: loss 0.0000362, train_acc 99.97%, test_acc 93.51%
Pretraining epoch 148: loss 0.0000274, train_acc 99.98%, test_acc 93.50%
Pretraining epoch 149: loss 0.0000385, train_acc 99.97%, test_acc 93.46%
Pretraining epoch 150: loss 0.0000323, train_acc 99.98%, test_acc 93.45%
Pretraining epoch 151: loss 0.0000370, train_acc 99.97%, test_acc 93.50%
Pretraining epoch 152: loss 0.0000414, train_acc 99.98%, test_acc 93.36%
Pretraining epoch 153: loss 0.0000290, train_acc 99.99%, test_acc 93.52%
Pretraining epoch 154: loss 0.0000257, train_acc 99.97%, test_acc 93.50%
Pretraining epoch 155: loss 0.0000271, train_acc 99.99%, test_acc 93.38%
Pretraining epoch 156: loss 0.0000241, train_acc 99.97%, test_acc 93.46%
Pretraining epoch 157: loss 0.0000303, train_acc 99.98%, test_acc 93.47%
Pretraining epoch 158: loss 0.0000272, train_acc 99.98%, test_acc 93.49%
Pretraining epoch 159: loss 0.0000345, train_acc 99.98%, test_acc 93.45%
 => Saving model at '/content/drive/MyDrive/pruningData/partially_trained/pretrained_models/vgg19_160_40_cifar10_basic_pretraining_model.pt'
