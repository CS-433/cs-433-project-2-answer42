=> Using a preset learning rate schedule:
{0: 0.1, 80: 0.010000000000000002, 120: 0.001}
 *** Used device: cuda
Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./cifar100/cifar-100-python.tar.gz
Extracting ./cifar100/cifar-100-python.tar.gz to ./cifar100
Files already downloaded and verified
 *** Mask calcualted (keeping 5.0% weights)
Epoch 0: loss 0.0653321, train_acc 11.01%, test_acc 11.20%
Epoch 1: loss 0.0581666, train_acc 15.70%, test_acc 15.88%
Epoch 2: loss 0.0530385, train_acc 21.81%, test_acc 21.58%
Epoch 3: loss 0.0491070, train_acc 25.25%, test_acc 25.33%
Epoch 4: loss 0.0462983, train_acc 30.19%, test_acc 30.15%
Epoch 5: loss 0.0442001, train_acc 31.02%, test_acc 30.71%
Epoch 6: loss 0.0425259, train_acc 24.96%, test_acc 24.49%
Epoch 7: loss 0.0412805, train_acc 32.27%, test_acc 31.61%
Epoch 8: loss 0.0404010, train_acc 38.28%, test_acc 36.75%
Epoch 9: loss 0.0393864, train_acc 33.53%, test_acc 33.30%
Epoch 10: loss 0.0388190, train_acc 35.18%, test_acc 34.12%
Epoch 11: loss 0.0381394, train_acc 38.30%, test_acc 35.65%
Epoch 12: loss 0.0375814, train_acc 40.36%, test_acc 38.49%
Epoch 13: loss 0.0371834, train_acc 40.50%, test_acc 37.73%
Epoch 14: loss 0.0367197, train_acc 35.39%, test_acc 33.41%
Epoch 15: loss 0.0363918, train_acc 39.98%, test_acc 37.75%
Epoch 16: loss 0.0359887, train_acc 38.77%, test_acc 36.23%
Epoch 17: loss 0.0357764, train_acc 42.61%, test_acc 39.56%
Epoch 18: loss 0.0354002, train_acc 42.92%, test_acc 40.88%
Epoch 19: loss 0.0351079, train_acc 40.01%, test_acc 36.62%
Epoch 20: loss 0.0349336, train_acc 41.61%, test_acc 38.36%
Epoch 21: loss 0.0346233, train_acc 42.81%, test_acc 39.68%
Epoch 22: loss 0.0345125, train_acc 41.54%, test_acc 38.64%
Epoch 23: loss 0.0342455, train_acc 43.85%, test_acc 41.40%
Epoch 24: loss 0.0341488, train_acc 42.55%, test_acc 40.05%
Epoch 25: loss 0.0339663, train_acc 43.43%, test_acc 41.31%
Epoch 26: loss 0.0338710, train_acc 46.02%, test_acc 43.24%
Epoch 27: loss 0.0337003, train_acc 43.65%, test_acc 39.99%
Epoch 28: loss 0.0336764, train_acc 42.78%, test_acc 40.09%
Epoch 29: loss 0.0334696, train_acc 44.19%, test_acc 41.63%
Epoch 30: loss 0.0333857, train_acc 45.13%, test_acc 42.09%
Epoch 31: loss 0.0332620, train_acc 44.41%, test_acc 41.82%
Epoch 32: loss 0.0332353, train_acc 44.42%, test_acc 41.28%
Epoch 33: loss 0.0330465, train_acc 46.67%, test_acc 43.71%
Epoch 34: loss 0.0330166, train_acc 45.35%, test_acc 43.82%
Epoch 35: loss 0.0328880, train_acc 44.12%, test_acc 41.55%
Epoch 36: loss 0.0328943, train_acc 43.63%, test_acc 40.91%
Epoch 37: loss 0.0327277, train_acc 44.24%, test_acc 41.22%
Epoch 38: loss 0.0327099, train_acc 46.38%, test_acc 42.92%
Epoch 39: loss 0.0325626, train_acc 45.92%, test_acc 42.15%
Epoch 40: loss 0.0325529, train_acc 44.87%, test_acc 42.46%
Epoch 41: loss 0.0326585, train_acc 43.11%, test_acc 39.95%
Epoch 42: loss 0.0322794, train_acc 45.06%, test_acc 41.59%
Epoch 43: loss 0.0322889, train_acc 44.00%, test_acc 41.56%
Epoch 44: loss 0.0324142, train_acc 42.93%, test_acc 39.75%
Epoch 45: loss 0.0323033, train_acc 44.42%, test_acc 40.53%
Epoch 46: loss 0.0322406, train_acc 44.77%, test_acc 42.06%
Epoch 47: loss 0.0321776, train_acc 43.06%, test_acc 41.12%
Epoch 48: loss 0.0321592, train_acc 46.69%, test_acc 43.21%
Epoch 49: loss 0.0320237, train_acc 41.87%, test_acc 38.74%
Epoch 50: loss 0.0320427, train_acc 42.68%, test_acc 39.25%
Epoch 51: loss 0.0320060, train_acc 45.04%, test_acc 41.43%
Epoch 52: loss 0.0319688, train_acc 47.21%, test_acc 43.38%
Epoch 53: loss 0.0318845, train_acc 42.93%, test_acc 40.28%
Epoch 54: loss 0.0317945, train_acc 48.59%, test_acc 45.50%
Epoch 55: loss 0.0318312, train_acc 44.15%, test_acc 41.10%
Epoch 56: loss 0.0318493, train_acc 43.95%, test_acc 41.11%
Epoch 57: loss 0.0318119, train_acc 46.92%, test_acc 43.37%
Epoch 58: loss 0.0316887, train_acc 45.65%, test_acc 42.85%
Epoch 59: loss 0.0317458, train_acc 43.16%, test_acc 38.94%
Epoch 60: loss 0.0316567, train_acc 47.39%, test_acc 44.56%
Epoch 61: loss 0.0315754, train_acc 45.81%, test_acc 42.73%
Epoch 62: loss 0.0316246, train_acc 47.46%, test_acc 44.68%
Epoch 63: loss 0.0314044, train_acc 47.18%, test_acc 43.66%
Epoch 64: loss 0.0314763, train_acc 42.32%, test_acc 37.80%
Epoch 65: loss 0.0315317, train_acc 46.99%, test_acc 43.76%
Epoch 66: loss 0.0313588, train_acc 46.22%, test_acc 43.07%
Epoch 67: loss 0.0314817, train_acc 45.57%, test_acc 42.10%
Epoch 68: loss 0.0313993, train_acc 46.99%, test_acc 44.02%
Epoch 69: loss 0.0313447, train_acc 48.23%, test_acc 44.49%
Epoch 70: loss 0.0313208, train_acc 45.05%, test_acc 41.14%
Epoch 71: loss 0.0314004, train_acc 46.27%, test_acc 42.94%
Epoch 72: loss 0.0312861, train_acc 44.69%, test_acc 42.43%
Epoch 73: loss 0.0312227, train_acc 45.89%, test_acc 42.66%
Epoch 74: loss 0.0313184, train_acc 48.22%, test_acc 44.05%
Epoch 75: loss 0.0312297, train_acc 42.86%, test_acc 39.76%
Epoch 76: loss 0.0311700, train_acc 47.50%, test_acc 44.14%
Epoch 77: loss 0.0311413, train_acc 44.12%, test_acc 40.13%
Epoch 78: loss 0.0311379, train_acc 47.64%, test_acc 44.16%
Epoch 79: loss 0.0311590, train_acc 44.92%, test_acc 41.05%
Epoch 80: loss 0.0266859, train_acc 58.52%, test_acc 53.47%
Epoch 81: loss 0.0255257, train_acc 59.20%, test_acc 53.53%
Epoch 82: loss 0.0250752, train_acc 59.75%, test_acc 53.91%
Epoch 83: loss 0.0248040, train_acc 59.85%, test_acc 54.02%
Epoch 84: loss 0.0247005, train_acc 60.35%, test_acc 54.28%
Epoch 85: loss 0.0244460, train_acc 60.25%, test_acc 53.95%
Epoch 86: loss 0.0243092, train_acc 60.35%, test_acc 53.94%
Epoch 87: loss 0.0242425, train_acc 60.71%, test_acc 54.21%
Epoch 88: loss 0.0240711, train_acc 60.82%, test_acc 54.16%
Epoch 89: loss 0.0239613, train_acc 61.19%, test_acc 54.19%
Epoch 90: loss 0.0238831, train_acc 61.20%, test_acc 54.48%
Epoch 91: loss 0.0237609, train_acc 61.11%, test_acc 54.31%
Epoch 92: loss 0.0236512, train_acc 61.40%, test_acc 54.62%
Epoch 93: loss 0.0235933, train_acc 61.23%, test_acc 53.94%
Epoch 94: loss 0.0236339, train_acc 61.16%, test_acc 54.12%
Epoch 95: loss 0.0235738, train_acc 61.41%, test_acc 54.18%
Epoch 96: loss 0.0234496, train_acc 62.49%, test_acc 54.56%
Epoch 97: loss 0.0234840, train_acc 61.83%, test_acc 54.11%
Epoch 98: loss 0.0233428, train_acc 62.30%, test_acc 54.61%
Epoch 99: loss 0.0233064, train_acc 61.72%, test_acc 54.17%
Epoch 100: loss 0.0233058, train_acc 61.74%, test_acc 54.07%
Epoch 101: loss 0.0232870, train_acc 61.95%, test_acc 53.98%
Epoch 102: loss 0.0231540, train_acc 61.86%, test_acc 53.92%
Epoch 103: loss 0.0231121, train_acc 61.54%, test_acc 53.76%
Epoch 104: loss 0.0231549, train_acc 62.24%, test_acc 54.73%
Epoch 105: loss 0.0231020, train_acc 61.81%, test_acc 53.94%
Epoch 106: loss 0.0230865, train_acc 61.89%, test_acc 53.21%
Epoch 107: loss 0.0230570, train_acc 61.70%, test_acc 54.05%
Epoch 108: loss 0.0231208, train_acc 62.27%, test_acc 54.31%
Epoch 109: loss 0.0230437, train_acc 62.53%, test_acc 53.93%
Epoch 110: loss 0.0230909, train_acc 62.59%, test_acc 53.85%
Epoch 111: loss 0.0230026, train_acc 62.27%, test_acc 54.47%
Epoch 112: loss 0.0230095, train_acc 61.70%, test_acc 53.12%
Epoch 113: loss 0.0229546, train_acc 62.53%, test_acc 54.04%
Epoch 114: loss 0.0229145, train_acc 62.59%, test_acc 54.46%
Epoch 115: loss 0.0229493, train_acc 62.34%, test_acc 54.09%
Epoch 116: loss 0.0229129, train_acc 62.61%, test_acc 54.33%
Epoch 117: loss 0.0228447, train_acc 62.13%, test_acc 53.55%
Epoch 118: loss 0.0229033, train_acc 62.06%, test_acc 53.43%
Epoch 119: loss 0.0228188, train_acc 61.84%, test_acc 53.47%
Epoch 120: loss 0.0217227, train_acc 64.62%, test_acc 55.56%
Epoch 121: loss 0.0214806, train_acc 64.76%, test_acc 55.39%
Epoch 122: loss 0.0212676, train_acc 65.07%, test_acc 55.63%
Epoch 123: loss 0.0212079, train_acc 65.15%, test_acc 55.62%
Epoch 124: loss 0.0211859, train_acc 65.28%, test_acc 55.67%
Epoch 125: loss 0.0210996, train_acc 65.38%, test_acc 55.75%
Epoch 126: loss 0.0210386, train_acc 65.20%, test_acc 55.55%
Epoch 127: loss 0.0210281, train_acc 65.23%, test_acc 55.71%
Epoch 128: loss 0.0210115, train_acc 65.32%, test_acc 55.69%
Epoch 129: loss 0.0209518, train_acc 65.37%, test_acc 55.66%
Epoch 130: loss 0.0209220, train_acc 65.43%, test_acc 55.52%
Epoch 131: loss 0.0209434, train_acc 65.56%, test_acc 55.98%
Epoch 132: loss 0.0209006, train_acc 65.53%, test_acc 55.52%
Epoch 133: loss 0.0209332, train_acc 65.42%, test_acc 55.46%
Epoch 134: loss 0.0208675, train_acc 65.78%, test_acc 55.61%
Epoch 135: loss 0.0208947, train_acc 65.55%, test_acc 55.54%
Epoch 136: loss 0.0208186, train_acc 65.63%, test_acc 55.97%
Epoch 137: loss 0.0207974, train_acc 65.70%, test_acc 55.55%
Epoch 138: loss 0.0207985, train_acc 65.88%, test_acc 55.60%
Epoch 139: loss 0.0207263, train_acc 65.66%, test_acc 55.35%
Epoch 140: loss 0.0209186, train_acc 65.71%, test_acc 55.58%
Epoch 141: loss 0.0208301, train_acc 65.77%, test_acc 55.64%
Epoch 142: loss 0.0207518, train_acc 65.62%, test_acc 55.26%
Epoch 143: loss 0.0206622, train_acc 65.69%, test_acc 55.36%
Epoch 144: loss 0.0207356, train_acc 65.93%, test_acc 55.45%
Epoch 145: loss 0.0207733, train_acc 65.79%, test_acc 55.68%
Epoch 146: loss 0.0206912, train_acc 65.38%, test_acc 55.47%
Epoch 147: loss 0.0206281, train_acc 65.86%, test_acc 55.45%
Epoch 148: loss 0.0206755, train_acc 65.80%, test_acc 55.34%
Epoch 149: loss 0.0206484, train_acc 65.98%, test_acc 55.37%
Epoch 150: loss 0.0206886, train_acc 65.93%, test_acc 55.48%
Epoch 151: loss 0.0206563, train_acc 66.09%, test_acc 55.54%
Epoch 152: loss 0.0206949, train_acc 66.00%, test_acc 55.80%
Epoch 153: loss 0.0205917, train_acc 65.95%, test_acc 55.44%
Epoch 154: loss 0.0205997, train_acc 65.99%, test_acc 55.44%
Epoch 155: loss 0.0205903, train_acc 65.87%, test_acc 55.69%
Epoch 156: loss 0.0206285, train_acc 66.05%, test_acc 55.38%
Epoch 157: loss 0.0205751, train_acc 66.07%, test_acc 55.60%
Epoch 158: loss 0.0205674, train_acc 65.92%, test_acc 55.52%
Epoch 159: loss 0.0205871, train_acc 66.15%, test_acc 55.74%
