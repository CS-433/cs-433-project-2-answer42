=> Using a preset learning rate schedule:
{0: 0.1, 80: 0.010000000000000002, 120: 0.001}
 *** Used device: cuda
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz
Extracting ./cifar10/cifar-10-python.tar.gz to ./cifar10
Files already downloaded and verified
 *** Random labels done
 *** Random pixels done
 *** Mask calcualted (keeping 10.0% weights)
Epoch 0: loss 0.0261798, train_acc 44.26%, test_acc 45.31%
Epoch 1: loss 0.0184309, train_acc 60.47%, test_acc 61.61%
Epoch 2: loss 0.0143418, train_acc 73.37%, test_acc 73.09%
Epoch 3: loss 0.0119345, train_acc 70.45%, test_acc 69.87%
Epoch 4: loss 0.0104088, train_acc 77.09%, test_acc 76.77%
Epoch 5: loss 0.0094417, train_acc 82.21%, test_acc 81.98%
Epoch 6: loss 0.0088085, train_acc 80.79%, test_acc 80.60%
Epoch 7: loss 0.0082757, train_acc 82.92%, test_acc 81.44%
Epoch 8: loss 0.0076595, train_acc 82.31%, test_acc 81.37%
Epoch 9: loss 0.0073685, train_acc 84.37%, test_acc 82.90%
Epoch 10: loss 0.0069934, train_acc 81.24%, test_acc 80.25%
Epoch 11: loss 0.0067695, train_acc 85.33%, test_acc 82.80%
Epoch 12: loss 0.0065254, train_acc 86.76%, test_acc 83.88%
Epoch 13: loss 0.0062807, train_acc 82.24%, test_acc 81.31%
Epoch 14: loss 0.0061330, train_acc 86.63%, test_acc 84.88%
Epoch 15: loss 0.0059647, train_acc 83.24%, test_acc 81.03%
Epoch 16: loss 0.0057201, train_acc 88.09%, test_acc 85.38%
Epoch 17: loss 0.0055503, train_acc 89.48%, test_acc 86.46%
Epoch 18: loss 0.0053874, train_acc 88.74%, test_acc 85.20%
Epoch 19: loss 0.0053223, train_acc 88.49%, test_acc 85.39%
Epoch 20: loss 0.0053214, train_acc 86.65%, test_acc 84.26%
Epoch 21: loss 0.0050508, train_acc 88.05%, test_acc 85.41%
Epoch 22: loss 0.0050135, train_acc 88.47%, test_acc 84.99%
Epoch 23: loss 0.0049867, train_acc 88.87%, test_acc 85.18%
Epoch 24: loss 0.0049327, train_acc 90.06%, test_acc 86.71%
Epoch 25: loss 0.0047476, train_acc 87.61%, test_acc 84.73%
Epoch 26: loss 0.0047540, train_acc 89.79%, test_acc 85.99%
Epoch 27: loss 0.0047485, train_acc 91.69%, test_acc 88.09%
Epoch 28: loss 0.0046165, train_acc 89.99%, test_acc 86.42%
Epoch 29: loss 0.0045295, train_acc 89.14%, test_acc 85.19%
Epoch 30: loss 0.0044915, train_acc 88.63%, test_acc 85.02%
Epoch 31: loss 0.0044464, train_acc 88.66%, test_acc 86.03%
Epoch 32: loss 0.0044371, train_acc 89.81%, test_acc 86.52%
Epoch 33: loss 0.0043779, train_acc 89.68%, test_acc 86.41%
Epoch 34: loss 0.0042665, train_acc 91.30%, test_acc 86.57%
Epoch 35: loss 0.0042359, train_acc 90.47%, test_acc 86.46%
Epoch 36: loss 0.0042805, train_acc 89.82%, test_acc 86.47%
Epoch 37: loss 0.0042217, train_acc 91.68%, test_acc 87.64%
Epoch 38: loss 0.0042198, train_acc 87.85%, test_acc 84.44%
Epoch 39: loss 0.0041897, train_acc 90.91%, test_acc 86.57%
Epoch 40: loss 0.0041363, train_acc 90.82%, test_acc 86.57%
Epoch 41: loss 0.0040875, train_acc 92.72%, test_acc 88.40%
Epoch 42: loss 0.0040293, train_acc 87.38%, test_acc 83.07%
Epoch 43: loss 0.0041086, train_acc 92.32%, test_acc 88.45%
Epoch 44: loss 0.0041052, train_acc 90.32%, test_acc 86.22%
Epoch 45: loss 0.0039662, train_acc 92.07%, test_acc 87.62%
Epoch 46: loss 0.0040163, train_acc 91.61%, test_acc 87.64%
Epoch 47: loss 0.0039239, train_acc 91.08%, test_acc 86.68%
Epoch 48: loss 0.0038867, train_acc 91.16%, test_acc 86.97%
Epoch 49: loss 0.0038691, train_acc 92.24%, test_acc 87.95%
Epoch 50: loss 0.0038692, train_acc 89.70%, test_acc 86.52%
Epoch 51: loss 0.0038375, train_acc 91.75%, test_acc 87.63%
Epoch 52: loss 0.0038145, train_acc 91.29%, test_acc 86.75%
Epoch 53: loss 0.0037351, train_acc 91.41%, test_acc 87.44%
Epoch 54: loss 0.0038228, train_acc 85.19%, test_acc 81.42%
Epoch 55: loss 0.0037665, train_acc 91.61%, test_acc 87.28%
Epoch 56: loss 0.0037456, train_acc 92.79%, test_acc 88.20%
Epoch 57: loss 0.0037843, train_acc 91.49%, test_acc 86.73%
Epoch 58: loss 0.0038694, train_acc 92.78%, test_acc 88.50%
Epoch 59: loss 0.0037292, train_acc 91.17%, test_acc 87.08%
Epoch 60: loss 0.0037355, train_acc 92.34%, test_acc 87.98%
Epoch 61: loss 0.0036519, train_acc 91.67%, test_acc 87.15%
Epoch 62: loss 0.0037268, train_acc 92.35%, test_acc 87.50%
Epoch 63: loss 0.0036727, train_acc 92.30%, test_acc 88.22%
Epoch 64: loss 0.0036562, train_acc 92.83%, test_acc 87.93%
Epoch 65: loss 0.0037296, train_acc 89.16%, test_acc 84.76%
Epoch 66: loss 0.0036634, train_acc 92.39%, test_acc 87.85%
Epoch 67: loss 0.0036920, train_acc 92.69%, test_acc 88.16%
Epoch 68: loss 0.0035969, train_acc 92.76%, test_acc 88.68%
Epoch 69: loss 0.0036303, train_acc 92.03%, test_acc 87.50%
Epoch 70: loss 0.0036068, train_acc 93.21%, test_acc 88.76%
Epoch 71: loss 0.0036216, train_acc 92.62%, test_acc 88.12%
Epoch 72: loss 0.0036088, train_acc 91.97%, test_acc 87.69%
Epoch 73: loss 0.0035731, train_acc 92.40%, test_acc 87.55%
Epoch 74: loss 0.0035366, train_acc 91.61%, test_acc 86.97%
Epoch 75: loss 0.0035308, train_acc 92.22%, test_acc 87.34%
Epoch 76: loss 0.0035798, train_acc 92.16%, test_acc 87.58%
Epoch 77: loss 0.0035643, train_acc 91.45%, test_acc 87.12%
Epoch 78: loss 0.0034276, train_acc 91.91%, test_acc 87.68%
Epoch 79: loss 0.0035014, train_acc 92.31%, test_acc 87.93%
Epoch 80: loss 0.0017474, train_acc 97.83%, test_acc 92.26%
Epoch 81: loss 0.0012331, train_acc 98.23%, test_acc 92.51%
Epoch 82: loss 0.0009990, train_acc 98.54%, test_acc 92.74%
Epoch 83: loss 0.0008939, train_acc 98.73%, test_acc 92.75%
Epoch 84: loss 0.0007686, train_acc 98.91%, test_acc 92.86%
Epoch 85: loss 0.0006882, train_acc 99.00%, test_acc 92.81%
Epoch 86: loss 0.0006065, train_acc 99.28%, test_acc 93.01%
Epoch 87: loss 0.0005740, train_acc 99.21%, test_acc 93.08%
Epoch 88: loss 0.0005422, train_acc 99.29%, test_acc 92.97%
Epoch 89: loss 0.0004924, train_acc 99.31%, test_acc 92.86%
Epoch 90: loss 0.0004490, train_acc 99.41%, test_acc 92.96%
Epoch 91: loss 0.0004238, train_acc 99.41%, test_acc 93.06%
Epoch 92: loss 0.0003975, train_acc 99.45%, test_acc 93.14%
Epoch 93: loss 0.0003737, train_acc 99.37%, test_acc 92.79%
Epoch 94: loss 0.0003418, train_acc 99.50%, test_acc 92.96%
Epoch 95: loss 0.0003179, train_acc 99.44%, test_acc 92.90%
Epoch 96: loss 0.0003413, train_acc 99.62%, test_acc 93.07%
Epoch 97: loss 0.0003315, train_acc 99.52%, test_acc 92.65%
Epoch 98: loss 0.0003047, train_acc 99.63%, test_acc 93.10%
Epoch 99: loss 0.0003034, train_acc 99.59%, test_acc 93.16%
Epoch 100: loss 0.0002971, train_acc 99.57%, test_acc 92.94%
Epoch 101: loss 0.0002781, train_acc 99.65%, test_acc 92.94%
Epoch 102: loss 0.0003079, train_acc 99.62%, test_acc 92.66%
Epoch 103: loss 0.0002878, train_acc 99.64%, test_acc 92.70%
Epoch 104: loss 0.0002530, train_acc 99.63%, test_acc 92.76%
Epoch 105: loss 0.0002606, train_acc 99.61%, test_acc 92.77%
Epoch 106: loss 0.0002622, train_acc 99.54%, test_acc 92.67%
Epoch 107: loss 0.0002393, train_acc 99.69%, test_acc 93.01%
Epoch 108: loss 0.0002502, train_acc 99.67%, test_acc 92.92%
Epoch 109: loss 0.0002439, train_acc 99.64%, test_acc 92.87%
Epoch 110: loss 0.0002579, train_acc 99.69%, test_acc 92.87%
Epoch 111: loss 0.0002552, train_acc 99.68%, test_acc 92.83%
Epoch 112: loss 0.0002692, train_acc 99.72%, test_acc 93.08%
Epoch 113: loss 0.0002735, train_acc 99.71%, test_acc 92.72%
Epoch 114: loss 0.0002424, train_acc 99.70%, test_acc 93.00%
Epoch 115: loss 0.0002775, train_acc 99.67%, test_acc 92.73%
Epoch 116: loss 0.0002130, train_acc 99.65%, test_acc 92.78%
Epoch 117: loss 0.0002375, train_acc 99.63%, test_acc 92.90%
Epoch 118: loss 0.0002190, train_acc 99.67%, test_acc 92.82%
Epoch 119: loss 0.0002698, train_acc 99.69%, test_acc 92.49%
Epoch 120: loss 0.0001706, train_acc 99.85%, test_acc 92.96%
Epoch 121: loss 0.0001243, train_acc 99.89%, test_acc 93.03%
Epoch 122: loss 0.0001075, train_acc 99.92%, test_acc 93.17%
Epoch 123: loss 0.0000862, train_acc 99.92%, test_acc 93.32%
Epoch 124: loss 0.0000882, train_acc 99.92%, test_acc 93.25%
Epoch 125: loss 0.0000849, train_acc 99.93%, test_acc 93.25%
Epoch 126: loss 0.0000693, train_acc 99.94%, test_acc 93.28%
Epoch 127: loss 0.0000757, train_acc 99.93%, test_acc 93.22%
Epoch 128: loss 0.0000768, train_acc 99.95%, test_acc 93.47%
Epoch 129: loss 0.0000713, train_acc 99.95%, test_acc 93.22%
Epoch 130: loss 0.0000645, train_acc 99.97%, test_acc 93.34%
Epoch 131: loss 0.0000662, train_acc 99.96%, test_acc 93.45%
Epoch 132: loss 0.0000570, train_acc 99.97%, test_acc 93.41%
Epoch 133: loss 0.0000628, train_acc 99.95%, test_acc 93.40%
Epoch 134: loss 0.0000685, train_acc 99.96%, test_acc 93.44%
Epoch 135: loss 0.0000610, train_acc 99.97%, test_acc 93.45%
Epoch 136: loss 0.0000570, train_acc 99.95%, test_acc 93.44%
Epoch 137: loss 0.0000667, train_acc 99.96%, test_acc 93.54%
Epoch 138: loss 0.0000511, train_acc 99.98%, test_acc 93.48%
Epoch 139: loss 0.0000523, train_acc 99.97%, test_acc 93.46%
Epoch 140: loss 0.0000549, train_acc 99.95%, test_acc 93.32%
Epoch 141: loss 0.0000506, train_acc 99.98%, test_acc 93.45%
Epoch 142: loss 0.0000474, train_acc 99.97%, test_acc 93.54%
Epoch 143: loss 0.0000465, train_acc 99.98%, test_acc 93.30%
Epoch 144: loss 0.0000453, train_acc 99.96%, test_acc 93.39%
Epoch 145: loss 0.0000481, train_acc 99.97%, test_acc 93.45%
Epoch 146: loss 0.0000514, train_acc 99.98%, test_acc 93.40%
Epoch 147: loss 0.0000494, train_acc 99.98%, test_acc 93.41%
Epoch 148: loss 0.0000476, train_acc 99.98%, test_acc 93.53%
Epoch 149: loss 0.0000430, train_acc 99.97%, test_acc 93.45%
Epoch 150: loss 0.0000490, train_acc 99.97%, test_acc 93.43%
Epoch 151: loss 0.0000487, train_acc 99.97%, test_acc 93.39%
Epoch 152: loss 0.0000448, train_acc 99.98%, test_acc 93.37%
Epoch 153: loss 0.0000413, train_acc 99.98%, test_acc 93.35%
Epoch 154: loss 0.0000425, train_acc 99.98%, test_acc 93.41%
Epoch 155: loss 0.0000312, train_acc 99.98%, test_acc 93.53%
Epoch 156: loss 0.0000408, train_acc 99.97%, test_acc 93.48%
Epoch 157: loss 0.0000400, train_acc 99.98%, test_acc 93.45%
Epoch 158: loss 0.0000389, train_acc 99.98%, test_acc 93.48%
Epoch 159: loss 0.0000391, train_acc 99.99%, test_acc 93.37%
