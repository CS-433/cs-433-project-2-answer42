=> Using a preset learning rate schedule:
{0: 0.1, 80: 0.010000000000000002, 120: 0.001}
 *** Used device: cuda
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz
Extracting ./cifar10/cifar-10-python.tar.gz to ./cifar10
Files already downloaded and verified
 *** Random labels done
 *** Random pixels done
 *** Mask calcualted (keeping 5.0% weights)
Epoch 0: loss 0.0246793, train_acc 42.17%, test_acc 42.06%
Epoch 1: loss 0.0166004, train_acc 63.70%, test_acc 63.43%
Epoch 2: loss 0.0136053, train_acc 70.24%, test_acc 69.13%
Epoch 3: loss 0.0119615, train_acc 73.13%, test_acc 71.13%
Epoch 4: loss 0.0109930, train_acc 76.43%, test_acc 75.17%
Epoch 5: loss 0.0103231, train_acc 75.81%, test_acc 74.56%
Epoch 6: loss 0.0097573, train_acc 74.53%, test_acc 73.32%
Epoch 7: loss 0.0094488, train_acc 78.05%, test_acc 76.06%
Epoch 8: loss 0.0090792, train_acc 78.95%, test_acc 77.51%
Epoch 9: loss 0.0088484, train_acc 76.85%, test_acc 75.46%
Epoch 10: loss 0.0086464, train_acc 78.60%, test_acc 76.92%
Epoch 11: loss 0.0084996, train_acc 80.83%, test_acc 79.59%
Epoch 12: loss 0.0083489, train_acc 77.16%, test_acc 75.49%
Epoch 13: loss 0.0081659, train_acc 81.26%, test_acc 80.11%
Epoch 14: loss 0.0080996, train_acc 83.46%, test_acc 81.38%
Epoch 15: loss 0.0079981, train_acc 80.52%, test_acc 78.21%
Epoch 16: loss 0.0077500, train_acc 76.92%, test_acc 74.29%
Epoch 17: loss 0.0076757, train_acc 78.45%, test_acc 77.51%
Epoch 18: loss 0.0075860, train_acc 80.00%, test_acc 77.64%
Epoch 19: loss 0.0074550, train_acc 81.04%, test_acc 78.96%
Epoch 20: loss 0.0075016, train_acc 81.58%, test_acc 79.85%
Epoch 21: loss 0.0073912, train_acc 83.02%, test_acc 81.82%
Epoch 22: loss 0.0073845, train_acc 82.16%, test_acc 80.35%
Epoch 23: loss 0.0072468, train_acc 82.41%, test_acc 80.70%
Epoch 24: loss 0.0072504, train_acc 81.78%, test_acc 80.12%
Epoch 25: loss 0.0072386, train_acc 82.09%, test_acc 81.34%
Epoch 26: loss 0.0072159, train_acc 81.96%, test_acc 80.31%
Epoch 27: loss 0.0071418, train_acc 84.46%, test_acc 82.24%
Epoch 28: loss 0.0070214, train_acc 82.78%, test_acc 80.55%
Epoch 29: loss 0.0070173, train_acc 81.53%, test_acc 78.97%
Epoch 30: loss 0.0070358, train_acc 84.48%, test_acc 82.30%
Epoch 31: loss 0.0068933, train_acc 83.38%, test_acc 81.49%
Epoch 32: loss 0.0069721, train_acc 82.27%, test_acc 81.42%
Epoch 33: loss 0.0069184, train_acc 78.51%, test_acc 76.61%
Epoch 34: loss 0.0068990, train_acc 83.47%, test_acc 82.01%
Epoch 35: loss 0.0068210, train_acc 83.56%, test_acc 81.42%
Epoch 36: loss 0.0067701, train_acc 85.25%, test_acc 82.76%
Epoch 37: loss 0.0067826, train_acc 83.38%, test_acc 81.54%
Epoch 38: loss 0.0067466, train_acc 83.30%, test_acc 82.04%
Epoch 39: loss 0.0067330, train_acc 82.56%, test_acc 79.94%
Epoch 40: loss 0.0066987, train_acc 82.74%, test_acc 80.64%
Epoch 41: loss 0.0066812, train_acc 78.70%, test_acc 76.29%
Epoch 42: loss 0.0066363, train_acc 86.17%, test_acc 84.91%
Epoch 43: loss 0.0066347, train_acc 82.49%, test_acc 80.07%
Epoch 44: loss 0.0065720, train_acc 84.46%, test_acc 82.85%
Epoch 45: loss 0.0065746, train_acc 85.32%, test_acc 83.02%
Epoch 46: loss 0.0065886, train_acc 81.40%, test_acc 79.23%
Epoch 47: loss 0.0065547, train_acc 85.37%, test_acc 82.78%
Epoch 48: loss 0.0065360, train_acc 82.74%, test_acc 80.42%
Epoch 49: loss 0.0064804, train_acc 80.44%, test_acc 78.57%
Epoch 50: loss 0.0064464, train_acc 82.96%, test_acc 80.85%
Epoch 51: loss 0.0064889, train_acc 84.70%, test_acc 83.01%
Epoch 52: loss 0.0064428, train_acc 80.40%, test_acc 78.62%
Epoch 53: loss 0.0065112, train_acc 83.26%, test_acc 81.09%
Epoch 54: loss 0.0063911, train_acc 85.38%, test_acc 83.06%
Epoch 55: loss 0.0064455, train_acc 85.04%, test_acc 83.01%
Epoch 56: loss 0.0063881, train_acc 83.95%, test_acc 81.19%
Epoch 57: loss 0.0063302, train_acc 84.48%, test_acc 82.97%
Epoch 58: loss 0.0063760, train_acc 84.62%, test_acc 82.67%
Epoch 59: loss 0.0063648, train_acc 79.08%, test_acc 76.96%
Epoch 60: loss 0.0064385, train_acc 82.11%, test_acc 80.47%
Epoch 61: loss 0.0062737, train_acc 82.02%, test_acc 79.63%
Epoch 62: loss 0.0063802, train_acc 82.41%, test_acc 80.46%
Epoch 63: loss 0.0063457, train_acc 86.67%, test_acc 84.24%
Epoch 64: loss 0.0062195, train_acc 83.73%, test_acc 81.01%
Epoch 65: loss 0.0063619, train_acc 81.16%, test_acc 78.80%
Epoch 66: loss 0.0063085, train_acc 83.16%, test_acc 80.64%
Epoch 67: loss 0.0061947, train_acc 84.36%, test_acc 81.19%
Epoch 68: loss 0.0062996, train_acc 84.34%, test_acc 82.86%
Epoch 69: loss 0.0062511, train_acc 84.33%, test_acc 82.00%
Epoch 70: loss 0.0063005, train_acc 83.32%, test_acc 81.39%
Epoch 71: loss 0.0061919, train_acc 79.95%, test_acc 77.21%
Epoch 72: loss 0.0061911, train_acc 86.83%, test_acc 84.62%
Epoch 73: loss 0.0062200, train_acc 85.45%, test_acc 83.44%
Epoch 74: loss 0.0061756, train_acc 85.76%, test_acc 83.37%
Epoch 75: loss 0.0061357, train_acc 86.07%, test_acc 84.51%
Epoch 76: loss 0.0062141, train_acc 85.79%, test_acc 83.84%
Epoch 77: loss 0.0062077, train_acc 84.13%, test_acc 82.26%
Epoch 78: loss 0.0061616, train_acc 86.33%, test_acc 84.43%
Epoch 79: loss 0.0061635, train_acc 83.43%, test_acc 80.82%
Epoch 80: loss 0.0043463, train_acc 92.50%, test_acc 89.53%
Epoch 81: loss 0.0037678, train_acc 92.74%, test_acc 89.73%
Epoch 82: loss 0.0036251, train_acc 93.31%, test_acc 89.62%
Epoch 83: loss 0.0034492, train_acc 93.32%, test_acc 89.87%
Epoch 84: loss 0.0033816, train_acc 93.51%, test_acc 89.97%
Epoch 85: loss 0.0032820, train_acc 93.54%, test_acc 89.77%
Epoch 86: loss 0.0032253, train_acc 94.00%, test_acc 89.88%
Epoch 87: loss 0.0031602, train_acc 94.15%, test_acc 90.17%
Epoch 88: loss 0.0030651, train_acc 94.16%, test_acc 90.11%
Epoch 89: loss 0.0030552, train_acc 94.41%, test_acc 90.06%
Epoch 90: loss 0.0029508, train_acc 94.46%, test_acc 90.11%
Epoch 91: loss 0.0029536, train_acc 94.54%, test_acc 90.26%
Epoch 92: loss 0.0028850, train_acc 94.66%, test_acc 90.09%
Epoch 93: loss 0.0028605, train_acc 94.71%, test_acc 90.05%
Epoch 94: loss 0.0028213, train_acc 94.67%, test_acc 90.19%
Epoch 95: loss 0.0027872, train_acc 94.91%, test_acc 90.09%
Epoch 96: loss 0.0027803, train_acc 94.88%, test_acc 90.12%
Epoch 97: loss 0.0027672, train_acc 94.92%, test_acc 90.31%
Epoch 98: loss 0.0027268, train_acc 94.92%, test_acc 90.11%
Epoch 99: loss 0.0027105, train_acc 94.76%, test_acc 89.53%
Epoch 100: loss 0.0026600, train_acc 95.02%, test_acc 90.08%
Epoch 101: loss 0.0026781, train_acc 95.12%, test_acc 90.09%
Epoch 102: loss 0.0026233, train_acc 95.26%, test_acc 90.04%
Epoch 103: loss 0.0026026, train_acc 95.20%, test_acc 90.16%
Epoch 104: loss 0.0026362, train_acc 95.21%, test_acc 90.16%
Epoch 105: loss 0.0025627, train_acc 95.41%, test_acc 90.37%
Epoch 106: loss 0.0025899, train_acc 95.29%, test_acc 90.43%
Epoch 107: loss 0.0025587, train_acc 94.38%, test_acc 89.38%
Epoch 108: loss 0.0024939, train_acc 95.35%, test_acc 90.14%
Epoch 109: loss 0.0025629, train_acc 94.99%, test_acc 89.58%
Epoch 110: loss 0.0025052, train_acc 95.44%, test_acc 89.83%
Epoch 111: loss 0.0024711, train_acc 94.31%, test_acc 88.64%
Epoch 112: loss 0.0025082, train_acc 94.80%, test_acc 89.59%
Epoch 113: loss 0.0025217, train_acc 95.33%, test_acc 89.76%
Epoch 114: loss 0.0024556, train_acc 95.40%, test_acc 89.77%
Epoch 115: loss 0.0024416, train_acc 95.44%, test_acc 90.03%
Epoch 116: loss 0.0024550, train_acc 95.16%, test_acc 90.03%
Epoch 117: loss 0.0024618, train_acc 95.65%, test_acc 89.93%
Epoch 118: loss 0.0025007, train_acc 94.71%, test_acc 89.07%
Epoch 119: loss 0.0024745, train_acc 95.08%, test_acc 89.44%
Epoch 120: loss 0.0020247, train_acc 96.64%, test_acc 90.70%
Epoch 121: loss 0.0019004, train_acc 96.87%, test_acc 90.76%
Epoch 122: loss 0.0018159, train_acc 97.00%, test_acc 90.98%
Epoch 123: loss 0.0017764, train_acc 97.02%, test_acc 90.85%
Epoch 124: loss 0.0017856, train_acc 96.95%, test_acc 90.78%
Epoch 125: loss 0.0017572, train_acc 97.08%, test_acc 90.73%
Epoch 126: loss 0.0017102, train_acc 97.09%, test_acc 90.85%
Epoch 127: loss 0.0016814, train_acc 97.27%, test_acc 90.84%
Epoch 128: loss 0.0016634, train_acc 97.17%, test_acc 90.98%
Epoch 129: loss 0.0016740, train_acc 97.29%, test_acc 90.82%
Epoch 130: loss 0.0016732, train_acc 97.32%, test_acc 90.95%
Epoch 131: loss 0.0016615, train_acc 97.31%, test_acc 91.15%
Epoch 132: loss 0.0016204, train_acc 97.35%, test_acc 90.74%
Epoch 133: loss 0.0016045, train_acc 97.31%, test_acc 90.68%
Epoch 134: loss 0.0016198, train_acc 97.41%, test_acc 90.60%
Epoch 135: loss 0.0016335, train_acc 97.41%, test_acc 90.84%
Epoch 136: loss 0.0016265, train_acc 97.37%, test_acc 90.74%
Epoch 137: loss 0.0015964, train_acc 97.38%, test_acc 90.44%
Epoch 138: loss 0.0015857, train_acc 97.38%, test_acc 90.73%
Epoch 139: loss 0.0015658, train_acc 97.50%, test_acc 90.63%
Epoch 140: loss 0.0015494, train_acc 97.45%, test_acc 90.53%
Epoch 141: loss 0.0015472, train_acc 97.53%, test_acc 90.57%
Epoch 142: loss 0.0015868, train_acc 97.48%, test_acc 90.69%
Epoch 143: loss 0.0015282, train_acc 97.58%, test_acc 90.63%
Epoch 144: loss 0.0015281, train_acc 97.57%, test_acc 90.64%
Epoch 145: loss 0.0015416, train_acc 97.52%, test_acc 90.55%
Epoch 146: loss 0.0015505, train_acc 97.56%, test_acc 90.75%
Epoch 147: loss 0.0015063, train_acc 97.54%, test_acc 90.57%
Epoch 148: loss 0.0015589, train_acc 97.60%, test_acc 90.65%
Epoch 149: loss 0.0014697, train_acc 97.53%, test_acc 90.62%
Epoch 150: loss 0.0015049, train_acc 97.61%, test_acc 90.49%
Epoch 151: loss 0.0015028, train_acc 97.67%, test_acc 90.51%
Epoch 152: loss 0.0014829, train_acc 97.64%, test_acc 90.42%
Epoch 153: loss 0.0014764, train_acc 97.73%, test_acc 90.61%
Epoch 154: loss 0.0014938, train_acc 97.78%, test_acc 90.67%
Epoch 155: loss 0.0014797, train_acc 97.67%, test_acc 90.52%
Epoch 156: loss 0.0014662, train_acc 97.67%, test_acc 90.49%
Epoch 157: loss 0.0014519, train_acc 97.68%, test_acc 90.58%
Epoch 158: loss 0.0014548, train_acc 97.67%, test_acc 90.54%
Epoch 159: loss 0.0014577, train_acc 97.79%, test_acc 90.51%
