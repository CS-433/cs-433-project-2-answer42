=> Using a preset learning rate schedule:
{0: 0.1, 80: 0.010000000000000002, 120: 0.001}
 *** Used device: cuda
Files already downloaded and verified
Files already downloaded and verified
 *** Mask calcualted (keeping 2.0% weights)
 *** Layerwise rearrange done
Epoch 0: loss 0.0240309, train_acc 51.18%, test_acc 51.80%
Epoch 1: loss 0.0172345, train_acc 59.45%, test_acc 58.76%
Epoch 2: loss 0.0152238, train_acc 64.38%, test_acc 63.87%
Epoch 3: loss 0.0140584, train_acc 66.56%, test_acc 66.56%
Epoch 4: loss 0.0132012, train_acc 61.28%, test_acc 60.50%
Epoch 5: loss 0.0125408, train_acc 71.06%, test_acc 69.08%
Epoch 6: loss 0.0119913, train_acc 67.55%, test_acc 66.00%
Epoch 7: loss 0.0115349, train_acc 65.90%, test_acc 64.22%
Epoch 8: loss 0.0111502, train_acc 68.80%, test_acc 67.87%
Epoch 9: loss 0.0109566, train_acc 63.29%, test_acc 60.93%
Epoch 10: loss 0.0106090, train_acc 71.22%, test_acc 70.52%
Epoch 11: loss 0.0105020, train_acc 75.87%, test_acc 73.29%
Epoch 12: loss 0.0103664, train_acc 77.47%, test_acc 76.44%
Epoch 13: loss 0.0101363, train_acc 72.28%, test_acc 69.95%
Epoch 14: loss 0.0100673, train_acc 71.93%, test_acc 70.26%
Epoch 15: loss 0.0098281, train_acc 72.05%, test_acc 70.11%
Epoch 16: loss 0.0097824, train_acc 73.62%, test_acc 70.65%
Epoch 17: loss 0.0096584, train_acc 75.67%, test_acc 75.14%
Epoch 18: loss 0.0096910, train_acc 77.82%, test_acc 76.83%
Epoch 19: loss 0.0095035, train_acc 74.98%, test_acc 73.13%
Epoch 20: loss 0.0094515, train_acc 78.31%, test_acc 77.35%
Epoch 21: loss 0.0094131, train_acc 78.37%, test_acc 75.86%
Epoch 22: loss 0.0093440, train_acc 78.93%, test_acc 77.07%
Epoch 23: loss 0.0093620, train_acc 74.88%, test_acc 75.34%
Epoch 24: loss 0.0091258, train_acc 70.40%, test_acc 68.71%
Epoch 25: loss 0.0092139, train_acc 71.93%, test_acc 69.57%
Epoch 26: loss 0.0090874, train_acc 79.90%, test_acc 78.91%
Epoch 27: loss 0.0091060, train_acc 75.62%, test_acc 74.44%
Epoch 28: loss 0.0090566, train_acc 76.24%, test_acc 75.29%
Epoch 29: loss 0.0088895, train_acc 75.31%, test_acc 73.32%
Epoch 30: loss 0.0088472, train_acc 77.49%, test_acc 76.17%
Epoch 31: loss 0.0089863, train_acc 76.14%, test_acc 73.82%
Epoch 32: loss 0.0088740, train_acc 72.82%, test_acc 70.16%
Epoch 33: loss 0.0088344, train_acc 79.03%, test_acc 77.54%
Epoch 34: loss 0.0087831, train_acc 78.34%, test_acc 75.94%
Epoch 35: loss 0.0088080, train_acc 77.29%, test_acc 75.14%
Epoch 36: loss 0.0086578, train_acc 73.44%, test_acc 70.23%
Epoch 37: loss 0.0087135, train_acc 81.30%, test_acc 79.58%
Epoch 38: loss 0.0086586, train_acc 80.88%, test_acc 78.58%
Epoch 39: loss 0.0087375, train_acc 75.38%, test_acc 73.58%
Epoch 40: loss 0.0085843, train_acc 73.08%, test_acc 71.03%
Epoch 41: loss 0.0085593, train_acc 76.07%, test_acc 73.72%
Epoch 42: loss 0.0085738, train_acc 80.35%, test_acc 78.39%
Epoch 43: loss 0.0085006, train_acc 79.66%, test_acc 78.19%
Epoch 44: loss 0.0084613, train_acc 78.37%, test_acc 77.17%
Epoch 45: loss 0.0085236, train_acc 76.82%, test_acc 75.20%
Epoch 46: loss 0.0084798, train_acc 81.62%, test_acc 80.11%
Epoch 47: loss 0.0083776, train_acc 80.07%, test_acc 78.53%
Epoch 48: loss 0.0084246, train_acc 81.51%, test_acc 79.22%
Epoch 49: loss 0.0084234, train_acc 74.79%, test_acc 72.38%
Epoch 50: loss 0.0084182, train_acc 82.09%, test_acc 80.48%
Epoch 51: loss 0.0084266, train_acc 75.48%, test_acc 73.55%
Epoch 52: loss 0.0083330, train_acc 79.95%, test_acc 79.21%
Epoch 53: loss 0.0082669, train_acc 78.40%, test_acc 77.62%
Epoch 54: loss 0.0082825, train_acc 80.46%, test_acc 78.43%
Epoch 55: loss 0.0083213, train_acc 79.07%, test_acc 76.28%
Epoch 56: loss 0.0083775, train_acc 77.30%, test_acc 74.66%
Epoch 57: loss 0.0082587, train_acc 78.91%, test_acc 76.70%
Epoch 58: loss 0.0082720, train_acc 78.73%, test_acc 76.68%
Epoch 59: loss 0.0083068, train_acc 74.80%, test_acc 73.54%
Epoch 60: loss 0.0082674, train_acc 82.15%, test_acc 80.89%
Epoch 61: loss 0.0081583, train_acc 76.79%, test_acc 73.73%
Epoch 62: loss 0.0082070, train_acc 73.84%, test_acc 71.52%
Epoch 63: loss 0.0081666, train_acc 81.50%, test_acc 79.44%
Epoch 64: loss 0.0081761, train_acc 76.80%, test_acc 74.35%
Epoch 65: loss 0.0081765, train_acc 79.97%, test_acc 78.55%
Epoch 66: loss 0.0082102, train_acc 80.41%, test_acc 78.49%
Epoch 67: loss 0.0082242, train_acc 80.07%, test_acc 77.63%
Epoch 68: loss 0.0082120, train_acc 80.42%, test_acc 77.72%
Epoch 69: loss 0.0081879, train_acc 78.54%, test_acc 75.86%
Epoch 70: loss 0.0080601, train_acc 81.12%, test_acc 78.97%
Epoch 71: loss 0.0081388, train_acc 80.73%, test_acc 78.25%
Epoch 72: loss 0.0080975, train_acc 75.79%, test_acc 74.35%
Epoch 73: loss 0.0080397, train_acc 77.79%, test_acc 76.79%
Epoch 74: loss 0.0080223, train_acc 79.83%, test_acc 79.34%
Epoch 75: loss 0.0080740, train_acc 75.78%, test_acc 72.65%
Epoch 76: loss 0.0080334, train_acc 80.25%, test_acc 78.85%
Epoch 77: loss 0.0080597, train_acc 81.35%, test_acc 79.45%
Epoch 78: loss 0.0080688, train_acc 82.44%, test_acc 81.03%
Epoch 79: loss 0.0080831, train_acc 79.60%, test_acc 79.08%
Epoch 80: loss 0.0062061, train_acc 88.68%, test_acc 85.87%
Epoch 81: loss 0.0056653, train_acc 89.11%, test_acc 86.22%
Epoch 82: loss 0.0054520, train_acc 89.35%, test_acc 86.63%
Epoch 83: loss 0.0053132, train_acc 89.56%, test_acc 86.77%
Epoch 84: loss 0.0053220, train_acc 89.80%, test_acc 86.92%
Epoch 85: loss 0.0051769, train_acc 90.01%, test_acc 86.89%
Epoch 86: loss 0.0051224, train_acc 90.07%, test_acc 87.05%
Epoch 87: loss 0.0050220, train_acc 89.84%, test_acc 86.46%
Epoch 88: loss 0.0049879, train_acc 90.16%, test_acc 86.88%
Epoch 89: loss 0.0050071, train_acc 90.30%, test_acc 87.17%
Epoch 90: loss 0.0049563, train_acc 90.14%, test_acc 86.90%
Epoch 91: loss 0.0049166, train_acc 90.42%, test_acc 86.89%
Epoch 92: loss 0.0049000, train_acc 90.52%, test_acc 87.21%
Epoch 93: loss 0.0049201, train_acc 90.57%, test_acc 87.30%
Epoch 94: loss 0.0049023, train_acc 90.43%, test_acc 86.88%
Epoch 95: loss 0.0048089, train_acc 90.80%, test_acc 87.69%
Epoch 96: loss 0.0048196, train_acc 90.83%, test_acc 87.38%
Epoch 97: loss 0.0048082, train_acc 90.93%, test_acc 87.11%
Epoch 98: loss 0.0047621, train_acc 90.83%, test_acc 87.19%
Epoch 99: loss 0.0047229, train_acc 90.73%, test_acc 86.98%
Epoch 100: loss 0.0046876, train_acc 90.74%, test_acc 87.27%
Epoch 101: loss 0.0047041, train_acc 90.85%, test_acc 87.11%
Epoch 102: loss 0.0046659, train_acc 90.95%, test_acc 86.90%
Epoch 103: loss 0.0046495, train_acc 91.11%, test_acc 86.95%
Epoch 104: loss 0.0046293, train_acc 90.76%, test_acc 86.68%
Epoch 105: loss 0.0046333, train_acc 90.76%, test_acc 86.82%
Epoch 106: loss 0.0046241, train_acc 90.88%, test_acc 86.35%
Epoch 107: loss 0.0046620, train_acc 91.18%, test_acc 86.88%
Epoch 108: loss 0.0046601, train_acc 90.69%, test_acc 86.38%
Epoch 109: loss 0.0046257, train_acc 90.73%, test_acc 86.73%
Epoch 110: loss 0.0046097, train_acc 91.05%, test_acc 87.20%
Epoch 111: loss 0.0046740, train_acc 90.66%, test_acc 86.35%
Epoch 112: loss 0.0045827, train_acc 91.12%, test_acc 86.80%
Epoch 113: loss 0.0046400, train_acc 91.09%, test_acc 87.01%
Epoch 114: loss 0.0045854, train_acc 90.76%, test_acc 86.58%
Epoch 115: loss 0.0045478, train_acc 90.85%, test_acc 85.93%
Epoch 116: loss 0.0045446, train_acc 90.43%, test_acc 85.87%
Epoch 117: loss 0.0045879, train_acc 90.62%, test_acc 86.90%
Epoch 118: loss 0.0045532, train_acc 90.31%, test_acc 85.87%
Epoch 119: loss 0.0046030, train_acc 91.18%, test_acc 86.38%
Epoch 120: loss 0.0041143, train_acc 92.24%, test_acc 87.52%
Epoch 121: loss 0.0039257, train_acc 92.42%, test_acc 87.65%
Epoch 122: loss 0.0039247, train_acc 92.62%, test_acc 87.96%
Epoch 123: loss 0.0038889, train_acc 92.85%, test_acc 87.96%
Epoch 124: loss 0.0038346, train_acc 92.88%, test_acc 87.99%
Epoch 125: loss 0.0038337, train_acc 92.82%, test_acc 87.73%
Epoch 126: loss 0.0038365, train_acc 92.87%, test_acc 87.89%
Epoch 127: loss 0.0038463, train_acc 92.81%, test_acc 87.85%
Epoch 128: loss 0.0037591, train_acc 92.86%, test_acc 87.70%
Epoch 129: loss 0.0037998, train_acc 92.93%, test_acc 87.77%
Epoch 130: loss 0.0037121, train_acc 92.95%, test_acc 87.75%
Epoch 131: loss 0.0037185, train_acc 92.81%, test_acc 87.82%
Epoch 132: loss 0.0037432, train_acc 93.06%, test_acc 87.84%
Epoch 133: loss 0.0037611, train_acc 92.89%, test_acc 87.82%
Epoch 134: loss 0.0037603, train_acc 92.87%, test_acc 87.91%
Epoch 135: loss 0.0037019, train_acc 92.92%, test_acc 87.62%
Epoch 136: loss 0.0036768, train_acc 93.12%, test_acc 87.66%
Epoch 137: loss 0.0036791, train_acc 93.03%, test_acc 87.75%
Epoch 138: loss 0.0037227, train_acc 93.07%, test_acc 87.89%
Epoch 139: loss 0.0037000, train_acc 92.97%, test_acc 87.61%
Epoch 140: loss 0.0036636, train_acc 93.29%, test_acc 87.73%
Epoch 141: loss 0.0036528, train_acc 93.18%, test_acc 87.78%
Epoch 142: loss 0.0036466, train_acc 93.29%, test_acc 87.90%
Epoch 143: loss 0.0036410, train_acc 93.16%, test_acc 87.67%
Epoch 144: loss 0.0036123, train_acc 93.16%, test_acc 88.00%
Epoch 145: loss 0.0036515, train_acc 93.09%, test_acc 87.75%
Epoch 146: loss 0.0036348, train_acc 93.17%, test_acc 87.61%
Epoch 147: loss 0.0036553, train_acc 93.29%, test_acc 87.89%
Epoch 148: loss 0.0036375, train_acc 93.14%, test_acc 87.71%
Epoch 149: loss 0.0036477, train_acc 93.37%, test_acc 87.66%
Epoch 150: loss 0.0036766, train_acc 93.40%, test_acc 87.70%
Epoch 151: loss 0.0036455, train_acc 93.24%, test_acc 87.89%
Epoch 152: loss 0.0036479, train_acc 93.44%, test_acc 87.80%
Epoch 153: loss 0.0035970, train_acc 93.24%, test_acc 87.82%
Epoch 154: loss 0.0035906, train_acc 93.31%, test_acc 87.60%
Epoch 155: loss 0.0036015, train_acc 93.36%, test_acc 87.68%
Epoch 156: loss 0.0035761, train_acc 93.25%, test_acc 87.84%
Epoch 157: loss 0.0035949, train_acc 93.26%, test_acc 87.55%
Epoch 158: loss 0.0035884, train_acc 93.28%, test_acc 87.47%
Epoch 159: loss 0.0035919, train_acc 93.29%, test_acc 87.62%
