=> Using a preset learning rate schedule:
{0: 0.1, 80: 0.010000000000000002, 120: 0.001}
Used device: cuda
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz
Extracting ./cifar10/cifar-10-python.tar.gz to ./cifar10
Files already downloaded and verified
Mask calcualted (keeping 10.0% weights)
Epoch 0: loss 0.0273537, train_acc 43.79%, test_acc 44.51%
Epoch 1: loss 0.0194060, train_acc 59.14%, test_acc 59.12%
Epoch 2: loss 0.0147628, train_acc 68.46%, test_acc 67.11%
Epoch 3: loss 0.0123333, train_acc 67.78%, test_acc 66.97%
Epoch 4: loss 0.0108803, train_acc 73.96%, test_acc 73.47%
Epoch 5: loss 0.0098503, train_acc 77.73%, test_acc 76.70%
Epoch 6: loss 0.0092510, train_acc 78.74%, test_acc 76.41%
Epoch 7: loss 0.0087783, train_acc 80.78%, test_acc 79.68%
Epoch 8: loss 0.0083470, train_acc 82.26%, test_acc 81.20%
Epoch 9: loss 0.0080400, train_acc 80.53%, test_acc 77.61%
Epoch 10: loss 0.0077456, train_acc 79.05%, test_acc 76.97%
Epoch 11: loss 0.0074978, train_acc 83.55%, test_acc 81.40%
Epoch 12: loss 0.0073854, train_acc 82.75%, test_acc 80.85%
Epoch 13: loss 0.0071457, train_acc 80.67%, test_acc 79.22%
Epoch 14: loss 0.0069751, train_acc 83.91%, test_acc 82.53%
Epoch 15: loss 0.0068865, train_acc 82.41%, test_acc 80.45%
Epoch 16: loss 0.0067866, train_acc 84.23%, test_acc 82.49%
Epoch 17: loss 0.0066812, train_acc 83.78%, test_acc 81.59%
Epoch 18: loss 0.0064692, train_acc 85.09%, test_acc 83.55%
Epoch 19: loss 0.0065203, train_acc 81.72%, test_acc 79.35%
Epoch 20: loss 0.0063947, train_acc 86.08%, test_acc 84.11%
Epoch 21: loss 0.0063135, train_acc 85.88%, test_acc 83.50%
Epoch 22: loss 0.0061982, train_acc 85.42%, test_acc 83.14%
Epoch 23: loss 0.0061389, train_acc 84.54%, test_acc 81.18%
Epoch 24: loss 0.0060744, train_acc 80.57%, test_acc 78.26%
Epoch 25: loss 0.0060322, train_acc 84.12%, test_acc 82.19%
Epoch 26: loss 0.0059502, train_acc 84.03%, test_acc 82.15%
Epoch 27: loss 0.0058865, train_acc 86.41%, test_acc 84.43%
Epoch 28: loss 0.0058758, train_acc 86.64%, test_acc 84.17%
Epoch 29: loss 0.0059023, train_acc 84.69%, test_acc 82.70%
Epoch 30: loss 0.0057436, train_acc 86.17%, test_acc 83.48%
Epoch 31: loss 0.0057791, train_acc 86.76%, test_acc 84.80%
Epoch 32: loss 0.0057026, train_acc 85.34%, test_acc 82.68%
Epoch 33: loss 0.0055838, train_acc 86.92%, test_acc 84.81%
Epoch 34: loss 0.0055928, train_acc 87.20%, test_acc 85.10%
Epoch 35: loss 0.0055591, train_acc 86.55%, test_acc 83.93%
Epoch 36: loss 0.0056005, train_acc 85.89%, test_acc 83.05%
Epoch 37: loss 0.0055325, train_acc 85.17%, test_acc 82.51%
Epoch 38: loss 0.0054069, train_acc 89.08%, test_acc 86.61%
Epoch 39: loss 0.0055013, train_acc 87.07%, test_acc 85.54%
Epoch 40: loss 0.0054785, train_acc 86.48%, test_acc 83.99%
Epoch 41: loss 0.0053928, train_acc 81.19%, test_acc 78.72%
Epoch 42: loss 0.0053253, train_acc 87.65%, test_acc 85.14%
Epoch 43: loss 0.0053490, train_acc 84.58%, test_acc 81.70%
Epoch 44: loss 0.0053610, train_acc 85.77%, test_acc 83.29%
Epoch 45: loss 0.0052870, train_acc 85.82%, test_acc 82.51%
Epoch 46: loss 0.0053048, train_acc 86.77%, test_acc 84.00%
Epoch 47: loss 0.0051801, train_acc 86.85%, test_acc 83.77%
Epoch 48: loss 0.0051666, train_acc 88.88%, test_acc 85.59%
Epoch 49: loss 0.0051000, train_acc 87.55%, test_acc 85.31%
Epoch 50: loss 0.0053129, train_acc 87.64%, test_acc 85.76%
Epoch 51: loss 0.0051663, train_acc 85.20%, test_acc 82.88%
Epoch 52: loss 0.0051460, train_acc 87.32%, test_acc 85.26%
Epoch 53: loss 0.0051537, train_acc 88.52%, test_acc 85.93%
Epoch 54: loss 0.0051282, train_acc 88.24%, test_acc 85.74%
Epoch 55: loss 0.0050897, train_acc 87.12%, test_acc 84.76%
Epoch 56: loss 0.0051543, train_acc 82.44%, test_acc 80.31%
Epoch 57: loss 0.0050712, train_acc 86.78%, test_acc 84.63%
Epoch 58: loss 0.0050559, train_acc 86.09%, test_acc 83.37%
Epoch 59: loss 0.0050246, train_acc 85.04%, test_acc 81.92%
Epoch 60: loss 0.0050333, train_acc 89.00%, test_acc 86.94%
Epoch 61: loss 0.0050405, train_acc 88.75%, test_acc 85.73%
Epoch 62: loss 0.0050254, train_acc 90.16%, test_acc 87.44%
Epoch 63: loss 0.0050538, train_acc 86.82%, test_acc 84.38%
Epoch 64: loss 0.0049608, train_acc 88.38%, test_acc 85.16%
Epoch 65: loss 0.0049387, train_acc 88.00%, test_acc 84.79%
Epoch 66: loss 0.0050212, train_acc 87.89%, test_acc 83.81%
Epoch 67: loss 0.0049804, train_acc 87.34%, test_acc 84.92%
Epoch 68: loss 0.0048523, train_acc 88.27%, test_acc 85.33%
Epoch 69: loss 0.0049706, train_acc 88.57%, test_acc 86.12%
Epoch 70: loss 0.0049323, train_acc 84.39%, test_acc 82.43%
Epoch 71: loss 0.0048784, train_acc 89.10%, test_acc 86.28%
Epoch 72: loss 0.0048938, train_acc 88.15%, test_acc 85.38%
Epoch 73: loss 0.0048729, train_acc 90.00%, test_acc 87.20%
Epoch 74: loss 0.0049445, train_acc 88.36%, test_acc 85.01%
Epoch 75: loss 0.0049699, train_acc 87.54%, test_acc 85.12%
Epoch 76: loss 0.0048263, train_acc 86.19%, test_acc 84.14%
Epoch 77: loss 0.0047724, train_acc 85.95%, test_acc 82.90%
Epoch 78: loss 0.0048677, train_acc 88.23%, test_acc 85.73%
Epoch 79: loss 0.0048680, train_acc 87.34%, test_acc 84.58%
Epoch 80: loss 0.0031060, train_acc 95.13%, test_acc 91.80%
Epoch 81: loss 0.0025514, train_acc 95.61%, test_acc 91.99%
Epoch 82: loss 0.0023324, train_acc 96.01%, test_acc 92.13%
Epoch 83: loss 0.0022059, train_acc 96.14%, test_acc 92.16%
Epoch 84: loss 0.0021209, train_acc 96.44%, test_acc 92.14%
Epoch 85: loss 0.0019708, train_acc 96.43%, test_acc 92.26%
Epoch 86: loss 0.0019317, train_acc 96.72%, test_acc 92.26%
Epoch 87: loss 0.0018833, train_acc 96.98%, test_acc 92.41%
Epoch 88: loss 0.0017780, train_acc 96.96%, test_acc 92.26%
Epoch 89: loss 0.0017179, train_acc 97.17%, test_acc 92.19%
Epoch 90: loss 0.0016685, train_acc 97.37%, test_acc 92.41%
Epoch 91: loss 0.0016540, train_acc 97.26%, test_acc 92.36%
Epoch 92: loss 0.0015692, train_acc 97.42%, test_acc 92.19%
Epoch 93: loss 0.0015474, train_acc 97.59%, test_acc 92.44%
Epoch 94: loss 0.0014955, train_acc 97.33%, test_acc 92.14%
Epoch 95: loss 0.0014698, train_acc 97.56%, test_acc 92.30%
Epoch 96: loss 0.0014245, train_acc 97.70%, test_acc 92.21%
Epoch 97: loss 0.0013990, train_acc 97.63%, test_acc 92.37%
Epoch 98: loss 0.0013730, train_acc 97.69%, test_acc 92.08%
Epoch 99: loss 0.0013427, train_acc 97.55%, test_acc 92.02%
Epoch 100: loss 0.0013089, train_acc 98.04%, test_acc 92.14%
Epoch 101: loss 0.0013065, train_acc 98.05%, test_acc 92.11%
Epoch 102: loss 0.0012481, train_acc 98.09%, test_acc 92.06%
Epoch 103: loss 0.0012552, train_acc 98.03%, test_acc 92.18%
Epoch 104: loss 0.0012578, train_acc 98.05%, test_acc 92.19%
Epoch 105: loss 0.0012139, train_acc 98.26%, test_acc 92.29%
Epoch 106: loss 0.0012237, train_acc 98.17%, test_acc 92.37%
Epoch 107: loss 0.0012046, train_acc 98.00%, test_acc 92.15%
Epoch 108: loss 0.0012265, train_acc 98.09%, test_acc 91.99%
Epoch 109: loss 0.0011952, train_acc 97.83%, test_acc 91.53%
Epoch 110: loss 0.0011465, train_acc 97.67%, test_acc 91.25%
Epoch 111: loss 0.0011522, train_acc 98.36%, test_acc 92.14%
Epoch 112: loss 0.0011444, train_acc 98.06%, test_acc 91.88%
Epoch 113: loss 0.0011511, train_acc 98.25%, test_acc 91.84%
Epoch 114: loss 0.0011447, train_acc 98.23%, test_acc 91.86%
Epoch 115: loss 0.0011508, train_acc 98.10%, test_acc 91.91%
Epoch 116: loss 0.0011091, train_acc 98.03%, test_acc 91.81%
Epoch 117: loss 0.0010899, train_acc 98.19%, test_acc 91.85%
Epoch 118: loss 0.0011245, train_acc 98.30%, test_acc 91.66%
Epoch 119: loss 0.0011001, train_acc 98.16%, test_acc 91.99%
Epoch 120: loss 0.0008515, train_acc 98.99%, test_acc 92.71%
Epoch 121: loss 0.0007463, train_acc 99.10%, test_acc 92.76%
Epoch 122: loss 0.0006938, train_acc 99.21%, test_acc 92.82%
Epoch 123: loss 0.0006456, train_acc 99.25%, test_acc 92.93%
Epoch 124: loss 0.0006194, train_acc 99.35%, test_acc 92.84%
Epoch 125: loss 0.0006115, train_acc 99.32%, test_acc 92.82%
Epoch 126: loss 0.0006081, train_acc 99.38%, test_acc 92.88%
Epoch 127: loss 0.0005779, train_acc 99.37%, test_acc 92.76%
Epoch 128: loss 0.0005717, train_acc 99.42%, test_acc 92.65%
Epoch 129: loss 0.0005562, train_acc 99.40%, test_acc 92.59%
Epoch 130: loss 0.0005626, train_acc 99.39%, test_acc 92.75%
Epoch 131: loss 0.0005632, train_acc 99.42%, test_acc 92.69%
Epoch 132: loss 0.0005499, train_acc 99.46%, test_acc 92.81%
Epoch 133: loss 0.0005335, train_acc 99.44%, test_acc 92.73%
Epoch 134: loss 0.0005142, train_acc 99.51%, test_acc 92.71%
Epoch 135: loss 0.0005117, train_acc 99.50%, test_acc 92.77%
Epoch 136: loss 0.0005233, train_acc 99.58%, test_acc 92.68%
Epoch 137: loss 0.0005176, train_acc 99.48%, test_acc 92.52%
Epoch 138: loss 0.0005173, train_acc 99.52%, test_acc 92.68%
Epoch 139: loss 0.0005067, train_acc 99.55%, test_acc 92.65%
Epoch 140: loss 0.0004833, train_acc 99.53%, test_acc 92.76%
Epoch 141: loss 0.0004856, train_acc 99.56%, test_acc 92.78%
Epoch 142: loss 0.0004596, train_acc 99.54%, test_acc 92.77%
Epoch 143: loss 0.0004785, train_acc 99.55%, test_acc 92.72%
Epoch 144: loss 0.0004792, train_acc 99.58%, test_acc 92.74%
Epoch 145: loss 0.0004666, train_acc 99.60%, test_acc 92.68%
Epoch 146: loss 0.0004755, train_acc 99.61%, test_acc 92.73%
Epoch 147: loss 0.0004475, train_acc 99.53%, test_acc 92.68%
Epoch 148: loss 0.0004513, train_acc 99.57%, test_acc 92.55%
Epoch 149: loss 0.0004583, train_acc 99.59%, test_acc 92.66%
Epoch 150: loss 0.0004593, train_acc 99.61%, test_acc 92.63%
Epoch 151: loss 0.0004567, train_acc 99.59%, test_acc 92.60%
Epoch 152: loss 0.0004361, train_acc 99.62%, test_acc 92.56%
Epoch 153: loss 0.0004412, train_acc 99.68%, test_acc 92.76%
Epoch 154: loss 0.0004321, train_acc 99.63%, test_acc 92.65%
Epoch 155: loss 0.0004385, train_acc 99.64%, test_acc 92.70%
Epoch 156: loss 0.0004201, train_acc 99.66%, test_acc 92.74%
Epoch 157: loss 0.0004459, train_acc 99.64%, test_acc 92.67%
Epoch 158: loss 0.0004397, train_acc 99.61%, test_acc 92.46%
Epoch 159: loss 0.0004128, train_acc 99.58%, test_acc 92.55%
