=> Using a preset learning rate schedule:
{0: 0.1, 80: 0.010000000000000002, 120: 0.001}
 *** Used device: cuda
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz
Extracting ./cifar10/cifar-10-python.tar.gz to ./cifar10
Files already downloaded and verified
 *** Random labels done
 *** Random pixels done
 *** Mask calcualted (keeping 10.0% weights)
Epoch 0: loss 0.0288460, train_acc 41.33%, test_acc 41.86%
Epoch 1: loss 0.0212407, train_acc 52.39%, test_acc 52.18%
Epoch 2: loss 0.0167088, train_acc 61.98%, test_acc 61.00%
Epoch 3: loss 0.0140030, train_acc 65.88%, test_acc 66.01%
Epoch 4: loss 0.0120057, train_acc 71.62%, test_acc 71.92%
Epoch 5: loss 0.0108097, train_acc 75.46%, test_acc 73.57%
Epoch 6: loss 0.0100066, train_acc 71.82%, test_acc 69.80%
Epoch 7: loss 0.0094082, train_acc 81.97%, test_acc 80.90%
Epoch 8: loss 0.0088883, train_acc 81.62%, test_acc 80.68%
Epoch 9: loss 0.0085821, train_acc 81.92%, test_acc 80.37%
Epoch 10: loss 0.0082158, train_acc 79.65%, test_acc 79.09%
Epoch 11: loss 0.0080404, train_acc 78.92%, test_acc 77.92%
Epoch 12: loss 0.0077339, train_acc 79.53%, test_acc 77.82%
Epoch 13: loss 0.0075938, train_acc 83.08%, test_acc 81.50%
Epoch 14: loss 0.0072451, train_acc 81.00%, test_acc 79.38%
Epoch 15: loss 0.0071851, train_acc 82.26%, test_acc 79.49%
Epoch 16: loss 0.0069617, train_acc 85.35%, test_acc 83.39%
Epoch 17: loss 0.0069377, train_acc 84.50%, test_acc 82.33%
Epoch 18: loss 0.0068602, train_acc 85.44%, test_acc 82.84%
Epoch 19: loss 0.0067301, train_acc 80.83%, test_acc 77.88%
Epoch 20: loss 0.0065963, train_acc 85.28%, test_acc 83.40%
Epoch 21: loss 0.0065026, train_acc 82.80%, test_acc 79.78%
Epoch 22: loss 0.0064311, train_acc 87.81%, test_acc 85.53%
Epoch 23: loss 0.0063419, train_acc 83.33%, test_acc 81.48%
Epoch 24: loss 0.0062542, train_acc 84.08%, test_acc 81.61%
Epoch 25: loss 0.0062706, train_acc 86.20%, test_acc 84.00%
Epoch 26: loss 0.0061651, train_acc 84.19%, test_acc 82.51%
Epoch 27: loss 0.0059568, train_acc 84.73%, test_acc 82.32%
Epoch 28: loss 0.0060163, train_acc 86.94%, test_acc 84.60%
Epoch 29: loss 0.0059603, train_acc 81.03%, test_acc 79.46%
Epoch 30: loss 0.0059245, train_acc 87.21%, test_acc 85.48%
Epoch 31: loss 0.0058772, train_acc 85.39%, test_acc 83.20%
Epoch 32: loss 0.0058321, train_acc 88.01%, test_acc 85.19%
Epoch 33: loss 0.0057597, train_acc 84.43%, test_acc 82.05%
Epoch 34: loss 0.0057237, train_acc 84.42%, test_acc 81.84%
Epoch 35: loss 0.0057020, train_acc 84.53%, test_acc 81.81%
Epoch 36: loss 0.0057214, train_acc 87.08%, test_acc 85.08%
Epoch 37: loss 0.0056670, train_acc 87.16%, test_acc 84.87%
Epoch 38: loss 0.0056373, train_acc 85.40%, test_acc 83.23%
Epoch 39: loss 0.0055274, train_acc 84.09%, test_acc 81.70%
Epoch 40: loss 0.0055411, train_acc 85.71%, test_acc 83.50%
Epoch 41: loss 0.0054209, train_acc 84.52%, test_acc 82.53%
Epoch 42: loss 0.0055222, train_acc 84.33%, test_acc 81.13%
Epoch 43: loss 0.0054611, train_acc 86.72%, test_acc 84.39%
Epoch 44: loss 0.0053985, train_acc 88.29%, test_acc 85.18%
Epoch 45: loss 0.0053862, train_acc 86.28%, test_acc 83.73%
Epoch 46: loss 0.0053275, train_acc 86.22%, test_acc 82.83%
Epoch 47: loss 0.0052506, train_acc 85.76%, test_acc 83.20%
Epoch 48: loss 0.0053632, train_acc 86.54%, test_acc 83.68%
Epoch 49: loss 0.0052939, train_acc 84.96%, test_acc 82.17%
Epoch 50: loss 0.0052084, train_acc 82.21%, test_acc 80.26%
Epoch 51: loss 0.0052513, train_acc 87.68%, test_acc 84.83%
Epoch 52: loss 0.0052254, train_acc 87.51%, test_acc 85.05%
Epoch 53: loss 0.0051815, train_acc 85.07%, test_acc 82.20%
Epoch 54: loss 0.0052394, train_acc 88.73%, test_acc 85.80%
Epoch 55: loss 0.0051557, train_acc 83.16%, test_acc 80.72%
Epoch 56: loss 0.0051315, train_acc 87.12%, test_acc 84.67%
Epoch 57: loss 0.0051941, train_acc 85.86%, test_acc 83.69%
Epoch 58: loss 0.0051511, train_acc 89.38%, test_acc 87.07%
Epoch 59: loss 0.0050807, train_acc 88.86%, test_acc 85.67%
Epoch 60: loss 0.0050562, train_acc 86.29%, test_acc 83.44%
Epoch 61: loss 0.0050775, train_acc 90.09%, test_acc 87.81%
Epoch 62: loss 0.0050954, train_acc 85.84%, test_acc 83.94%
Epoch 63: loss 0.0049447, train_acc 87.96%, test_acc 84.95%
Epoch 64: loss 0.0049741, train_acc 86.58%, test_acc 83.55%
Epoch 65: loss 0.0050218, train_acc 86.71%, test_acc 84.00%
Epoch 66: loss 0.0049956, train_acc 89.52%, test_acc 87.00%
Epoch 67: loss 0.0049676, train_acc 86.11%, test_acc 83.22%
Epoch 68: loss 0.0049077, train_acc 89.25%, test_acc 86.42%
Epoch 69: loss 0.0050362, train_acc 84.96%, test_acc 82.55%
Epoch 70: loss 0.0049533, train_acc 88.10%, test_acc 85.53%
Epoch 71: loss 0.0049907, train_acc 82.12%, test_acc 79.23%
Epoch 72: loss 0.0048111, train_acc 88.58%, test_acc 85.49%
Epoch 73: loss 0.0049739, train_acc 87.99%, test_acc 85.90%
Epoch 74: loss 0.0048970, train_acc 86.63%, test_acc 84.04%
Epoch 75: loss 0.0049507, train_acc 88.70%, test_acc 85.36%
Epoch 76: loss 0.0048661, train_acc 88.25%, test_acc 86.10%
Epoch 77: loss 0.0048949, train_acc 85.08%, test_acc 81.96%
Epoch 78: loss 0.0049282, train_acc 87.62%, test_acc 84.82%
Epoch 79: loss 0.0048775, train_acc 89.06%, test_acc 86.16%
Epoch 80: loss 0.0030272, train_acc 95.18%, test_acc 91.50%
Epoch 81: loss 0.0025554, train_acc 95.77%, test_acc 91.87%
Epoch 82: loss 0.0023014, train_acc 96.01%, test_acc 92.10%
Epoch 83: loss 0.0022042, train_acc 96.33%, test_acc 92.16%
Epoch 84: loss 0.0020628, train_acc 96.52%, test_acc 92.04%
Epoch 85: loss 0.0019656, train_acc 96.64%, test_acc 92.29%
Epoch 86: loss 0.0019369, train_acc 96.82%, test_acc 92.26%
Epoch 87: loss 0.0018449, train_acc 97.09%, test_acc 92.48%
Epoch 88: loss 0.0017682, train_acc 97.04%, test_acc 92.09%
Epoch 89: loss 0.0017094, train_acc 97.22%, test_acc 92.41%
Epoch 90: loss 0.0016693, train_acc 97.35%, test_acc 92.27%
Epoch 91: loss 0.0016237, train_acc 97.43%, test_acc 91.88%
Epoch 92: loss 0.0015499, train_acc 97.44%, test_acc 92.09%
Epoch 93: loss 0.0015080, train_acc 97.46%, test_acc 92.12%
Epoch 94: loss 0.0014981, train_acc 97.59%, test_acc 92.27%
Epoch 95: loss 0.0014568, train_acc 97.78%, test_acc 92.15%
Epoch 96: loss 0.0014224, train_acc 97.81%, test_acc 92.09%
Epoch 97: loss 0.0013917, train_acc 97.72%, test_acc 92.18%
Epoch 98: loss 0.0013562, train_acc 97.52%, test_acc 91.69%
Epoch 99: loss 0.0013584, train_acc 97.89%, test_acc 91.69%
Epoch 100: loss 0.0013059, train_acc 98.24%, test_acc 92.30%
Epoch 101: loss 0.0013030, train_acc 98.10%, test_acc 92.04%
Epoch 102: loss 0.0012517, train_acc 98.11%, test_acc 92.00%
Epoch 103: loss 0.0012638, train_acc 98.24%, test_acc 92.10%
Epoch 104: loss 0.0012473, train_acc 98.07%, test_acc 91.84%
Epoch 105: loss 0.0011955, train_acc 98.08%, test_acc 91.85%
Epoch 106: loss 0.0011981, train_acc 98.25%, test_acc 91.81%
Epoch 107: loss 0.0011850, train_acc 98.16%, test_acc 91.79%
Epoch 108: loss 0.0011617, train_acc 98.11%, test_acc 91.78%
Epoch 109: loss 0.0011783, train_acc 98.05%, test_acc 91.87%
Epoch 110: loss 0.0011857, train_acc 98.13%, test_acc 91.50%
Epoch 111: loss 0.0011352, train_acc 98.34%, test_acc 92.15%
Epoch 112: loss 0.0011841, train_acc 98.08%, test_acc 91.59%
Epoch 113: loss 0.0010954, train_acc 98.36%, test_acc 91.94%
Epoch 114: loss 0.0011382, train_acc 98.25%, test_acc 91.68%
Epoch 115: loss 0.0010974, train_acc 98.21%, test_acc 91.58%
Epoch 116: loss 0.0011188, train_acc 98.42%, test_acc 92.13%
Epoch 117: loss 0.0011196, train_acc 98.08%, test_acc 92.09%
Epoch 118: loss 0.0011372, train_acc 98.13%, test_acc 91.76%
Epoch 119: loss 0.0010593, train_acc 98.35%, test_acc 91.59%
Epoch 120: loss 0.0008520, train_acc 99.07%, test_acc 92.51%
Epoch 121: loss 0.0007005, train_acc 99.20%, test_acc 92.43%
Epoch 122: loss 0.0006992, train_acc 99.26%, test_acc 92.62%
Epoch 123: loss 0.0006475, train_acc 99.34%, test_acc 92.61%
Epoch 124: loss 0.0006275, train_acc 99.29%, test_acc 92.58%
Epoch 125: loss 0.0005849, train_acc 99.44%, test_acc 92.60%
Epoch 126: loss 0.0005811, train_acc 99.35%, test_acc 92.66%
Epoch 127: loss 0.0005980, train_acc 99.42%, test_acc 92.66%
Epoch 128: loss 0.0005831, train_acc 99.47%, test_acc 92.44%
Epoch 129: loss 0.0005519, train_acc 99.49%, test_acc 92.67%
Epoch 130: loss 0.0005526, train_acc 99.48%, test_acc 92.69%
Epoch 131: loss 0.0005354, train_acc 99.46%, test_acc 92.70%
Epoch 132: loss 0.0005298, train_acc 99.47%, test_acc 92.63%
Epoch 133: loss 0.0005403, train_acc 99.44%, test_acc 92.55%
Epoch 134: loss 0.0005375, train_acc 99.46%, test_acc 92.58%
Epoch 135: loss 0.0005049, train_acc 99.53%, test_acc 92.57%
Epoch 136: loss 0.0004798, train_acc 99.53%, test_acc 92.63%
Epoch 137: loss 0.0004891, train_acc 99.56%, test_acc 92.70%
Epoch 138: loss 0.0004908, train_acc 99.54%, test_acc 92.63%
Epoch 139: loss 0.0005012, train_acc 99.58%, test_acc 92.77%
Epoch 140: loss 0.0004777, train_acc 99.53%, test_acc 92.62%
Epoch 141: loss 0.0004854, train_acc 99.62%, test_acc 92.67%
Epoch 142: loss 0.0004884, train_acc 99.57%, test_acc 92.73%
Epoch 143: loss 0.0004701, train_acc 99.59%, test_acc 92.79%
Epoch 144: loss 0.0004448, train_acc 99.59%, test_acc 92.79%
Epoch 145: loss 0.0004639, train_acc 99.66%, test_acc 92.69%
Epoch 146: loss 0.0004738, train_acc 99.66%, test_acc 92.79%
Epoch 147: loss 0.0004553, train_acc 99.60%, test_acc 92.65%
Epoch 148: loss 0.0004383, train_acc 99.61%, test_acc 92.70%
Epoch 149: loss 0.0004311, train_acc 99.64%, test_acc 92.70%
Epoch 150: loss 0.0004370, train_acc 99.59%, test_acc 92.75%
Epoch 151: loss 0.0004600, train_acc 99.68%, test_acc 92.67%
Epoch 152: loss 0.0004405, train_acc 99.63%, test_acc 92.64%
Epoch 153: loss 0.0004315, train_acc 99.66%, test_acc 92.49%
Epoch 154: loss 0.0004080, train_acc 99.66%, test_acc 92.65%
Epoch 155: loss 0.0004110, train_acc 99.63%, test_acc 92.58%
Epoch 156: loss 0.0004177, train_acc 99.68%, test_acc 92.53%
Epoch 157: loss 0.0004066, train_acc 99.70%, test_acc 92.58%
Epoch 158: loss 0.0004173, train_acc 99.70%, test_acc 92.54%
Epoch 159: loss 0.0004182, train_acc 99.71%, test_acc 92.61%
