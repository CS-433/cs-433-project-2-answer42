=> Using a preset learning rate schedule:
{0: 0.1, 80: 0.010000000000000002, 120: 0.001}
 *** Used device: cuda
Files already downloaded and verified
Files already downloaded and verified
 *** Mask calcualted (keeping 2.0% weights)
 *** Layerwise rearrange done
Epoch 0: loss 0.0319116, train_acc 21.94%, test_acc 22.16%
Epoch 1: loss 0.0281510, train_acc 36.33%, test_acc 34.91%
Epoch 2: loss 0.0248793, train_acc 43.71%, test_acc 43.32%
Epoch 3: loss 0.0226303, train_acc 40.18%, test_acc 41.37%
Epoch 4: loss 0.0208913, train_acc 47.38%, test_acc 49.01%
Epoch 5: loss 0.0195849, train_acc 58.50%, test_acc 58.88%
Epoch 6: loss 0.0186633, train_acc 58.13%, test_acc 57.88%
Epoch 7: loss 0.0179634, train_acc 57.85%, test_acc 57.54%
Epoch 8: loss 0.0174324, train_acc 56.43%, test_acc 56.42%
Epoch 9: loss 0.0168052, train_acc 62.48%, test_acc 62.64%
Epoch 10: loss 0.0165083, train_acc 68.16%, test_acc 66.98%
Epoch 11: loss 0.0162665, train_acc 65.15%, test_acc 64.11%
Epoch 12: loss 0.0161390, train_acc 62.82%, test_acc 62.12%
Epoch 13: loss 0.0162265, train_acc 64.46%, test_acc 63.74%
Epoch 14: loss 0.0167373, train_acc 66.00%, test_acc 66.10%
Epoch 15: loss 0.0165178, train_acc 55.32%, test_acc 54.88%
Epoch 16: loss 0.0175927, train_acc 65.54%, test_acc 64.03%
Epoch 17: loss 0.0161732, train_acc 65.88%, test_acc 65.23%
Epoch 18: loss 0.0159721, train_acc 63.73%, test_acc 64.07%
Epoch 19: loss 0.0166968, train_acc 66.24%, test_acc 67.48%
Epoch 20: loss 0.0154819, train_acc 69.11%, test_acc 68.66%
Epoch 21: loss 0.0158063, train_acc 51.57%, test_acc 51.66%
Epoch 22: loss 0.0183465, train_acc 56.15%, test_acc 57.17%
Epoch 23: loss 0.0161239, train_acc 68.41%, test_acc 67.37%
Epoch 24: loss 0.0153916, train_acc 69.31%, test_acc 68.36%
Epoch 25: loss 0.0162834, train_acc 65.67%, test_acc 64.55%
Epoch 26: loss 0.0154614, train_acc 71.20%, test_acc 69.81%
Epoch 27: loss 0.0163148, train_acc 66.90%, test_acc 65.74%
Epoch 28: loss 0.0153507, train_acc 67.98%, test_acc 67.23%
Epoch 29: loss 0.0153305, train_acc 72.12%, test_acc 70.37%
Epoch 30: loss 0.0157447, train_acc 69.90%, test_acc 68.38%
Epoch 31: loss 0.0152969, train_acc 72.85%, test_acc 72.03%
Epoch 32: loss 0.0146717, train_acc 69.19%, test_acc 68.13%
Epoch 33: loss 0.0154949, train_acc 68.99%, test_acc 68.38%
Epoch 34: loss 0.0150185, train_acc 63.01%, test_acc 63.68%
Epoch 35: loss 0.0160382, train_acc 55.05%, test_acc 57.92%
Epoch 36: loss 0.0158020, train_acc 68.47%, test_acc 68.49%
Epoch 37: loss 0.0180435, train_acc 65.52%, test_acc 64.57%
Epoch 38: loss 0.0157637, train_acc 72.39%, test_acc 71.36%
Epoch 39: loss 0.0147075, train_acc 72.53%, test_acc 70.78%
Epoch 40: loss 0.0142114, train_acc 73.48%, test_acc 72.95%
Epoch 41: loss 0.0138077, train_acc 74.26%, test_acc 72.96%
Epoch 42: loss 0.0137130, train_acc 76.56%, test_acc 75.91%
Epoch 43: loss 0.0134809, train_acc 76.40%, test_acc 75.43%
Epoch 44: loss 0.0133117, train_acc 73.96%, test_acc 73.66%
Epoch 45: loss 0.0133510, train_acc 75.50%, test_acc 74.28%
Epoch 46: loss 0.0132533, train_acc 75.57%, test_acc 75.20%
Epoch 47: loss 0.0132514, train_acc 76.79%, test_acc 75.74%
Epoch 48: loss 0.0130456, train_acc 77.93%, test_acc 76.80%
Epoch 49: loss 0.0130119, train_acc 76.71%, test_acc 76.06%
Epoch 50: loss 0.0129075, train_acc 78.20%, test_acc 76.69%
Epoch 51: loss 0.0129537, train_acc 73.39%, test_acc 71.54%
Epoch 52: loss 0.0128327, train_acc 76.44%, test_acc 75.80%
Epoch 53: loss 0.0127987, train_acc 76.04%, test_acc 75.12%
Epoch 54: loss 0.0127776, train_acc 77.53%, test_acc 75.93%
Epoch 55: loss 0.0126687, train_acc 76.57%, test_acc 75.08%
Epoch 56: loss 0.0126621, train_acc 77.32%, test_acc 76.59%
Epoch 57: loss 0.0125516, train_acc 77.81%, test_acc 77.51%
Epoch 58: loss 0.0125024, train_acc 78.49%, test_acc 77.46%
Epoch 59: loss 0.0124668, train_acc 77.99%, test_acc 77.06%
Epoch 60: loss 0.0125096, train_acc 73.05%, test_acc 72.92%
Epoch 61: loss 0.0124277, train_acc 77.82%, test_acc 76.23%
Epoch 62: loss 0.0124671, train_acc 79.29%, test_acc 77.85%
Epoch 63: loss 0.0124164, train_acc 78.30%, test_acc 76.50%
Epoch 64: loss 0.0123130, train_acc 77.96%, test_acc 77.24%
Epoch 65: loss 0.0125677, train_acc 77.33%, test_acc 76.33%
Epoch 66: loss 0.0123140, train_acc 80.55%, test_acc 78.86%
Epoch 67: loss 0.0121931, train_acc 78.83%, test_acc 78.02%
Epoch 68: loss 0.0122632, train_acc 76.07%, test_acc 74.28%
Epoch 69: loss 0.0121167, train_acc 79.91%, test_acc 78.08%
Epoch 70: loss 0.0121890, train_acc 80.50%, test_acc 79.33%
Epoch 71: loss 0.0121191, train_acc 77.32%, test_acc 75.55%
Epoch 72: loss 0.0120483, train_acc 78.52%, test_acc 76.52%
Epoch 73: loss 0.0120139, train_acc 80.74%, test_acc 79.03%
Epoch 74: loss 0.0120421, train_acc 80.13%, test_acc 78.31%
Epoch 75: loss 0.0120102, train_acc 79.18%, test_acc 78.14%
Epoch 76: loss 0.0119341, train_acc 80.70%, test_acc 79.17%
Epoch 77: loss 0.0120197, train_acc 77.95%, test_acc 77.57%
Epoch 78: loss 0.0119283, train_acc 77.97%, test_acc 77.24%
Epoch 79: loss 0.0119374, train_acc 73.02%, test_acc 72.73%
Epoch 80: loss 0.0100376, train_acc 87.41%, test_acc 84.30%
Epoch 81: loss 0.0094645, train_acc 87.51%, test_acc 84.80%
Epoch 82: loss 0.0091591, train_acc 88.62%, test_acc 85.59%
Epoch 83: loss 0.0089340, train_acc 88.98%, test_acc 85.44%
Epoch 84: loss 0.0087623, train_acc 89.39%, test_acc 85.99%
Epoch 85: loss 0.0086737, train_acc 89.68%, test_acc 86.23%
Epoch 86: loss 0.0084649, train_acc 90.16%, test_acc 86.51%
Epoch 87: loss 0.0083570, train_acc 90.18%, test_acc 86.51%
Epoch 88: loss 0.0082873, train_acc 90.33%, test_acc 86.10%
Epoch 89: loss 0.0081713, train_acc 90.89%, test_acc 86.87%
Epoch 90: loss 0.0081390, train_acc 90.88%, test_acc 86.38%
Epoch 91: loss 0.0079538, train_acc 91.00%, test_acc 86.40%
Epoch 92: loss 0.0078838, train_acc 91.29%, test_acc 86.82%
Epoch 93: loss 0.0078630, train_acc 91.04%, test_acc 86.31%
Epoch 94: loss 0.0077097, train_acc 91.53%, test_acc 86.80%
Epoch 95: loss 0.0076394, train_acc 91.67%, test_acc 86.73%
Epoch 96: loss 0.0075678, train_acc 91.91%, test_acc 86.83%
Epoch 97: loss 0.0075704, train_acc 91.54%, test_acc 86.68%
Epoch 98: loss 0.0074890, train_acc 91.52%, test_acc 86.44%
Epoch 99: loss 0.0074435, train_acc 91.24%, test_acc 85.91%
Epoch 100: loss 0.0073039, train_acc 92.00%, test_acc 86.50%
Epoch 101: loss 0.0073038, train_acc 92.12%, test_acc 86.84%
Epoch 102: loss 0.0072253, train_acc 91.58%, test_acc 86.12%
Epoch 103: loss 0.0071538, train_acc 92.34%, test_acc 86.56%
Epoch 104: loss 0.0071821, train_acc 92.41%, test_acc 86.48%
Epoch 105: loss 0.0071459, train_acc 92.01%, test_acc 86.25%
Epoch 106: loss 0.0071367, train_acc 92.49%, test_acc 87.19%
Epoch 107: loss 0.0070102, train_acc 91.24%, test_acc 85.62%
Epoch 108: loss 0.0070267, train_acc 91.78%, test_acc 86.55%
Epoch 109: loss 0.0069853, train_acc 92.61%, test_acc 86.65%
Epoch 110: loss 0.0068882, train_acc 92.09%, test_acc 86.38%
Epoch 111: loss 0.0068932, train_acc 92.70%, test_acc 86.82%
Epoch 112: loss 0.0068458, train_acc 93.24%, test_acc 87.30%
Epoch 113: loss 0.0067972, train_acc 92.95%, test_acc 86.82%
Epoch 114: loss 0.0067693, train_acc 92.84%, test_acc 87.05%
Epoch 115: loss 0.0067929, train_acc 93.44%, test_acc 87.47%
Epoch 116: loss 0.0067242, train_acc 92.97%, test_acc 86.98%
Epoch 117: loss 0.0067241, train_acc 93.32%, test_acc 86.93%
Epoch 118: loss 0.0066800, train_acc 93.04%, test_acc 86.93%
Epoch 119: loss 0.0066919, train_acc 93.22%, test_acc 86.83%
Epoch 120: loss 0.0063185, train_acc 93.98%, test_acc 87.57%
Epoch 121: loss 0.0062071, train_acc 94.42%, test_acc 87.57%
Epoch 122: loss 0.0060984, train_acc 94.74%, test_acc 87.87%
Epoch 123: loss 0.0060297, train_acc 94.72%, test_acc 87.71%
Epoch 124: loss 0.0060330, train_acc 94.77%, test_acc 87.58%
Epoch 125: loss 0.0060044, train_acc 94.76%, test_acc 87.63%
Epoch 126: loss 0.0059652, train_acc 94.79%, test_acc 87.68%
Epoch 127: loss 0.0059525, train_acc 94.79%, test_acc 87.80%
Epoch 128: loss 0.0059597, train_acc 94.80%, test_acc 87.92%
Epoch 129: loss 0.0059260, train_acc 94.86%, test_acc 87.91%
Epoch 130: loss 0.0059089, train_acc 94.98%, test_acc 87.96%
Epoch 131: loss 0.0058981, train_acc 95.14%, test_acc 87.94%
Epoch 132: loss 0.0058875, train_acc 95.17%, test_acc 87.81%
Epoch 133: loss 0.0058495, train_acc 95.02%, test_acc 87.98%
Epoch 134: loss 0.0058311, train_acc 95.18%, test_acc 88.12%
Epoch 135: loss 0.0058761, train_acc 95.30%, test_acc 87.98%
Epoch 136: loss 0.0058269, train_acc 95.09%, test_acc 88.02%
Epoch 137: loss 0.0057722, train_acc 95.45%, test_acc 88.00%
Epoch 138: loss 0.0057841, train_acc 95.41%, test_acc 88.07%
Epoch 139: loss 0.0058057, train_acc 95.34%, test_acc 88.23%
Epoch 140: loss 0.0057844, train_acc 95.24%, test_acc 88.13%
Epoch 141: loss 0.0058138, train_acc 95.36%, test_acc 88.08%
Epoch 142: loss 0.0057851, train_acc 95.35%, test_acc 88.01%
Epoch 143: loss 0.0057231, train_acc 95.38%, test_acc 88.28%
Epoch 144: loss 0.0057832, train_acc 95.51%, test_acc 88.28%
Epoch 145: loss 0.0057153, train_acc 95.56%, test_acc 88.48%
Epoch 146: loss 0.0056989, train_acc 95.44%, test_acc 87.89%
Epoch 147: loss 0.0057015, train_acc 95.37%, test_acc 88.33%
Epoch 148: loss 0.0056809, train_acc 95.69%, test_acc 88.23%
Epoch 149: loss 0.0056961, train_acc 95.69%, test_acc 88.21%
Epoch 150: loss 0.0056562, train_acc 95.63%, test_acc 88.18%
Epoch 151: loss 0.0056578, train_acc 95.53%, test_acc 88.22%
Epoch 152: loss 0.0056831, train_acc 95.50%, test_acc 87.97%
Epoch 153: loss 0.0056887, train_acc 95.58%, test_acc 88.15%
Epoch 154: loss 0.0056550, train_acc 95.70%, test_acc 88.03%
Epoch 155: loss 0.0056479, train_acc 95.77%, test_acc 88.27%
Epoch 156: loss 0.0056510, train_acc 95.68%, test_acc 88.16%
Epoch 157: loss 0.0056268, train_acc 95.78%, test_acc 88.18%
Epoch 158: loss 0.0056019, train_acc 95.87%, test_acc 88.31%
Epoch 159: loss 0.0055913, train_acc 95.70%, test_acc 88.41%
